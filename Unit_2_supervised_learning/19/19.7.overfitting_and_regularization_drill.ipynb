{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "In this assignment, you'll continue working with the house prices data. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Reimplement your model from the previous checkpoint.\n",
    "* Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do **k-fold cross-validation** to choose the best hyperparameter values for your models. Which model is the best? Why?\n",
    "\n",
    "This is not a graded checkpoint, but you should discuss your solution with your mentor. After you've submitted your work, take a moment to compare your solution to [this example solution](https://github.com/Thinkful-Ed/machine-learning-regression-problems/blob/master/notebooks/7.solution_overfitting_and_regularization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats import mode\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numpy': '1.16.4', 'pandas': '0.25.0', 'sklearn': '0.0', 'matplotlib': '3.1.1', 'seaborn': '0.9.0', 'sqlalchemy': '1.3.6', 'scipy': '1.3.0'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'numpy': '1.16.4',\n",
       " 'pandas': '0.25.0',\n",
       " 'sklearn': '0.0',\n",
       " 'matplotlib': '3.1.1',\n",
       " 'seaborn': '0.9.0',\n",
       " 'sqlalchemy': '1.3.6',\n",
       " 'scipy': '1.3.0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load ../utility/overhead.py\n",
    "#record module versions used in cell 1\n",
    "#\n",
    "def version_recorder():\n",
    "    '''\n",
    "    only works if import is first cell run. prints and then returns dictionary with modules:version.\n",
    "    '''\n",
    "    import pkg_resources\n",
    "    resources = In[1].splitlines()\n",
    "    ##ADD: drop lines if not _from_ or _import_\n",
    "    version_dict = { resource.split()[1].split(\".\")[0] : pkg_resources.get_distribution(resource.split()[1].split(\".\")[0]).version for resource in resources }\n",
    "    return version_dict\n",
    "version_recorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared (uncentered):</th>      <td>   0.953</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.953</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   7390.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Jul 2019</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:01:57</td>     <th>  Log-Likelihood:    </th>          <td> -17642.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1460</td>      <th>  AIC:               </th>          <td>3.529e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1456</td>      <th>  BIC:               </th>          <td>3.531e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th> <td>  3.27e+04</td> <td> 1074.204</td> <td>   30.442</td> <td> 0.000</td> <td> 3.06e+04</td> <td> 3.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>   <td>   52.9168</td> <td>    2.972</td> <td>   17.806</td> <td> 0.000</td> <td>   47.087</td> <td>   58.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>    <td> 4384.2970</td> <td> 2740.626</td> <td>    1.600</td> <td> 0.110</td> <td> -991.700</td> <td> 9760.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>   <td>  -53.4819</td> <td>    2.694</td> <td>  -19.856</td> <td> 0.000</td> <td>  -58.766</td> <td>  -48.198</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>350.750</td> <th>  Durbin-Watson:     </th> <td>   1.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7694.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.561</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.191</td>  <th>  Cond. No.          </th> <td>6.16e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.16e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              saleprice   R-squared (uncentered):                   0.953\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.953\n",
       "Method:                 Least Squares   F-statistic:                              7390.\n",
       "Date:                Thu, 25 Jul 2019   Prob (F-statistic):                        0.00\n",
       "Time:                        20:01:57   Log-Likelihood:                         -17642.\n",
       "No. Observations:                1460   AIC:                                  3.529e+04\n",
       "Df Residuals:                    1456   BIC:                                  3.531e+04\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "overallqual   3.27e+04   1074.204     30.442      0.000    3.06e+04    3.48e+04\n",
       "grlivarea      52.9168      2.972     17.806      0.000      47.087      58.746\n",
       "fullbath     4384.2970   2740.626      1.600      0.110    -991.700    9760.294\n",
       "yearbuilt     -53.4819      2.694    -19.856      0.000     -58.766     -48.198\n",
       "==============================================================================\n",
       "Omnibus:                      350.750   Durbin-Watson:                   1.980\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7694.705\n",
       "Skew:                           0.561   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.191   Cond. No.                     6.16e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.16e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#credentials\n",
    "user = 'dsbc_student'\n",
    "pw = '7*.8G9QH21'\n",
    "host = '142.93.121.174'\n",
    "port = '5432'\n",
    "db = 'houseprices'\n",
    "dialect = 'postgresql'\n",
    "\n",
    "engine = create_engine('{}://{}:{}@{}:{}/{}'.format(dialect, user, pw, host, port, db))\n",
    "engine.table_names()\n",
    "\n",
    "sql_query = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    houseprices\n",
    "'''\n",
    "source_df = pd.read_sql(sql_query, con=engine)\n",
    "engine.dispose()\n",
    "house_df = source_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#create df with categorical variables to select some features from\n",
    "categorical_feat = house_df.dtypes[house_df.dtypes == 'object'].index\n",
    "new_categories_df = pd.DataFrame()\n",
    "for feature in categorical_feat:\n",
    "    new_categories_df = pd.concat([new_categories_df, \n",
    "                                   pd.get_dummies(house_df[feature], columns=categorical_feat, drop_first=True, prefix = feature)], axis=1)\n",
    "#append numerical features to new df\n",
    "new_categories_df = pd.concat([new_categories_df, \n",
    "                               house_df.filter(items=(house_df.columns[(house_df.dtypes.values != 'object').tolist()]), axis=1) ], \n",
    "                              axis=1) #tolist() needed to avoid hashability issue\n",
    "\n",
    "#create X & y\n",
    "X = house_df[[\"overallqual\", \"grlivarea\", \"fullbath\", \"yearbuilt\",]]\n",
    "pd.concat([X, new_categories_df[['exterqual_TA', 'foundation_CBlock']]])\n",
    "X[\"overalqual_x_year\"] = house_df.overallqual * house_df.yearbuilt\n",
    "y = house_df.saleprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X=X, y=y, kfold = 5):\n",
    "    X_overall = X\n",
    "    sm.add_constant(X_overall)\n",
    "    overall_model = sm.OLS(y, X_overall).fit()\n",
    "    print('------------test-------------')\n",
    "    print('adjusted R^2 is {}'.format(overall_model.rsquared_adj))\n",
    "    print('AIC is {} and BIC is {}'.format(overall_model.aic, overall_model.bic))\n",
    "    for k in range(1, kfold):\n",
    "        #split into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+k)\n",
    "\n",
    "        sm.add_constant(X_train)\n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "        y_preds = model.predict(X_test)\n",
    "        \n",
    "        print('-----------{}-FOLD-------------'.format(k))\n",
    "        print(\"root mean squared error is: {}\".format(rmse(y_test, y_preds)))\n",
    "        print(\"mean squared error is: {}\\n\".format(mse(y_test, y_preds)))\n",
    "    print(overall_model.summary())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------test-------------\n",
      "adjusted R^2 is 0.9593178009510193\n",
      "AIC is 35079.660951391044 and BIC is 35106.091909964554\n",
      "-----------1-FOLD-------------\n",
      "root mean squared error is: 34944.75385267113\n",
      "mean squared error is: 1221135821.8237736\n",
      "\n",
      "-----------2-FOLD-------------\n",
      "root mean squared error is: 34144.21352594143\n",
      "mean squared error is: 1165827317.3050814\n",
      "\n",
      "-----------3-FOLD-------------\n",
      "root mean squared error is: 35102.3078392356\n",
      "mean squared error is: 1232172015.6404607\n",
      "\n",
      "-----------4-FOLD-------------\n",
      "root mean squared error is: 39946.941649133834\n",
      "mean squared error is: 1595758147.1193032\n",
      "\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              saleprice   R-squared (uncentered):                   0.959\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.959\n",
      "Method:                 Least Squares   F-statistic:                              6887.\n",
      "Date:                Thu, 25 Jul 2019   Prob (F-statistic):                        0.00\n",
      "Time:                        23:36:59   Log-Likelihood:                         -17535.\n",
      "No. Observations:                1460   AIC:                                  3.508e+04\n",
      "Df Residuals:                    1455   BIC:                                  3.511e+04\n",
      "Df Model:                           5                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "overallqual       -1.861e+05   1.45e+04    -12.862      0.000   -2.15e+05   -1.58e+05\n",
      "grlivarea            68.5385      2.949     23.244      0.000      62.755      74.323\n",
      "fullbath          -1.081e+04   2737.769     -3.947      0.000   -1.62e+04   -5435.906\n",
      "yearbuilt           -29.0650      2.977     -9.762      0.000     -34.905     -23.225\n",
      "overalqual_x_year   106.7888      7.045     15.158      0.000      92.970     120.608\n",
      "==============================================================================\n",
      "Omnibus:                      369.617   Durbin-Watson:                   1.980\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21320.487\n",
      "Skew:                           0.175   Prob(JB):                         0.00\n",
      "Kurtosis:                      21.718   Cond. No.                     1.76e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.76e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "test_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge Regression\n",
    "sm.regression.linear_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
