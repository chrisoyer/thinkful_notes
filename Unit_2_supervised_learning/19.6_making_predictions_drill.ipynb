{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "In this exercise, you'll predict house prices using your model. To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "* Load the **houseprices** data from Thinkful's database.\n",
    "* Split your data into train and test sets.\n",
    "* Estimate your model from the previous checkpoint in the train set. Assess the goodness of fit of your model.\n",
    "* Predict the house prices in the test set, and evaluate the performance of your model using the metrics we mentioned in this checkpoint.\n",
    "* Is the performance of your model satisfactory? Why?\n",
    "* Try to improve your model in terms of predictive performance by adding or removing some variables.\n",
    "\n",
    "Please submit a link your work notebook. This is not a graded checkpoint, but you should discuss your solutions with your mentor. Also, when you're done, compare your work to [this example solution](https://github.com/Thinkful-Ed/machine-learning-regression-problems/blob/master/notebooks/6.solution_making_predictions.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.stats import mode\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numpy': '1.16.4',\n",
       " 'pandas': '0.25.0',\n",
       " 'sklearn': '0.0',\n",
       " 'matplotlib': '3.1.1',\n",
       " 'seaborn': '0.9.0',\n",
       " 'sqlalchemy': '1.3.6',\n",
       " 'scipy': '1.3.0',\n",
       " 'statsmodels': '0.10.1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#record module versions used in cell 1\n",
    "import pkg_resources\n",
    "resources = In[1].splitlines()\n",
    "version_dict = { resource.split()[1].split(\".\")[0] : pkg_resources.get_distribution(resource.split()[1].split(\".\")[0]).version for resource in resources }\n",
    "version_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#credentials\n",
    "user = 'dsbc_student'\n",
    "pw = '7*.8G9QH21'\n",
    "host = '142.93.121.174'\n",
    "port = '5432'\n",
    "db = 'houseprices'\n",
    "dialect = 'postgresql'\n",
    "\n",
    "db_addr = f'{dialect}://{user}:{pw}@{host}:{port}/{db}'\n",
    "engine = create_engine(db_addr)\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    houseprices\n",
    "'''\n",
    "\n",
    "raw_df = pd.read_sql(query, con=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = raw_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X & y\n",
    "X = house_df[[\"overallqual\", \"grlivarea\", \"fullbath\", \"yearbuilt\"]]\n",
    "y = house_df.saleprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared (uncentered):</th>      <td>   0.954</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.954</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   6038.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 24 Jul 2019</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:41:04</td>     <th>  Log-Likelihood:    </th>          <td> -14104.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th>          <td>2.822e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th>          <td>2.824e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th> <td> 3.277e+04</td> <td> 1192.501</td> <td>   27.484</td> <td> 0.000</td> <td> 3.04e+04</td> <td> 3.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>   <td>   48.4781</td> <td>    3.246</td> <td>   14.936</td> <td> 0.000</td> <td>   42.110</td> <td>   54.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>    <td> 6375.8166</td> <td> 3020.730</td> <td>    2.111</td> <td> 0.035</td> <td>  449.131</td> <td> 1.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>   <td>  -52.1815</td> <td>    3.052</td> <td>  -17.097</td> <td> 0.000</td> <td>  -58.170</td> <td>  -46.193</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>232.779</td> <th>  Durbin-Watson:     </th> <td>   2.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4805.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.312</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>12.917</td>  <th>  Cond. No.          </th> <td>6.15e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.15e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              saleprice   R-squared (uncentered):                   0.954\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.954\n",
       "Method:                 Least Squares   F-statistic:                              6038.\n",
       "Date:                Wed, 24 Jul 2019   Prob (F-statistic):                        0.00\n",
       "Time:                        21:41:04   Log-Likelihood:                         -14104.\n",
       "No. Observations:                1168   AIC:                                  2.822e+04\n",
       "Df Residuals:                    1164   BIC:                                  2.824e+04\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "overallqual  3.277e+04   1192.501     27.484      0.000    3.04e+04    3.51e+04\n",
       "grlivarea      48.4781      3.246     14.936      0.000      42.110      54.846\n",
       "fullbath     6375.8166   3020.730      2.111      0.035     449.131    1.23e+04\n",
       "yearbuilt     -52.1815      3.052    -17.097      0.000     -58.170     -46.193\n",
       "==============================================================================\n",
       "Omnibus:                      232.779   Durbin-Watson:                   2.089\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4805.472\n",
       "Skew:                           0.312   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.917   Cond. No.                     6.15e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.15e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (292,5) and (4,) not aligned: 5 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-341a66d2c796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"root mean squared error is: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mean squared error is: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m         predict_results = self.model.predict(self.params, exog, *args,\n\u001b[1;32m-> 1038\u001b[1;33m                                              **kwargs)\n\u001b[0m\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m         if exog_index is not None and not hasattr(predict_results,\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (292,5) and (4,) not aligned: 5 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "X_test = sm.add_constant(X_test)\n",
    "y_preds = model.predict(X_test)\n",
    "print(\"root mean squared error is: \".format(rmse(y_test, y_preds)))\n",
    "print(\"mean squared error is: \".format(mse(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
