{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Kindle_Reviews__Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisoyer/thinkful_notes/blob/master/Amazon_Kindle_Reviews__Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-DjJmVMsUk",
        "colab_type": "text"
      },
      "source": [
        "# Description:\n",
        "Goal: Amazon Reviews Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haKf5PoUM5dO",
        "colab_type": "text"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K2oSl1VM4ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#environment\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds8rh3VeGIao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_CLASSPATH\"] = '/content/spark-2.4.5-bin-hadoop2.7'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGmM9NimNDY2",
        "colab_type": "code",
        "outputId": "e84d9743-b436-4075-d375-f101bee704f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 54kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=bc4a3cdb71918739f8151e4817d85c1693f701a6e4cb0cff290f6e4d612d540c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4y1rP_DIa4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName('Spark NLP') \\\n",
        "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.2.2\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_5yArpRPTg9",
        "colab_type": "code",
        "outputId": "83d0c8aa-ceff-4613-c6be-6be43dbe9e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV3EdpQix1Tt",
        "colab_type": "code",
        "outputId": "0c4f93cf-865b-4bbd-ab0e-60bf18b4ec87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import urllib\n",
        "from pyspark import SparkContext\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "!pip install spark-nlp\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp.base import LightPipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import RegexRule\n",
        "from sparknlp.base import DocumentAssembler, Finisher"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spark-nlp in /usr/local/lib/python3.6/dist-packages (2.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njcPYngZMFw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_url = r\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_5.json.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ToghFIPT-3",
        "colab_type": "text"
      },
      "source": [
        "I am using a local copy of the above file, stored on gDrive, instead of re-downloading the source file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kZfyUIEP1-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = r'/content/gdrive/My Drive/thinkful/colab_datasets/amazon_reviews/'\n",
        "reviews_arx = os.path.join(data_folder, 'reviews_Kindle_Store_5.json.gz')\n",
        "reviews_raw = os.path.join(data_folder, 'Grocery_and_Gourmet_Food_5.json')\n",
        "if not os.path.exists(reviews_raw):\n",
        "    if not os.path.exists(data_folder):\n",
        "        os.mkdir(data_folder)\n",
        "    if not os.path.exists(reviews_arx):\n",
        "        urllib.request.urlretrieve(source_url, filename=reviews_arx)\n",
        "    import shutil\n",
        "    import gzip\n",
        "    with gzip.open(reviews_arx, 'rb') as f_in:\n",
        "        with open(reviews_raw, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "SPARK_URL = \"local[*]\"\n",
        "APP_NAME  = \"amazon_food_reviews\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HrmTKPaPhWn",
        "colab_type": "code",
        "outputId": "0fd57a90-6e0d-4be3-cff4-421dfde12596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(\"Spark NLP version\")\n",
        "sparknlp.version()\n",
        "print(\"Apache Spark version\")\n",
        "spark.version"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version\n",
            "2.2.2\n",
            "Apache Spark version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4B0pToj9oht",
        "colab_type": "code",
        "outputId": "73d4a919-ad7f-4406-9bc1-5132dadf3a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "sparknlp.start()\n",
        "pipeline = PretrainedPipeline(name='analyze_sentiment', lang='en')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_GDMh39QKnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = spark.read.options(inferschema = \"true\").json(reviews_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJGgdyXHppbz",
        "colab_type": "code",
        "outputId": "d8dabd73-16d2-47d6-f463-7a2c8bff065d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "reviews_df.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHRBLfUppuAq",
        "colab_type": "code",
        "outputId": "c6a74da2-2afe-4dd2-fc1b-c091db9d571d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "reviews_df.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|   reviewerName|             summary|unixReviewTime|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "|616719923X| [0, 0]|    4.0|Just another flav...| 06 1, 2013|A1VEELTKS8NLZB|Amazon Customer|          Good Taste|    1370044800|\n",
            "|616719923X| [0, 1]|    3.0|I bought this on ...|05 19, 2014|A14R9XMZVJ6INB|        amf0001|3.5 stars,  sadly...|    1400457600|\n",
            "|616719923X| [3, 4]|    4.0|Really good. Grea...| 10 8, 2013|A27IQHDZFQFNGG|        Caitlin|                Yum!|    1381190400|\n",
            "|616719923X| [0, 0]|    5.0|I had never had i...|05 20, 2013|A31QY5TASILE89|   DebraDownSth|Unexpected flavor...|    1369008000|\n",
            "|616719923X| [1, 2]|    4.0|I've been looking...|05 26, 2013|A2LWK003FFMCI5|       Diana X.|Not a very strong...|    1369526400|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meXz731U18UB",
        "colab_type": "code",
        "outputId": "fbdc22b0-b175-4a89-fff2-5ebf9dc83b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "reviews_df.select('overall').describe().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|           overall|\n",
            "+-------+------------------+\n",
            "|  count|            151254|\n",
            "|   mean| 4.243041506340329|\n",
            "| stddev|1.0900026138973262|\n",
            "|    min|               1.0|\n",
            "|    max|               5.0|\n",
            "+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA260z_c3fT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = reviews_df.withColumn('sentiment_label', F.when(reviews_df[\"overall\"] >= 4, 'Positive').otherwise('Negative'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crs2GVvP5INN",
        "colab_type": "code",
        "outputId": "6ef5d633-bf8d-40e8-a61b-fd3f8d9cf7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "reviews_df.show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|sentiment_label|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+\n",
            "|616719923X| [0, 0]|    4.0|Just another flav...| 06 1, 2013|A1VEELTKS8NLZB|     Amazon Customer|          Good Taste|    1370044800|       Positive|\n",
            "|616719923X| [0, 1]|    3.0|I bought this on ...|05 19, 2014|A14R9XMZVJ6INB|             amf0001|3.5 stars,  sadly...|    1400457600|       Negative|\n",
            "|616719923X| [3, 4]|    4.0|Really good. Grea...| 10 8, 2013|A27IQHDZFQFNGG|             Caitlin|                Yum!|    1381190400|       Positive|\n",
            "|616719923X| [0, 0]|    5.0|I had never had i...|05 20, 2013|A31QY5TASILE89|        DebraDownSth|Unexpected flavor...|    1369008000|       Positive|\n",
            "|616719923X| [1, 2]|    4.0|I've been looking...|05 26, 2013|A2LWK003FFMCI5|            Diana X.|Not a very strong...|    1369526400|       Positive|\n",
            "|616719923X| [0, 1]|    4.0|These Kit-kats ar...| 09 5, 2013|A1NZJTY0BAA2SK|           Elizabeth|              Subtle|    1378339200|       Positive|\n",
            "|616719923X| [1, 2]|    3.0|I found these in ...|10 18, 2013| AA95FYFIP38RM|Emily Veinglory \"...|Available in some...|    1382054400|       Negative|\n",
            "|616719923X| [2, 3]|    5.0|Creamy white choc...| 07 5, 2013|A3FIVHUOGMUMPK|           greenlife|      So Delicious!!|    1372982400|       Positive|\n",
            "|616719923X| [0, 0]|    5.0|After hearing mix...|06 14, 2013|A27FSPAMTQF1J8|              Japhyl|These are my favo...|    1371168000|       Positive|\n",
            "|616719923X|[0, 10]|    1.0|I love green tea,...|09 19, 2012|A33NXNZ79H5K51|         Jean M \"JM\"|           Not a fan|    1348012800|       Negative|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdRjRT7iA3RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = reviews_df.na.drop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32hkHSki_dUy",
        "colab_type": "text"
      },
      "source": [
        "# Spark NLP Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKZA-kX_U7Fy",
        "colab_type": "text"
      },
      "source": [
        "Using example from jonsnow sparknlp\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvB1XubdqrL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use document assemble which puts data in annotaed form\n",
        "document_assembler = DocumentAssembler() \\\n",
        "                      .setInputCol(\"reviewText\") \\\n",
        "                      .setOutputCol(\"review_document\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z-2qOuiA1fn",
        "colab_type": "code",
        "outputId": "ae88ada8-f002-41f8-9851-acad9511cd9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "assembled = document_assembler.transform(reviews_df)\n",
        "assembled.select('review_document').take(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(review_document=[Row(annotatorType='document', begin=0, end=293, result=\"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=454, result=\"This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=374, result=\"This was a fairly interesting read.  It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.  I read for fun and relaxation......I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=100, result=\"I'd never read any of the Amy Brewster mysteries until this one..  So I am really hooked on them now.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=129, result='If you like period pieces - clothing, lingo, you will enjoy this mystery.  Author had me guessing at least 2/3 of the way through.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4RcNPjopw-a",
        "colab_type": "code",
        "outputId": "64ff9709-efc9-491e-b95a-6378fc56fd62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#detect sentences\n",
        "sentence_finder = SentenceDetector() \\\n",
        "    .setExplodeSentences(False) \\\n",
        "    .setInputCols(\"review_document\") \\\n",
        "    .setOutputCol(\"sentence\") \n",
        "sentence_data = sentence_finder.transform(assembled)\n",
        "sentence_data.select(\"sentence\").limit(5).show(truncate=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[[document, 0, 63, I enjoy vintage books and movies so I enjoyed reading this book., [sentence -> 0], [], []], [document, 66, 86, The plot was unusual., [sentence -> 1], [], []], [document, 89, 293, Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me., [sentence -> 2], [], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|[[document, 0, 36, This book is a reissue of an old one;, [sentence -> 0], [], []], [document, 38, 65, the author was born in 1910., [sentence -> 1], [], []], [document, 67, 102, It's of the era of, say, Nero Wolfe., [sentence -> 2], [], []], [document, 104, 201, The introduction was quite interesting, explaining who the author was and why he's been forgotten;, [sentence -> 3], [], []], [document, 203, 292, I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;, [sentence -> 4], [], []], [document, 293, 299, heater., [sentence -> 5], [], []], [document, 300, 304, &#34;, [sentence -> 6], [], []], [document, 307, 378, I also made good use of my Fire's dictionary to look up words like &#34;, [sentence -> 7], [], []], [document, 379, 393, deshabille&#34;, [sentence -> 8], [], []], [document, 395, 403, and &#34;, [sentence -> 9], [], []], [document, 404, 412, Canarsie., [sentence -> 10], [], []], [document, 413, 417, &#34;, [sentence -> 11], [], []], [document, 419, 454, Still, it was well worth a look-see., [sentence -> 12], [], []]]|\n",
            "|[[document, 0, 34, This was a fairly interesting read., [sentence -> 0], [], []], [document, 37, 141, It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage., [sentence -> 1], [], []], [document, 144, 173, I read for fun and relaxation., [sentence -> 2], [], []], [document, 174, 174, ., [sentence -> 3], [], []], [document, 175, 175, ., [sentence -> 4], [], []], [document, 176, 176, ., [sentence -> 5], [], []], [document, 177, 177, ., [sentence -> 6], [], []], [document, 178, 178, ., [sentence -> 7], [], []], [document, 179, 374, I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language., [sentence -> 8], [], []]]                                                                                                                                                                                                                                                                                 |\n",
            "|[[document, 0, 63, I'd never read any of the Amy Brewster mysteries until this one., [sentence -> 0], [], []], [document, 64, 64, ., [sentence -> 1], [], []], [document, 67, 100, So I am really hooked on them now., [sentence -> 2], [], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "|[[document, 0, 72, If you like period pieces - clothing, lingo, you will enjoy this mystery., [sentence -> 0], [], []], [document, 75, 129, Author had me guessing at least 2/3 of the way through., [sentence -> 1], [], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhC29_VIICcl",
        "colab_type": "code",
        "outputId": "6eaa7b48-4c37-4a80-e6ed-b5f8841c4a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "first_obs = sentence_data.select('sentence') \\\n",
        "      .limit(1)\n",
        "first_obs_df = first_obs.select('sentence', F.explode(first_obs.sentence).alias('_sentence'))\n",
        "first_obs_df.toPandas()[['_sentence']]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(document, 0, 63, I enjoy vintage books and mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(document, 66, 86, The plot was unusual., {'se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(document, 89, 293, Don't think killing someon...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           _sentence\n",
              "0  (document, 0, 63, I enjoy vintage books and mo...\n",
              "1  (document, 66, 86, The plot was unusual., {'se...\n",
              "2  (document, 89, 293, Don't think killing someon..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uczEzYxQJVJ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f80452ee-808c-4c7a-db79-e564e79d8bf1"
      },
      "source": [
        "#Tokenize\n",
        "tokenizer = Tokenizer() \\\n",
        "              .setInputCols(['sentence']) \\\n",
        "              .setOutputCol('token')\n",
        "token_data = tokenizer.fit(sentence_data).transform(sentence_data)\n",
        "token_data.take(5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_corrupt_record=None, asin='B000F83SZQ', helpful=[0, 0], overall=5.0, reviewText=\"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", reviewTime='05 5, 2014', reviewerID='A1F6404F1VG29J', reviewerName='Avidreader', summary='Nice vintage story', unixReviewTime=1399248000, review_document=[Row(annotatorType='document', begin=0, end=293, result=\"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])], sentence=[Row(annotatorType='document', begin=0, end=63, result='I enjoy vintage books and movies so I enjoyed reading this book.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=66, end=86, result='The plot was unusual.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=89, end=293, result=\"Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[])], token=[Row(annotatorType='token', begin=0, end=0, result='I', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=2, end=6, result='enjoy', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=8, end=14, result='vintage', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=16, end=20, result='books', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=22, end=24, result='and', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=26, end=31, result='movies', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=33, end=34, result='so', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=36, end=36, result='I', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=38, end=44, result='enjoyed', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=46, end=52, result='reading', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=54, end=57, result='this', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=59, end=62, result='book', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=63, end=63, result='.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=66, end=68, result='The', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=70, end=73, result='plot', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=75, end=77, result='was', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=79, end=85, result='unusual', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=86, end=86, result='.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=89, end=93, result=\"Don't\", metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=95, end=99, result='think', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=101, end=107, result='killing', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=109, end=115, result='someone', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=117, end=118, result='in', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=120, end=131, result='self-defense', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=133, end=135, result='but', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=137, end=143, result='leaving', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=145, end=147, result='the', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=149, end=153, result='scene', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=155, end=157, result='and', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=159, end=161, result='the', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=163, end=166, result='body', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=168, end=174, result='without', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=176, end=184, result='notifying', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=186, end=188, result='the', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=190, end=195, result='police', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=197, end=198, result='or', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=200, end=206, result='hitting', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=208, end=214, result='someone', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=216, end=217, result='in', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=219, end=221, result='the', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=223, end=225, result='jaw', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=227, end=228, result='to', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=230, end=234, result='knock', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=236, end=239, result='them', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=241, end=243, result='out', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=245, end=249, result='would', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=251, end=254, result='wash', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=256, end=266, result='today.Still', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=268, end=269, result='it', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=271, end=273, result='was', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=275, end=275, result='a', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=277, end=280, result='good', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=282, end=285, result='read', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=287, end=289, result='for', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=291, end=292, result='me', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=293, end=293, result='.', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(_corrupt_record=None, asin='B000F83SZQ', helpful=[2, 2], overall=4.0, reviewText=\"This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\", reviewTime='01 6, 2014', reviewerID='AN0N05A9LIJEQ', reviewerName='critters', summary='Different...', unixReviewTime=1388966400, review_document=[Row(annotatorType='document', begin=0, end=454, result=\"This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])], sentence=[Row(annotatorType='document', begin=0, end=36, result='This book is a reissue of an old one;', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=38, end=65, result='the author was born in 1910.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=67, end=102, result=\"It's of the era of, say, Nero Wolfe.\", metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=104, end=201, result=\"The introduction was quite interesting, explaining who the author was and why he's been forgotten;\", metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=203, end=292, result=\"I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;\", metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=293, end=299, result='heater.', metadata={'sentence': '5'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=300, end=304, result='&#34;', metadata={'sentence': '6'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=307, end=378, result=\"I also made good use of my Fire's dictionary to look up words like &#34;\", metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=379, end=393, result='deshabille&#34;', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=395, end=403, result='and &#34;', metadata={'sentence': '9'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=404, end=412, result='Canarsie.', metadata={'sentence': '10'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=413, end=417, result='&#34;', metadata={'sentence': '11'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=419, end=454, result='Still, it was well worth a look-see.', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[])], token=[Row(annotatorType='token', begin=0, end=3, result='This', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=5, end=8, result='book', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=10, end=11, result='is', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=13, end=13, result='a', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=15, end=21, result='reissue', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=23, end=24, result='of', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=26, end=27, result='an', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=29, end=31, result='old', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=33, end=35, result='one', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=36, end=36, result=';', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=38, end=40, result='the', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=42, end=47, result='author', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=49, end=51, result='was', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=53, end=56, result='born', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=58, end=59, result='in', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=61, end=64, result='1910', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=65, end=65, result='.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=67, end=70, result=\"It's\", metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=72, end=73, result='of', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=75, end=77, result='the', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=79, end=81, result='era', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=83, end=84, result='of', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=85, end=85, result=',', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=87, end=89, result='say', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=90, end=90, result=',', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=92, end=95, result='Nero', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=97, end=101, result='Wolfe', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=102, end=102, result='.', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=104, end=106, result='The', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=108, end=119, result='introduction', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=121, end=123, result='was', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=125, end=129, result='quite', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=131, end=141, result='interesting', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=142, end=142, result=',', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=144, end=153, result='explaining', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=155, end=157, result='who', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=159, end=161, result='the', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=163, end=168, result='author', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=170, end=172, result='was', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=174, end=176, result='and', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=178, end=180, result='why', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=182, end=185, result=\"he's\", metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=187, end=190, result='been', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=192, end=200, result='forgotten', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=201, end=201, result=';', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=203, end=205, result=\"I'd\", metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=207, end=211, result='never', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=213, end=217, result='heard', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=219, end=220, result='of', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=222, end=228, result='him.The', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=230, end=237, result='language', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=239, end=240, result='is', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=242, end=242, result='a', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=244, end=249, result='little', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=251, end=255, result='dated', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=257, end=258, result='at', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=260, end=264, result='times', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=265, end=265, result=',', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=267, end=270, result='like', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=272, end=278, result='calling', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=280, end=280, result='a', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=282, end=284, result='gun', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=286, end=286, result='a', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=288, end=291, result='&#34', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=292, end=292, result=';', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=293, end=298, result='heater', metadata={'sentence': '5'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=299, end=299, result='.', metadata={'sentence': '5'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=300, end=303, result='&#34', metadata={'sentence': '6'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=304, end=304, result=';', metadata={'sentence': '6'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=307, end=307, result='I', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=309, end=312, result='also', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=314, end=317, result='made', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=319, end=322, result='good', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=324, end=326, result='use', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=328, end=329, result='of', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=331, end=332, result='my', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=334, end=339, result=\"Fire's\", metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=341, end=350, result='dictionary', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=352, end=353, result='to', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=355, end=358, result='look', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=360, end=361, result='up', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=363, end=367, result='words', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=369, end=372, result='like', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=374, end=377, result='&#34', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=378, end=378, result=';', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=379, end=392, result='deshabille&#34', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=393, end=393, result=';', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=395, end=397, result='and', metadata={'sentence': '9'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=399, end=402, result='&#34', metadata={'sentence': '9'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=403, end=403, result=';', metadata={'sentence': '9'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=404, end=411, result='Canarsie', metadata={'sentence': '10'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=412, end=412, result='.', metadata={'sentence': '10'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=413, end=416, result='&#34', metadata={'sentence': '11'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=417, end=417, result=';', metadata={'sentence': '11'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=419, end=423, result='Still', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=424, end=424, result=',', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=426, end=427, result='it', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=429, end=431, result='was', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=433, end=436, result='well', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=438, end=442, result='worth', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=444, end=444, result='a', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=446, end=453, result='look-see', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=454, end=454, result='.', metadata={'sentence': '12'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(_corrupt_record=None, asin='B000F83SZQ', helpful=[2, 2], overall=4.0, reviewText=\"This was a fairly interesting read.  It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.  I read for fun and relaxation......I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.\", reviewTime='04 4, 2014', reviewerID='A795DMNCJILA6', reviewerName='dot', summary='Oldie', unixReviewTime=1396569600, review_document=[Row(annotatorType='document', begin=0, end=374, result=\"This was a fairly interesting read.  It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.  I read for fun and relaxation......I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])], sentence=[Row(annotatorType='document', begin=0, end=34, result='This was a fairly interesting read.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=37, end=141, result=\"It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.\", metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=144, end=173, result='I read for fun and relaxation.', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=174, end=174, result='.', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=175, end=175, result='.', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=176, end=176, result='.', metadata={'sentence': '5'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=177, end=177, result='.', metadata={'sentence': '6'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=178, end=178, result='.', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=179, end=374, result='I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[])], token=[Row(annotatorType='token', begin=0, end=3, result='This', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=5, end=7, result='was', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=9, end=9, result='a', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=11, end=16, result='fairly', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=18, end=28, result='interesting', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=30, end=33, result='read', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=34, end=34, result='.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=37, end=38, result='It', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=40, end=42, result='had', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=44, end=46, result='old', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=47, end=47, result='-', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=49, end=53, result='style', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=55, end=67, result='terminology.I', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=69, end=71, result='was', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=73, end=76, result='glad', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=78, end=79, result='to', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=81, end=83, result='get', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=86, end=87, result='to', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=89, end=92, result='read', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=94, end=94, result='a', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=96, end=100, result='story', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=102, end=105, result='that', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=107, end=113, result=\"doesn't\", metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=115, end=118, result='have', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=120, end=125, result='coarse', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=126, end=126, result=',', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=128, end=140, result='crasslanguage', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=141, end=141, result='.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=144, end=144, result='I', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=146, end=149, result='read', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=151, end=153, result='for', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=155, end=157, result='fun', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=159, end=161, result='and', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=163, end=172, result='relaxation', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=173, end=173, result='.', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=174, end=174, result='.', metadata={'sentence': '3'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=175, end=175, result='.', metadata={'sentence': '4'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=176, end=176, result='.', metadata={'sentence': '5'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=177, end=177, result='.', metadata={'sentence': '6'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=178, end=178, result='.', metadata={'sentence': '7'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=179, end=179, result='I', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=181, end=184, result='like', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=186, end=188, result='the', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=190, end=193, result='free', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=195, end=207, result='ebooksbecause', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=209, end=209, result='I', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=211, end=213, result='can', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=215, end=219, result='check', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=221, end=223, result='out', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=225, end=225, result='a', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=227, end=232, result='writer', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=234, end=236, result='and', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=238, end=243, result='decide', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=245, end=246, result='if', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=248, end=251, result='they', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=253, end=255, result='are', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=257, end=277, result='intriguing,innovative', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=278, end=278, result=',', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=280, end=282, result='and', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=284, end=287, result='have', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=289, end=294, result='enough', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=296, end=297, result='of', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=299, end=301, result='the', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=303, end=309, result='command', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=311, end=312, result='of', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=314, end=324, result='Englishthat', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=326, end=329, result='they', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=331, end=333, result='can', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=335, end=340, result='convey', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=342, end=344, result='the', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=346, end=350, result='story', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=352, end=358, result='without', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=360, end=364, result='crude', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=366, end=373, result='language', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=374, end=374, result='.', metadata={'sentence': '8'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(_corrupt_record=None, asin='B000F83SZQ', helpful=[1, 1], overall=5.0, reviewText=\"I'd never read any of the Amy Brewster mysteries until this one..  So I am really hooked on them now.\", reviewTime='02 19, 2014', reviewerID='A1FV0SX13TWVXQ', reviewerName='Elaine H. Turley \"Montana Songbird\"', summary='I really liked it.', unixReviewTime=1392768000, review_document=[Row(annotatorType='document', begin=0, end=100, result=\"I'd never read any of the Amy Brewster mysteries until this one..  So I am really hooked on them now.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])], sentence=[Row(annotatorType='document', begin=0, end=63, result=\"I'd never read any of the Amy Brewster mysteries until this one.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=64, end=64, result='.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=67, end=100, result='So I am really hooked on them now.', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[])], token=[Row(annotatorType='token', begin=0, end=2, result=\"I'd\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=4, end=8, result='never', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=10, end=13, result='read', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=15, end=17, result='any', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=19, end=20, result='of', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=22, end=24, result='the', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=26, end=28, result='Amy', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=30, end=37, result='Brewster', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=39, end=47, result='mysteries', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=49, end=53, result='until', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=55, end=58, result='this', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=60, end=62, result='one', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=63, end=63, result='.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=64, end=64, result='.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=67, end=68, result='So', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=70, end=70, result='I', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=72, end=73, result='am', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=75, end=80, result='really', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=82, end=87, result='hooked', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=89, end=90, result='on', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=92, end=95, result='them', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=97, end=99, result='now', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=100, end=100, result='.', metadata={'sentence': '2'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(_corrupt_record=None, asin='B000F83SZQ', helpful=[0, 1], overall=4.0, reviewText='If you like period pieces - clothing, lingo, you will enjoy this mystery.  Author had me guessing at least 2/3 of the way through.', reviewTime='03 19, 2014', reviewerID='A3SPTOKDG7WBLN', reviewerName='Father Dowling Fan', summary='Period Mystery', unixReviewTime=1395187200, review_document=[Row(annotatorType='document', begin=0, end=129, result='If you like period pieces - clothing, lingo, you will enjoy this mystery.  Author had me guessing at least 2/3 of the way through.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])], sentence=[Row(annotatorType='document', begin=0, end=72, result='If you like period pieces - clothing, lingo, you will enjoy this mystery.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='document', begin=75, end=129, result='Author had me guessing at least 2/3 of the way through.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[])], token=[Row(annotatorType='token', begin=0, end=1, result='If', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=3, end=5, result='you', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=7, end=10, result='like', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=12, end=17, result='period', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=19, end=24, result='pieces', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=26, end=26, result='-', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=28, end=35, result='clothing', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=36, end=36, result=',', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=38, end=42, result='lingo', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=43, end=43, result=',', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=45, end=47, result='you', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=49, end=52, result='will', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=54, end=58, result='enjoy', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=60, end=63, result='this', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=65, end=71, result='mystery', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=72, end=72, result='.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=75, end=80, result='Author', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=82, end=84, result='had', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=86, end=87, result='me', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=89, end=96, result='guessing', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=98, end=99, result='at', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=101, end=105, result='least', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=107, end=109, result='2/3', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=111, end=112, result='of', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=114, end=116, result='the', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=118, end=120, result='way', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=122, end=128, result='through', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[]), Row(annotatorType='token', begin=129, end=129, result='.', metadata={'sentence': '1'}, embeddings=[], sentence_embeddings=[])])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzGEAhHnN0ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "64f82830-2897-41b1-a4d2-b1ab6148c04b"
      },
      "source": [
        "#Normalize\n",
        "normalizer = Normalizer() \\\n",
        "                .setInputCols([\"token\"]) \\\n",
        "                .setOutputCol('normed_token')\n",
        "normalizer_data = normalizer.fit(token_data).transform(token_data)\n",
        "normalizer_data.show(5)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+----------+-------+-------+--------------------+-----------+--------------+--------------------+------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|_corrupt_record|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|           summary|unixReviewTime|     review_document|            sentence|               token|        normed_token|\n",
            "+---------------+----------+-------+-------+--------------------+-----------+--------------+--------------------+------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|           null|B000F83SZQ| [0, 0]|    5.0|I enjoy vintage b...| 05 5, 2014|A1F6404F1VG29J|          Avidreader|Nice vintage story|    1399248000|[[document, 0, 29...|[[document, 0, 63...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|\n",
            "|           null|B000F83SZQ| [2, 2]|    4.0|This book is a re...| 01 6, 2014| AN0N05A9LIJEQ|            critters|      Different...|    1388966400|[[document, 0, 45...|[[document, 0, 36...|[[token, 0, 3, Th...|[[token, 0, 3, Th...|\n",
            "|           null|B000F83SZQ| [2, 2]|    4.0|This was a fairly...| 04 4, 2014| A795DMNCJILA6|                 dot|             Oldie|    1396569600|[[document, 0, 37...|[[document, 0, 34...|[[token, 0, 3, Th...|[[token, 0, 3, Th...|\n",
            "|           null|B000F83SZQ| [1, 1]|    5.0|I'd never read an...|02 19, 2014|A1FV0SX13TWVXQ|Elaine H. Turley ...|I really liked it.|    1392768000|[[document, 0, 10...|[[document, 0, 63...|[[token, 0, 2, I'...|[[token, 0, 1, Id...|\n",
            "|           null|B000F83SZQ| [0, 1]|    4.0|If you like perio...|03 19, 2014|A3SPTOKDG7WBLN|  Father Dowling Fan|    Period Mystery|    1395187200|[[document, 0, 12...|[[document, 0, 72...|[[token, 0, 1, If...|[[token, 0, 1, If...|\n",
            "+---------------+----------+-------+-------+--------------------+-----------+--------------+--------------------+------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEw2dYAzTRZF",
        "colab_type": "code",
        "outputId": "e4b92cd2-f17d-48db-e278-a52f4b524933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# -N new only\n",
        "# -P set directory\n",
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt -P /tmp"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-09 07:46:12--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.249.246\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.249.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4862966 (4.6M) [text/plain]\n",
            "Saving to: ‘/tmp/words.txt’\n",
            "\n",
            "words.txt           100%[===================>]   4.64M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-09 07:46:13 (43.2 MB/s) - ‘/tmp/words.txt’ saved [4862966/4862966]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x84UyLOHOkoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check Spelling\n",
        "spell_check = NorvigSweetingApproach() \\\n",
        "                .setInputCols(['normed_token']) \\\n",
        "                .setOutputCol('spell_checked') \\\n",
        "                .setDictionary(\"/tmp/words.txt\")\n",
        "spell_check_data = spell_check.fit(normalizer_data).transform(normalizer_data)\n",
        "spell_check_data.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlh-BpEmPGpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentiment\n",
        "sentiment_analyzer = ViveknSentimentApproach() \\\n",
        "                      .setInputCols(['spell_checked', 'sentence']) \\\n",
        "                      .setOutputCol('sentiment') \\\n",
        "                      .setPruneCorpus(0) \\\n",
        "                      .setSentimentCol('sentiment_label')\n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFcDzo4RQstJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"sentiment\"]) \\\n",
        "    .setIncludeMetadata(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzqy7NcrQvr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_pipe = Pipeline(stages=[\n",
        "                                  document_assembler,\n",
        "                                  sentence_finder,\n",
        "                                  tokenizer,\n",
        "                                  normalizer,\n",
        "                                  spell_check,\n",
        "                                  sentiment_analyzer,\n",
        "                                  finisher\n",
        "                                  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKuHFMLFQ9nN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2368f27-c1c0-4002-89a5-6cb75381867e"
      },
      "source": [
        "review_sentiment_model = sentiment_pipe.fit(reviews_df)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-49928eba1d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreview_sentiment_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o270.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 26.0 failed 1 times, most recent failure: Lost task 3.0 in stage 26.0 (TID 75, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAnnotate$1: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>,sentence_embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>,sentence_embeddings:array<float>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.IllegalArgumentException: Illegal group reference\n\tat java.util.regex.Matcher.appendReplacement(Matcher.java:857)\n\tat scala.util.matching.Regex$Replacement$class.replace(Regex.scala:804)\n\tat scala.util.matching.Regex$MatchIterator$$anon$1.replace(Regex.scala:782)\n\tat scala.util.matching.Regex$$anonfun$replaceAllIn$1.apply(Regex.scala:473)\n\tat scala.util.matching.Regex$$anonfun$replaceAllIn$1.apply(Regex.scala:473)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.util.matching.Regex.replaceAllIn(Regex.scala:473)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$2.apply(RuleFactory.scala:64)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$2.apply(RuleFactory.scala:63)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory.com$johnsnowlabs$nlp$util$regex$RuleFactory$$transformMatch(RuleFactory.scala:143)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4$$anonfun$apply$25.apply(RuleFactory.scala:95)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4$$anonfun$apply$25.apply(RuleFactory.scala:95)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4.apply(RuleFactory.scala:95)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4.apply(RuleFactory.scala:87)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory.transformWithSymbolicRules(RuleFactory.scala:162)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.PragmaticContentFormatter.formatBetweenPunctuations(PragmaticContentFormatter.scala:147)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.DefaultPragmaticMethod.extractBounds(PragmaticMethod.scala:50)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector.tag(SentenceDetector.scala:33)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector$$anonfun$2.apply(SentenceDetector.scala:62)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector$$anonfun$2.apply(SentenceDetector.scala:62)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector.annotate(SentenceDetector.scala:62)\n\tat com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:35)\n\tat com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:34)\n\t... 22 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)\n\tat org.apache.spark.sql.Dataset$$anonfun$collect$1.apply(Dataset.scala:2788)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:2788)\n\tat com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach.train(NorvigSweetingApproach.scala:60)\n\tat com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach.train(NorvigSweetingApproach.scala:11)\n\tat com.johnsnowlabs.nlp.AnnotatorApproach.fit(AnnotatorApproach.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAnnotate$1: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>,sentence_embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>,sentence_embeddings:array<float>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.IllegalArgumentException: Illegal group reference\n\tat java.util.regex.Matcher.appendReplacement(Matcher.java:857)\n\tat scala.util.matching.Regex$Replacement$class.replace(Regex.scala:804)\n\tat scala.util.matching.Regex$MatchIterator$$anon$1.replace(Regex.scala:782)\n\tat scala.util.matching.Regex$$anonfun$replaceAllIn$1.apply(Regex.scala:473)\n\tat scala.util.matching.Regex$$anonfun$replaceAllIn$1.apply(Regex.scala:473)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.util.matching.Regex.replaceAllIn(Regex.scala:473)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$2.apply(RuleFactory.scala:64)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$2.apply(RuleFactory.scala:63)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory.com$johnsnowlabs$nlp$util$regex$RuleFactory$$transformMatch(RuleFactory.scala:143)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4$$anonfun$apply$25.apply(RuleFactory.scala:95)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4$$anonfun$apply$25.apply(RuleFactory.scala:95)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4.apply(RuleFactory.scala:95)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory$$anonfun$4.apply(RuleFactory.scala:87)\n\tat com.johnsnowlabs.nlp.util.regex.RuleFactory.transformWithSymbolicRules(RuleFactory.scala:162)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.PragmaticContentFormatter.formatBetweenPunctuations(PragmaticContentFormatter.scala:147)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.DefaultPragmaticMethod.extractBounds(PragmaticMethod.scala:50)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector.tag(SentenceDetector.scala:33)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector$$anonfun$2.apply(SentenceDetector.scala:62)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector$$anonfun$2.apply(SentenceDetector.scala:62)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)\n\tat com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector.annotate(SentenceDetector.scala:62)\n\tat com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:35)\n\tat com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:34)\n\t... 22 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAlXT4QXuHPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_sentiment_data = review_sentiment_model.transform(reviews_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vonsa9lTtKro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_sentiment_data.show(n=5, truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucxbmYp3YIgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_pipe2 = LightPipeline(sentiment_pipe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiogQ-pa9tv2",
        "colab_type": "text"
      },
      "source": [
        "# Using pretrained pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzPKzbtdRjRd",
        "colab_type": "code",
        "outputId": "e8f85756-5e0b-4f0a-9a2f-b9118f569bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "prepipe = PretrainedPipeline(name='analyze_sentiment')\n",
        "result = prepipe.annotate(target=reviews_df, column=\"reviewText\")\n",
        "result.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      asin|helpful|overall|                text| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|sentiment_label|            document|            sentence|               token|             checked|           sentiment|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|616719923X| [0, 0]|    4.0|Just another flav...| 06 1, 2013|A1VEELTKS8NLZB|     Amazon Customer|          Good Taste|    1370044800|       Positive|[[document, 0, 16...|[[document, 0, 74...|[[token, 0, 3, Ju...|[[token, 0, 3, Ju...|[[sentiment, 0, 7...|\n",
            "|616719923X| [0, 1]|    3.0|I bought this on ...|05 19, 2014|A14R9XMZVJ6INB|             amf0001|3.5 stars,  sadly...|    1400457600|       Negative|[[document, 0, 58...|[[document, 0, 12...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 1...|\n",
            "|616719923X| [3, 4]|    4.0|Really good. Grea...| 10 8, 2013|A27IQHDZFQFNGG|             Caitlin|                Yum!|    1381190400|       Positive|[[document, 0, 10...|[[document, 0, 11...|[[token, 0, 5, Re...|[[token, 0, 5, Re...|[[sentiment, 0, 1...|\n",
            "|616719923X| [0, 0]|    5.0|I had never had i...|05 20, 2013|A31QY5TASILE89|        DebraDownSth|Unexpected flavor...|    1369008000|       Positive|[[document, 0, 14...|[[document, 0, 62...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 6...|\n",
            "|616719923X| [1, 2]|    4.0|I've been looking...|05 26, 2013|A2LWK003FFMCI5|            Diana X.|Not a very strong...|    1369526400|       Positive|[[document, 0, 60...|[[document, 0, 12...|[[token, 0, 3, I'...|[[token, 0, 3, I'...|[[sentiment, 0, 1...|\n",
            "|616719923X| [0, 1]|    4.0|These Kit-kats ar...| 09 5, 2013|A1NZJTY0BAA2SK|           Elizabeth|              Subtle|    1378339200|       Positive|[[document, 0, 14...|[[document, 0, 10...|[[token, 0, 4, Th...|[[token, 0, 4, Th...|[[sentiment, 0, 1...|\n",
            "|616719923X| [1, 2]|    3.0|I found these in ...|10 18, 2013| AA95FYFIP38RM|Emily Veinglory \"...|Available in some...|    1382054400|       Negative|[[document, 0, 29...|[[document, 0, 10...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 1...|\n",
            "|616719923X| [2, 3]|    5.0|Creamy white choc...| 07 5, 2013|A3FIVHUOGMUMPK|           greenlife|      So Delicious!!|    1372982400|       Positive|[[document, 0, 41...|[[document, 0, 81...|[[token, 0, 5, Cr...|[[token, 0, 5, dr...|[[sentiment, 0, 8...|\n",
            "|616719923X| [0, 0]|    5.0|After hearing mix...|06 14, 2013|A27FSPAMTQF1J8|              Japhyl|These are my favo...|    1371168000|       Positive|[[document, 0, 41...|[[document, 0, 72...|[[token, 0, 4, Af...|[[token, 0, 4, Af...|[[sentiment, 0, 7...|\n",
            "|616719923X|[0, 10]|    1.0|I love green tea,...|09 19, 2012|A33NXNZ79H5K51|         Jean M \"JM\"|           Not a fan|    1348012800|       Negative|[[document, 0, 10...|[[document, 0, 69...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 6...|\n",
            "|616719923X| [6, 8]|    5.0|I ordered these i...| 10 2, 2013|A220GN2X2R47JE|              Jeremy|            Amazing!|    1380672000|       Positive|[[document, 0, 32...|[[document, 0, 10...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 1...|\n",
            "|616719923X| [2, 3]|    5.0|These are definit...|05 26, 2013|A3C5Z05IKSSFB9|M. Magpoc \"malias...|I wish I could fi...|    1369526400|       Positive|[[document, 0, 14...|[[document, 0, 49...|[[token, 0, 4, Th...|[[token, 0, 4, Th...|[[sentiment, 0, 4...|\n",
            "|616719923X| [0, 0]|    5.0|Yes - this is one...| 07 6, 2013| AHA6G4IMEMAJR|    M. Zinn \"mczinn\"|Thank goodness th...|    1373068800|       Positive|[[document, 0, 29...|[[document, 0, 86...|[[token, 0, 2, Ye...|[[token, 0, 2, Ye...|[[sentiment, 0, 8...|\n",
            "|616719923X| [0, 0]|    5.0|I love the green ...| 06 8, 2013|A1Q2E3W9PRG313|             Sabrina|          it is good|    1370649600|       Positive|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 1...|\n",
            "|616719923X| [0, 0]|    3.0|I love Kit Kat & ...|09 26, 2013|A1P3PLYYMURAV1|               Sunny|                 Meh|    1380153600|       Negative|[[document, 0, 11...|[[document, 0, 26...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 2...|\n",
            "|616719923X| [0, 0]|    4.0|I tried this for ...|07 19, 2013|A38IEZF0P3ZUQJ|The Fallen Angel ...|Not enough Matcha...|    1374192000|       Positive|[[document, 0, 30...|[[document, 0, 14...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 1...|\n",
            "|9742356831| [0, 0]|    5.0|This curry paste ...|05 28, 2013|A23RYWDS884TUL|       Another Freak|          Delicious!|    1369699200|       Positive|[[document, 0, 20...|[[document, 0, 40...|[[token, 0, 3, Th...|[[token, 0, 3, Th...|[[sentiment, 0, 4...|\n",
            "|9742356831| [1, 2]|    5.0|I've purchased di...|09 17, 2012| A945RBQWGZXCK|              Cheryl|        Great flavor|    1347840000|       Positive|[[document, 0, 31...|[[document, 0, 10...|[[token, 0, 3, I'...|[[token, 0, 3, I'...|[[sentiment, 0, 1...|\n",
            "|9742356831| [2, 2]|    5.0|I love ethnic foo...| 08 3, 2013|A1TCSC0YWT82Q0|             GinSing|OMG! What a treas...|    1375488000|       Positive|[[document, 0, 50...|[[document, 0, 36...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 3...|\n",
            "|9742356831| [1, 1]|    4.0|I started a new d...|01 23, 2014|A3AMNY44OP8AOU|        Jennifer Lee|       Tastes great!|    1390435200|       Positive|[[document, 0, 27...|[[document, 0, 49...|[[token, 0, 0, I,...|[[token, 0, 0, I,...|[[sentiment, 0, 4...|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYXGNIY1xU7l",
        "colab_type": "code",
        "outputId": "1dc62960-da1c-451b-dc8c-25658c412fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "spark.createDataFrame(result.select('sentiment').take(1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-e937467d5855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchemaFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_merge_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some of types cannot be determined after inferring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Some of types cannot be determined after inferring"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zaBuqMLZkeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.select('sentiment').show(truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lmpJSsMuUFO",
        "colab_type": "code",
        "outputId": "1f6480b0-28ef-41ec-a4af-bdc11b0eb175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "result.withColumn('avg_sentiment', \n",
        "                  F.when(F.col('sentiment')['result']==F.lit('positive'), F.lit((1,1))) \\\n",
        "                         .otherwise((0,1)) \\\n",
        "                         .reduce(lambda x, y: (x[0]+y[0], x[1]+y[1])) \\\n",
        "                         .mapValues(lambda x: x[0]/x[1])) \\\n",
        "      .show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-ab84b0b8092c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m result.withColumn('avg_sentiment', \n\u001b[0;32m----> 2\u001b[0;31m                   \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                          \u001b[0;34m.\u001b[0m\u001b[0motherwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          .mapValues(lambda x: x[0]/x[1])) \\\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.sql.functions.lit.\n: java.lang.RuntimeException: Unsupported literal type class java.util.ArrayList [1, 1]\n\tat org.apache.spark.sql.catalyst.expressions.Literal$.apply(literals.scala:78)\n\tat org.apache.spark.sql.catalyst.expressions.Literal$$anonfun$create$2.apply(literals.scala:164)\n\tat org.apache.spark.sql.catalyst.expressions.Literal$$anonfun$create$2.apply(literals.scala:164)\n\tat scala.util.Try.getOrElse(Try.scala:79)\n\tat org.apache.spark.sql.catalyst.expressions.Literal$.create(literals.scala:163)\n\tat org.apache.spark.sql.functions$.typedLit(functions.scala:127)\n\tat org.apache.spark.sql.functions$.lit(functions.scala:110)\n\tat org.apache.spark.sql.functions.lit(functions.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGZx8xY9QgA-",
        "colab_type": "code",
        "outputId": "890beef5-0e0a-426f-d2e1-783908430ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "result.withColumn(\"sent_mean\", lambda x: x[\"sentiment\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-44195e873081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sent_mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \"\"\"\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: col should be Column"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG8ZPyXx4IWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.withColumn(\"exploded_sent\", F.explode(F.col(\"sentiment\"))).select(\"exploded_sent\").printSchema()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw8b7kwfzYfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "schema = StructType([StructField])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wD3T0VRBZC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result2 = result \\\n",
        "  .withColumn(\"reviewID\", F.monotonically_increasing_id()) \\\n",
        "  .withColumn(\"exploded_sent\", F.explode(F.col(\"sentiment\"))) \\\n",
        "  .select([\"exploded_sent.*\", \"overall\", \"sentiment_label\", \"reviewID\"])\n",
        "result2.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Glh7sjCg7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result2.printSchema()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmvBMRWjC4t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result2 = result2.withColumn(\"id\", F.monotonically_increasing_id())\n",
        "result2.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC6G3ljITPyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result3 = result2 \\\n",
        "  .withColumn(\"numerical_result\", F.when(result2[\"result\"] == \"Positive\", 1).otherwise(0)) \\\n",
        "  .groupBy([\"ID\", \"overall\", \"sentiment_label\"]) \\\n",
        "  .agg(F.mean(\"numerical_result\").alias(\"result_mean\")) \\\n",
        "  .show(truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZytky8n9vnr",
        "colab_type": "text"
      },
      "source": [
        "## Timeseries Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRvUxh819vHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_df = (review_sentiment_data\n",
        "         .withColumn(rev_date, col(\"unixReviewTime\").cast(\"DateType\")\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HMsxiz22UxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGUHjJnD1iuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFYIxiEJdOZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}