{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "* Shannon Entropy $H$, defined as: $ H = -\\sum_{i=1}^n P(x_i)log_2 P(x_i) $  \n",
    "    * decreases as number of possible outcomes decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do:\n",
    "conda install -c anaconda graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "* Downsides:\n",
    "    * ramdomness in generation, which can lead to variance in estimates. Also not built same way each time.\n",
    "    * **they are incredibly prone to overfitting**, especially if  deep or complex. \n",
    "    * Because they work from info gain, they are biased towards the dominant class, so **balanced data is needed**.\n",
    "* ID3 algorithm\n",
    "    * requirements:\n",
    "        * binary outcome\n",
    "        * categorical features\n",
    "    * splits on the most valuable attribute (causes largest drop of H) in each feature\n",
    "* Random forests\n",
    "    * create many trees and use them to vote\n",
    "    * uses bagging to get better diversity\n",
    "    * uses random subspace - only uses some of the features on each tree\n",
    "        * generally for a dataset with x features $\\sqrt{x}$ features are used for classifiers and $x/3$ for regression.\n",
    "    * only works on test values that are within the training values\n",
    "    * black box algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVMs)\n",
    "* __S__upport __V__ector __C__lassifiers\n",
    "* builds hyperplane\n",
    "    * A hyperplane in n-dimensional space is an (n-1)-dimensional space.\n",
    "* soft margin in when can't classify observations on one side or the other\n",
    "    * SVC deals with this by cost function:\n",
    "        * maximize margin size vs \n",
    "        * minimize cumulative distance of points on wrong side from boundary\n",
    "* kernel trick \n",
    "    * unrelated to computer kernels\n",
    "    * kernels map data to space using weights. eg kernel smoothing.\n",
    "    * in SVM a kernel is a function that implicitly computes the dot product between two vectors in a higher-dimensional space without actually transforming the vectors into that space.\n",
    "    * additional reading:\n",
    "        * post [post by Eric Kim](http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html), \n",
    "        * then this [paper by Martin Hoffman](http://www.cogsys.wiai.uni-bamberg.de/teaching/ss06/hs_svm/slides/SVM_Seminarbericht_Hofmann.pdf). \n",
    "        * This [hour lecture from Patrick Winston](https://www.youtube.com/watch?v=_PwhiWxHK8o) is a good short-breathed derivation of everything you've covered in SVM so far. \n",
    "        * If you don't have a good intuition of why dot products are important, check out this [video by Sal Khan](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/dot-cross-products/v/vector-dot-product-and-vector-length) from Khan Academy's linear algebra sequence.\n",
    "    * kernel choice\n",
    "        * default kernel - radial basis function, which uses a Gaussian decay according to the distance from the original point. \n",
    "        * other kernels: choose if [geometry justifies](https://stats.stackexchange.com/a/18032)\n",
    "        * can use cross validation in training set, but if tuning other hyperparameters, can be time consuming\n",
    "* SVM extensions\n",
    "    * simplest: hold-on-out on each classification (class vs all others), get confidence estimate for each, and classification with highest estimate (based on distance to boundary and classifier accuracy) wins\n",
    "    * pairwise boundaries; classification based on highest 1-vs-1 wins count\n",
    "* __S__upport __V__ector __R__egression\n",
    "    * works in reverse: penalty based on distance from far points\n",
    "    * parameters\n",
    "        * C: box constraint and sets the penalty for being outside of our margin. \n",
    "        * Epsilon: sets the size of our margin. \n",
    "    * advantage: can set sensitivity before model creation, not just after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meshgrid example\n",
    "Used for SVC or KNN classifier  \n",
    "Example for 22.2\n",
    "```\n",
    "# Visualize our model\n",
    "y_min, y_max = X.test.min() - 1, X.test.max() + 3\n",
    "x_min, x_max = X.project.min() - 1, X.project.max() + 3\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .1),\n",
    "                     np.arange(y_min, y_max, .1))\n",
    "\n",
    "Z = (svm.predict(np.c_[xx.ravel(), yy.ravel()])=='pass')\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "plt.scatter(test_data.project[0:10], test_data.test[0:10], marker='x')\n",
    "plt.scatter(test_data.project[10:20], test_data.test[10:20], marker='o')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xlabel('Project Grade')\n",
    "plt.ylabel('Test Grade')\n",
    "plt.title('Passing Grades SVM Example')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "* very popular for use\n",
    "* boosting models vary by:\n",
    "    * Type of simple model; almost any work.\n",
    "    * Index of error. You can use residuals from regression, classification errors, or any cost function.\n",
    "    * How the next iteration targets the error. You can weight inaccurately-predicted cases high and accurately-predicted cases low, you can directly model residuals, or you can model only the subset of the data that was inaccurately predicted.\n",
    "    * Stopping rule. You can stop once you've run a certain number of models, once the amount of variance explained by the most recent iteration of the model is lower than some threshold, or once the change in weights between the two most recent model iterations is lower than some threshold.\n",
    "* Gradient boosting can work on any combination of loss function and model type, as long as we can calculate the derivatives of the loss function with respect to the model parameters. \n",
    "* for regression trees:\n",
    "    * minimize $\\frac1{n}\\sum_{i=1}^n(y_i-(\\alpha + \\beta x_i))^2$\n",
    "    * takes residual of previous weak learner tree and tries to predict that. loop.\n",
    "    * often better than random forests, and less prone to overfitting that individual trees.\n",
    "        * can also subsample, so each iteration only gets part of the data\n",
    "        * can use shrinkage (a la Ridge regr) to lower impact of subsequent submodels\n",
    "            * learning rate 0 means only final combined model matters,\n",
    "            * learning rate 1 - all weighted equally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble models\n",
    "\n",
    "   * made up of other models\n",
    "   * types:\n",
    "       * bagging aka \"boostrap aggregating\" -drawing with replacement\n",
    "       * boosting - serial models daisy-chained together\n",
    "       * multiple models as first step, then output of these used as input for final model. Combination of other two methods\n",
    "    * \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation, leakage, etc.\n",
    "* training - 80% of subset. don't use training error. \n",
    "* validation - used to select hyperparameters or model type.\n",
    "* testing - held out data used to see how good model is. \n",
    "* kfold\n",
    "    * Cross validation samples without replacement\n",
    "    * Boostrap - samples ___with___ replacement\n",
    "    * used to get multiple estimates of prediction error which can be averaged. \n",
    "* sequence:\n",
    "    * determine hyperparameters with grid/random search \n",
    "        * picks set of hyperparameters for training subset, finds parameters, and validates on remaining. \n",
    "        * returns best hyperparameters.\n",
    "    * retrain on entire training dataset to get parametrs ?\n",
    "    * get error estimate on test data \n",
    "    * put into production\n",
    "* nested cross-validation:\n",
    "    * outer loop creates inner loops\n",
    "    * inner loops \n",
    "        * multiple times through the data set, setting aside different 20% for validation. \n",
    "        * Each time:\n",
    "            * Using the 80%, run grid/random search to repeatedly find parameter for each set of hypers, and choose best hypers.\n",
    "        * then you get average \n",
    "    * outer loop through multiple instances of:\n",
    "        use inner loops to find hypers. train on whole 'inner train&test' set and test again held out data.\n",
    "    * hopefully the best hypers found are close or identical. if not, it is an instability problem, although if multiple hypers are yeilding similar results, they may simply be unimportant.\n",
    "    * probably unneeded on classifiers with few parameters, or for random forest, SVM with Gaussian kernel, and gradient boosting machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
