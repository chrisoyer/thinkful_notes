{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy doesn't have mode function\n",
    "import statistics\n",
    "statistics.mode(df['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "# Using built-in Python functionality.\n",
    "sum(df['age']) / len(df['age'])\n",
    "\n",
    "# Using NumPy\n",
    "import numpy as np\n",
    "np.mean(df['age'])\n",
    "\n",
    "# median\n",
    "\n",
    "# Vanilla Python, using the built-in statistics module.\n",
    "import statistics\n",
    "statistics.median(df['age'])\n",
    "\n",
    "# Using NumPy.\n",
    "import numpy as np\n",
    "np.median(df['age'])\n",
    "\n",
    "# Return the mode using the statistics module.\n",
    "import statistics\n",
    "statistics.mode(df['age'])\n",
    "\n",
    "#variance\n",
    "v = sum((x - mean) ** 2) / (n - 1)\n",
    "df['age'].var()\n",
    "np.var(df.age)\n",
    "\n",
    "#standard deviation\n",
    "st_dev = variance ** 0.5\n",
    "np.std(df['age'], ddof=1) #this is for SAMPLE st dev. population does not require delta degrees of freedom parameter\n",
    "\n",
    "#standard error of the mean\n",
    "se = st_dev / (n ** 0.5)\n",
    "np.std(df['age'] ,ddof=1) / np.sqrt(len(df['age']))\n",
    "\n",
    "#\n",
    "value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantile-quantile (QQ) plots  \n",
    "\n",
    "should be straight line from bottom left to top right. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pop1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f92d39c333cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#instead of .head() can use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpop1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#if something returns too many returns:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pop1' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "#instead of .head() can use \n",
    "pop1[0:30]\n",
    "\n",
    "#if something returns too many returns:\n",
    "statistic_value= ttest_ind(sampn1000_frpop1_q2a, sampn1000_frpop2_q2a, equal_var=False)\n",
    "print(statistic_value)\n",
    "\n",
    "# this returns Ttest_indResult(statistic=-29.91690729062344, pvalue=1.2827399562260494e-162)\n",
    "\n",
    "\n",
    "statistic_value= ttest_ind(sampn1000_frpop1_q2a, sampn1000_frpop2_q2a, equal_var=False)\n",
    "print(statistic_value)\n",
    "\n",
    "#Then can use \n",
    "statistic_value= ttest_ind(sampn1000_frpop1_q2a, sampn1000_frpop2_q2a, equal_var=False).pvalue\n",
    "statistic_value= ttest_ind(sampn1000_frpop1_q2a, sampn1000_frpop2_q2a, equal_var=False)[1]\n",
    "\n",
    "# or \n",
    "test_value[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on small groups: \n",
    "Similar to how unusual two-dimensional datapoints could skew our analysis, groups with very small variances relative to other groups and groups with a very small number of observations can also mislead us. Hence, we should keep in mind interpreting the differences for small groups should be done cautiously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P value is AUC, on one tail or both.   \n",
    "Scaled on t statistic (or z) AND the Degrees of Freedom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test will return a chi-square test statistic and a p-value. Like the t-test,\n",
    "# the chi-square is compared against a distribution (the chi-square\n",
    "# distribution) to determine whether the group size differences are large\n",
    "# enough to reflect differences in the population.\n",
    "print(stats.chisquare(count_table, axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforms\n",
    "transformations such as taking the square root, the inverse, or the log of the variable; or by applying the Box-Cox transformation.  These only work when all datapoints are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normality\n",
    "A normal distribution has a skew of zero (i.e. it’s perfectly symmetrical around the mean) and a kurtosis of three; kurtosis tells you how much data is in the tails and gives you an idea about how “peaked” the distribution is.\n",
    "\n",
    "Jarque-Bera Test tests normality of distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Normalization is the rescaling of a variable into the [0,1] range (including 0 and 1). For this purpose, we'll use SKLearn's `.normalize()` method from the `preprocessing` module.\n",
    "2. Standardization is the rescaling of a variable so its mean becomes 0 and its standard deviation becomes 1. Notice in the standardization we don't apply a maximum value for the variable. To apply standardization, we'll use SKLearn's `.scale()` method from the `preprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests\n",
    "\n",
    "__Sensitivity__ is the percentage of positives correctly identified, in our case 198/747 or 27%. This shows how good we are at catching positives, or how sensitive our model is to identifying positives.\n",
    "\n",
    "__Specificity__ is just the opposite, the percentage of negatives correctly identified, 4770/4825 or 99%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Predicted No</th>\n",
       "      <th>Predicted Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual No</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Actual Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted No Predicted Yes\n",
       "1   Actual No                           \n",
       "2  Actual Yes                           "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix\n",
    "import pandas as pd\n",
    "confusion = [['', 'Predicted No', 'Predicted Yes'],\n",
    "             ['Actual No', '', ''],\n",
    "             ['Actual Yes', '', '']]\n",
    "confusion_df = pd.DataFrame(confusion)\n",
    "confusion_df = confusion_df.rename(columns=confusion_df.iloc[0]).drop(confusion_df.index[0])\n",
    "confusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "    *ROC considers all quadrants, but is problematic on imbalanced classes\n",
    "    *AUROC includes irrelevant info\n",
    "    *Precision-Recall Curve works better for imbalanced classes, but doesn't consider all quadrants\n",
    "    *Matthew Correlation coefficient [-1,1] considers all quads and handles imbalaned classification\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "2 \n",
      "fizz \n",
      "4 \n",
      "buzz \n",
      "fizz \n",
      "7 \n",
      "8 \n",
      "fizz \n",
      "buzz \n",
      "11 \n",
      "fizz \n",
      "13 \n",
      "14 \n",
      "fizz \n",
      "16 \n",
      "17 \n",
      "fizz \n",
      "19 \n",
      "buzz \n",
      "fizz \n",
      "22 \n",
      "23 \n",
      "fizz \n",
      "buzz \n",
      "26 \n",
      "fizz \n",
      "28 \n",
      "29 \n",
      "fizz \n",
      "31 \n",
      "32 \n",
      "fizz \n",
      "34 \n",
      "buzz \n",
      "fizz \n",
      "37 \n",
      "38 \n",
      "fizz \n",
      "buzz \n",
      "41 \n",
      "fizz \n",
      "43 \n",
      "44 \n",
      "fizz \n",
      "46 \n",
      "47 \n",
      "fizz \n",
      "49 \n",
      "buzz\n"
     ]
    }
   ],
   "source": [
    "def fizzbuzzer(max=50):\n",
    "    \"\"\"print string of the children's game\"\"\"\n",
    "    print(\" \\n\".join([\n",
    "        \"{}\".format(\"fizz\" if i%3==0 \n",
    "                    else \"buzz\" if i%5==0 \n",
    "                    else \"\")\n",
    "        or str(i)\n",
    "        for i in range(1, max+1)\n",
    "    ]))\n",
    "fizzbuzzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
