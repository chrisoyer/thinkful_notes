{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Kindle_Reviews__Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisoyer/thinkful_notes/blob/master/Unit_4_Spark/Amazon_Kindle_Reviews__Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-DjJmVMsUk",
        "colab_type": "text"
      },
      "source": [
        "# Description:\n",
        "Challenge: Amazon Reviews Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haKf5PoUM5dO",
        "colab_type": "text"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K2oSl1VM4ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#environment\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds8rh3VeGIao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_CLASSPATH\"] = '/content/spark-2.4.4-bin-hadoop2.7'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGmM9NimNDY2",
        "colab_type": "code",
        "outputId": "d8394e9e-aaeb-471f-eaf0-516e24227fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 93kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=2d550684839a80827c1978316df5281d1e2d7c687f4c64688523090855dff7f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4y1rP_DIa4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName('Spark NLP') \\\n",
        "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.2.2\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njcPYngZMFw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_url = r\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_5.json.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ToghFIPT-3",
        "colab_type": "text"
      },
      "source": [
        "I will be using gDrive file location instead of downloading the source file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_5yArpRPTg9",
        "colab_type": "code",
        "outputId": "b405e298-1e6f-4f66-d003-0644f38d8d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kZfyUIEP1-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_souce_file = r\"/content/gdrive/My Drive/thinkful/colab_datasets/reviews_Grocery_and_Gourmet_Food_5.json.gz\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "APP_NAME  = \"amazon_food_reviews\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HrmTKPaPhWn",
        "colab_type": "code",
        "outputId": "313239bf-c2b4-41e9-bea3-229fa0ba2f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "!pip install spark-nlp\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from sparknlp.base import LightPipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import RegexRule\n",
        "from sparknlp.base import DocumentAssembler, Finisher\n",
        "print(\"Spark NLP version\")\n",
        "sparknlp.version()\n",
        "print(\"Apache Spark version\")\n",
        "spark.version"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/1a/711bde42e9cd17b5166a2c282ba9824103c416091c9ad95ca7dcece7170e/spark_nlp-2.2.2-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.2.2\n",
            "Spark NLP version\n",
            "2.2.2\n",
            "Apache Spark version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4B0pToj9oht",
        "colab_type": "code",
        "outputId": "0b52f19d-bc10-4e99-efc2-d896ac900135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "sparknlp.start()\n",
        "pipeline = PretrainedPipeline(name='analyze_sentiment', lang='en')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_GDMh39QKnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "# not working# !gzip -dkc $local_source_file > /content/reviews\n",
        "reviews = r'/content/gdrive/My Drive/thinkful/colab_datasets/reviews_Grocery_and_Gourmet_Food_5.json'\n",
        "reviews_df = spark.read.options(inferschema = \"true\").json(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJGgdyXHppbz",
        "colab_type": "code",
        "outputId": "f376b504-f053-4eb3-9bf3-9dec607fee09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "reviews_df.printSchema()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHRBLfUppuAq",
        "colab_type": "code",
        "outputId": "f5f99b44-d896-4038-c178-37466ce8ef08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "reviews_df.show(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|   reviewerName|             summary|unixReviewTime|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "|616719923X| [0, 0]|    4.0|Just another flav...| 06 1, 2013|A1VEELTKS8NLZB|Amazon Customer|          Good Taste|    1370044800|\n",
            "|616719923X| [0, 1]|    3.0|I bought this on ...|05 19, 2014|A14R9XMZVJ6INB|        amf0001|3.5 stars,  sadly...|    1400457600|\n",
            "|616719923X| [3, 4]|    4.0|Really good. Grea...| 10 8, 2013|A27IQHDZFQFNGG|        Caitlin|                Yum!|    1381190400|\n",
            "|616719923X| [0, 0]|    5.0|I had never had i...|05 20, 2013|A31QY5TASILE89|   DebraDownSth|Unexpected flavor...|    1369008000|\n",
            "|616719923X| [1, 2]|    4.0|I've been looking...|05 26, 2013|A2LWK003FFMCI5|       Diana X.|Not a very strong...|    1369526400|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meXz731U18UB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "89454449-30a9-40a4-f759-872ee04e31b9"
      },
      "source": [
        "reviews_df.select('overall').describe().show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|           overall|\n",
            "+-------+------------------+\n",
            "|  count|            151254|\n",
            "|   mean| 4.243041506340329|\n",
            "| stddev|1.0900026138973262|\n",
            "|    min|               1.0|\n",
            "|    max|               5.0|\n",
            "+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA260z_c3fT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = reviews_df.withColumn('sentiment_label', F.when(reviews_df[\"overall\"] >= 4, 'Positive').otherwise('Negative'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crs2GVvP5INN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "e515a2f1-10e0-4285-fb25-d2e4d541c4ed"
      },
      "source": [
        "reviews_df.show(10)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|sentiment_label|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+\n",
            "|616719923X| [0, 0]|    4.0|Just another flav...| 06 1, 2013|A1VEELTKS8NLZB|     Amazon Customer|          Good Taste|    1370044800|       Positive|\n",
            "|616719923X| [0, 1]|    3.0|I bought this on ...|05 19, 2014|A14R9XMZVJ6INB|             amf0001|3.5 stars,  sadly...|    1400457600|       Negative|\n",
            "|616719923X| [3, 4]|    4.0|Really good. Grea...| 10 8, 2013|A27IQHDZFQFNGG|             Caitlin|                Yum!|    1381190400|       Positive|\n",
            "|616719923X| [0, 0]|    5.0|I had never had i...|05 20, 2013|A31QY5TASILE89|        DebraDownSth|Unexpected flavor...|    1369008000|       Positive|\n",
            "|616719923X| [1, 2]|    4.0|I've been looking...|05 26, 2013|A2LWK003FFMCI5|            Diana X.|Not a very strong...|    1369526400|       Positive|\n",
            "|616719923X| [0, 1]|    4.0|These Kit-kats ar...| 09 5, 2013|A1NZJTY0BAA2SK|           Elizabeth|              Subtle|    1378339200|       Positive|\n",
            "|616719923X| [1, 2]|    3.0|I found these in ...|10 18, 2013| AA95FYFIP38RM|Emily Veinglory \"...|Available in some...|    1382054400|       Negative|\n",
            "|616719923X| [2, 3]|    5.0|Creamy white choc...| 07 5, 2013|A3FIVHUOGMUMPK|           greenlife|      So Delicious!!|    1372982400|       Positive|\n",
            "|616719923X| [0, 0]|    5.0|After hearing mix...|06 14, 2013|A27FSPAMTQF1J8|              Japhyl|These are my favo...|    1371168000|       Positive|\n",
            "|616719923X|[0, 10]|    1.0|I love green tea,...|09 19, 2012|A33NXNZ79H5K51|         Jean M \"JM\"|           Not a fan|    1348012800|       Negative|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdRjRT7iA3RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = reviews_df.na.drop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32hkHSki_dUy",
        "colab_type": "text"
      },
      "source": [
        "# Spark NLP Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKZA-kX_U7Fy",
        "colab_type": "text"
      },
      "source": [
        "Using example from jonsnow sparknlp\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvB1XubdqrL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use document assemble which puts data in annotaed form\n",
        "document_assembler = DocumentAssembler() \\\n",
        "                      .setInputCol(\"reviewText\") \\\n",
        "                      .setOutputCol(\"review_document\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z-2qOuiA1fn",
        "colab_type": "code",
        "outputId": "dc246385-31b2-4249-dc07-d892559b37cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "assembled = document_assembler.transform(reviews_df)\n",
        "assembled.select('review_document').take(5)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(review_document=[Row(annotatorType='document', begin=0, end=161, result='Just another flavor of Kit Kat but the taste is unique and a bit different.  The only thing that is bothersome is the price.  I thought it was a bit expensive....', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=582, result=\"I bought this on impulse and it comes from Japan,  which amused my family,  all those weird stamps and markings on the package. So that was fun.  It said it would take about a month to arrive and it did take that long.  I was hoping for a more interesting taste but to our family,  it just tasted a bit less flavorful or weaker than the standard milk chocolate kit kat.  The green tea flavor was too subtle for the sugar and it just tasted sweet. The wafers were very crispy, and that was good,  but it tasted a bit anemic to us.I'm happy I bought it, but don't need to buy it again.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=105, result='Really good. Great gift for any fan of green tea! Just so expensive to purchase candy from across the sea.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=146, result='I had never had it before, was curious to see what it was like. Smooth, great subtle good flavor. I am ordering more and plan to make it a routine.', metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])]),\n",
              " Row(review_document=[Row(annotatorType='document', begin=0, end=602, result=\"I've been looking forward to trying these after hearing about how popular they were in Japan, and among Kit Kat fans as well. I do not recommend ordering these during warm weather, because they can melt and become smushy. I ordered mine right when summer began, and they were a bit mushy so I let them solidify under room temp. Afterwards, I tried some and they tasted fine. I was expecting a stronger green tea or matcha flavor, but it is actually quite subtle. The outer coating was creamy and not overly sugary, which I liked. Overall, I wouldn't say it's insanely good, but definitely a yummy treat.\", metadata={'sentence': '0'}, embeddings=[], sentence_embeddings=[])])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4RcNPjopw-a",
        "colab_type": "code",
        "outputId": "82a9726d-4a87-48e3-c0c8-4aff2e70d233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#detect sentences\n",
        "sentence_finder = SentenceDetector() \\\n",
        "    .setExplodeSentences(False) \\\n",
        "    .setInputCols(\"review_document\") \\\n",
        "    .setOutputCol(\"sentence\") \n",
        "sentence_data = sentence_finder.transform(assembled)\n",
        "sentence_data.select(\"sentence\").limit(5).show(truncate=False)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[[document, 0, 74, Just another flavor of Kit Kat but the taste is unique and a bit different., [sentence -> 0], [], []], [document, 77, 123, The only thing that is bothersome is the price., [sentence -> 1], [], []], [document, 126, 158, I thought it was a bit expensive., [sentence -> 2], [], []], [document, 159, 159, ., [sentence -> 3], [], []], [document, 160, 160, ., [sentence -> 4], [], []], [document, 161, 161, ., [sentence -> 5], [], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|[[document, 0, 126, I bought this on impulse and it comes from Japan,  which amused my family,  all those weird stamps and markings on the package., [sentence -> 0], [], []], [document, 128, 143, So that was fun., [sentence -> 1], [], []], [document, 146, 217, It said it would take about a month to arrive and it did take that long., [sentence -> 2], [], []], [document, 220, 368, I was hoping for a more interesting taste but to our family,  it just tasted a bit less flavorful or weaker than the standard milk chocolate kit kat., [sentence -> 3], [], []], [document, 371, 445, The green tea flavor was too subtle for the sugar and it just tasted sweet., [sentence -> 4], [], []], [document, 447, 582, The wafers were very crispy, and that was good,  but it tasted a bit anemic to us.I'm happy I bought it, but don't need to buy it again., [sentence -> 5], [], []]]                                                                       |\n",
            "|[[document, 0, 11, Really good., [sentence -> 0], [], []], [document, 13, 48, Great gift for any fan of green tea!, [sentence -> 1], [], []], [document, 50, 105, Just so expensive to purchase candy from across the sea., [sentence -> 2], [], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|[[document, 0, 62, I had never had it before, was curious to see what it was like., [sentence -> 0], [], []], [document, 64, 96, Smooth, great subtle good flavor., [sentence -> 1], [], []], [document, 98, 146, I am ordering more and plan to make it a routine., [sentence -> 2], [], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "|[[document, 0, 124, I've been looking forward to trying these after hearing about how popular they were in Japan, and among Kit Kat fans as well., [sentence -> 0], [], []], [document, 126, 220, I do not recommend ordering these during warm weather, because they can melt and become smushy., [sentence -> 1], [], []], [document, 222, 326, I ordered mine right when summer began, and they were a bit mushy so I let them solidify under room temp., [sentence -> 2], [], []], [document, 328, 373, Afterwards, I tried some and they tasted fine., [sentence -> 3], [], []], [document, 375, 461, I was expecting a stronger green tea or matcha flavor, but it is actually quite subtle., [sentence -> 4], [], []], [document, 463, 528, The outer coating was creamy and not overly sugary, which I liked., [sentence -> 5], [], []], [document, 530, 602, Overall, I wouldn't say it's insanely good, but definitely a yummy treat., [sentence -> 6], [], []]]|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhC29_VIICcl",
        "colab_type": "code",
        "outputId": "866f9a03-e93e-4753-f9eb-969fb199cbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "first_obs = sentence_data.select('sentence') \\\n",
        "      .limit(1)\n",
        "first_obs_df = first_obs.select('sentence', F.explode(first_obs.sentence).alias('_sentence'))\n",
        "first_obs_df.toPandas()[['_sentence']]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(document, 0, 74, Just another flavor of Kit K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(document, 77, 123, The only thing that is bot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(document, 126, 158, I thought it was a bit ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(document, 159, 159, ., {'sentence': '3'}, [],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(document, 160, 160, ., {'sentence': '4'}, [],...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(document, 161, 161, ., {'sentence': '5'}, [],...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           _sentence\n",
              "0  (document, 0, 74, Just another flavor of Kit K...\n",
              "1  (document, 77, 123, The only thing that is bot...\n",
              "2  (document, 126, 158, I thought it was a bit ex...\n",
              "3  (document, 159, 159, ., {'sentence': '3'}, [],...\n",
              "4  (document, 160, 160, ., {'sentence': '4'}, [],...\n",
              "5  (document, 161, 161, ., {'sentence': '5'}, [],..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uczEzYxQJVJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize\n",
        "tokenizer = Tokenizer() \\\n",
        "              .setInputCols(['sentence']) \\\n",
        "              .setOutputCol('token')\n",
        "token_data = tokenizer.fit(sentence_data).transform(sentence_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzGEAhHnN0ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize\n",
        "normalizer = Normalizer() \\\n",
        "                .setInputCols([\"token\"]) \\\n",
        "                .setOutputCol('normed_token')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEw2dYAzTRZF",
        "colab_type": "code",
        "outputId": "6dadd709-93fc-4e89-955e-9c262e6b29d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# -N new only\n",
        "# -P set directory\n",
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt -P /tmp"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-14 02:08:01--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.134.221\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.134.221|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘/tmp/words.txt’ not modified on server. Omitting download.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x84UyLOHOkoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check Spelling\n",
        "spell_check = NorvigSweetingApproach() \\\n",
        "                .setInputCols(['normed_token']) \\\n",
        "                .setOutputCol('spell_checked') \\\n",
        "                .setDictionary(\"/tmp/words.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlh-BpEmPGpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sentiment\n",
        "sentiment_analyzer = ViveknSentimentApproach() \\\n",
        "                      .setInputCols(['spell_checked', 'sentence']) \\\n",
        "                      .setOutputCol('sentiment') \\\n",
        "                      .setPruneCorpus(0) \\\n",
        "                      .setSentimentCol('sentiment_label')\n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFcDzo4RQstJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"sentiment\"]) \\\n",
        "    .setIncludeMetadata(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzqy7NcrQvr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_pipe = Pipeline(stages=[\n",
        "                                  document_assembler,\n",
        "                                  sentence_finder,\n",
        "                                  tokenizer,\n",
        "                                  normalizer,\n",
        "                                  spell_check,\n",
        "                                  sentiment_analyzer,\n",
        "                                  finisher])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKuHFMLFQ9nN",
        "colab_type": "code",
        "outputId": "6acc031b-7db7-4312-b456-c2413c276c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "review_sentiment_model = sentiment_pipe.fit(reviews_df)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3029.fit.\n: java.lang.IllegalArgumentException: requirement failed: Word analysis for features cannot be empty. Set prune to false if training is small\n\tat scala.Predef$.require(Predef.scala:224)\n\tat com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentModel.setWords(ViveknSentimentModel.scala:48)\n\tat com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach.train(ViveknSentimentApproach.scala:123)\n\tat com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach.train(ViveknSentimentApproach.scala:14)\n\tat com.johnsnowlabs.nlp.AnnotatorApproach.fit(AnnotatorApproach.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-49928eba1d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreview_sentiment_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: 'requirement failed: Word analysis for features cannot be empty. Set prune to false if training is small'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAlXT4QXuHPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_sentiment_data = review_sentiment_model.transform(reviews_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vonsa9lTtKro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_sentiment_data.show(n=5, truncate=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucxbmYp3YIgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_pipe2 = LightPipeline(sentiment_pipe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzPKzbtdRjRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}