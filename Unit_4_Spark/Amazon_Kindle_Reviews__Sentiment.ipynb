{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon_Kindle_Reviews__Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisoyer/thinkful_notes/blob/master/Unit_4_Spark/Amazon_Kindle_Reviews__Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-DjJmVMsUk",
        "colab_type": "text"
      },
      "source": [
        "# Description:\n",
        "Challenge: Amazon Reviews Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haKf5PoUM5dO",
        "colab_type": "text"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K2oSl1VM4ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#environment\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGmM9NimNDY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "f7b5ece5-aacd-4103-9f65-7ecacc5d3048"
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 90kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=91c4769138bd1722ff797640de60ed8923d09cd5120c1a6ec210c4068e42f358\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njcPYngZMFw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_url = r\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Kindle_Store_5.json.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ToghFIPT-3",
        "colab_type": "text"
      },
      "source": [
        "I will be using gDrive file location instead of downloading the source file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_5yArpRPTg9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84464fea-39ea-4c72-e19d-5adb1d89c672"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kZfyUIEP1-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local_souce_file = r\"/content/gdrive/My Drive/thinkful/colab_datasets/reviews_Grocery_and_Gourmet_Food_5.json.gz\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "APP_NAME  = \"amazon_food_reviews\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HrmTKPaPhWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_GDMh39QKnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "# not working# !gzip -dkc $local_source_file > /content/reviews\n",
        "reviews = r'/content/gdrive/My Drive/thinkful/colab_datasets/reviews_Grocery_and_Gourmet_Food_5.json'\n",
        "reviews_df = spark.read.options(inferschema = \"true\").json(reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxJ7YqvqQ-Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72675e16-13f5-4575-b706-cd4664e04dd9"
      },
      "source": [
        "!file $local_source_file"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: file: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJGgdyXHppbz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "55e6a1c8-b2bd-4489-8902-68004e3f60e2"
      },
      "source": [
        "reviews_df.printSchema()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- asin: string (nullable = true)\n",
            " |-- helpful: array (nullable = true)\n",
            " |    |-- element: long (containsNull = true)\n",
            " |-- overall: double (nullable = true)\n",
            " |-- reviewText: string (nullable = true)\n",
            " |-- reviewTime: string (nullable = true)\n",
            " |-- reviewerID: string (nullable = true)\n",
            " |-- reviewerName: string (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- unixReviewTime: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHRBLfUppuAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ae0da668-cbfc-4f2e-d441-da4dc0e70587"
      },
      "source": [
        "reviews_df.show(5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "|      asin|helpful|overall|          reviewText| reviewTime|    reviewerID|   reviewerName|             summary|unixReviewTime|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "|616719923X| [0, 0]|    4.0|Just another flav...| 06 1, 2013|A1VEELTKS8NLZB|Amazon Customer|          Good Taste|    1370044800|\n",
            "|616719923X| [0, 1]|    3.0|I bought this on ...|05 19, 2014|A14R9XMZVJ6INB|        amf0001|3.5 stars,  sadly...|    1400457600|\n",
            "|616719923X| [3, 4]|    4.0|Really good. Grea...| 10 8, 2013|A27IQHDZFQFNGG|        Caitlin|                Yum!|    1381190400|\n",
            "|616719923X| [0, 0]|    5.0|I had never had i...|05 20, 2013|A31QY5TASILE89|   DebraDownSth|Unexpected flavor...|    1369008000|\n",
            "|616719923X| [1, 2]|    4.0|I've been looking...|05 26, 2013|A2LWK003FFMCI5|       Diana X.|Not a very strong...|    1369526400|\n",
            "+----------+-------+-------+--------------------+-----------+--------------+---------------+--------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvB1XubdqrL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "8d724380-e8c2-4aa4-e532-bff42cc399f2"
      },
      "source": [
        "!pip install spark-nlp\n",
        "import sparknlp\n",
        "spartnlp.start()\n",
        "pipeline = PretrainedPipeline(name='analyze_sentiment', lang='en')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp\n",
            "  Downloading https://files.pythonhosted.org/packages/f9/1a/711bde42e9cd17b5166a2c282ba9824103c416091c9ad95ca7dcece7170e/spark_nlp-2.2.2-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}