{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rfc_spark_batch_02_26_19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisoyer/thinkful_notes/blob/master/Unit_4_Spark/rfc_spark_batch_02_26_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rCwqd_Gdlx10"
      },
      "source": [
        "In this notebook, you'll learn the basics of working with Spark in batch mode to build a random forest classifier. Note that this notebook is intended to be run on Google Colaboratory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GOUD58haara",
        "colab_type": "text"
      },
      "source": [
        "## Spark and Colaboratory setup\n",
        "\n",
        "First, there's some configration specific to running Spark on Colaboratory that we'll need to attend to. Run these cells to set everything up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahlaHUHYnGcg",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65tInhQ5aarv",
        "colab_type": "code",
        "outputId": "421490a5-0ead-4800-8a64-54bfc3f63005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 119kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 50.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=fb281bded302c5cf47b9d198df72f1c959f89c3b37fdecfa7be8aaaa66a1094d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pxKUb5pnHix",
        "colab": {}
      },
      "source": [
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mil61lIqaar_",
        "colab_type": "code",
        "outputId": "9b79d078-af65-4e49-ca37-f1cb538d2480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Point Colaboratory to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cTDxREFdlx11"
      },
      "source": [
        "##  Import dependencies\n",
        "\n",
        "Next, we need to import the tools we'll need from PySpark. The imports below allow us to connect to the Spark server, load our data, clean it, and prepare, execute, and evaluate a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBIeh7Eblx12",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5PLkpx0slx15"
      },
      "source": [
        "## Set our constants\n",
        "\n",
        "Next, we create a set of constants that we can refer to throughout the notebook. These are values that the rest of our code needs to run, but that we might need to change at some point (for instance, if the location of our data changes). \n",
        "\n",
        "If you saved the relevant datasets in the folders suggested in the previous checkpoint (link), you can use the below code chunk as is. If you saved the datasets elsewhere on your Google Drive, modify the file path after the `My Drive` folder. \n",
        "\n",
        "Regardless of the exact file path, these datasets **must** be stored on Google Drive!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mqs6LIRelx16",
        "colab": {}
      },
      "source": [
        "CSV_PATH = \"/content/gdrive/My Drive/thinkful/colab_datasets/allData.csv\" \n",
        "CSV_ACTIVITY_LABEL_PATH = \"/content/gdrive/My Drive/thinkful/colab_datasets/activity_labels.csv\"\n",
        "APP_NAME = \"UCI HAR Random Forest Example\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "RANDOM_SEED = 141107\n",
        "TRAINING_DATA_RATIO = 0.8\n",
        "RF_NUM_TREES = 10\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hh1r-3Ialx19"
      },
      "source": [
        "## Connect to the server and load data\n",
        "\n",
        "Now we're ready to connect to the Spark server. We do that (relying on the constants set above) and then load our labels (loaded into `activity_labels`) and activity data (loaded into `df`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e3daglotlx19",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "activity_labels = spark.read.options(inferschema = \"true\").csv(CSV_ACTIVITY_LABEL_PATH)\n",
        "df = spark.read.options(inferschema = \"true\").csv(CSV_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-r3VQzLlx2A"
      },
      "source": [
        "## Validate the data\n",
        "\n",
        "If our data has been properly cleaned and prepared, it will meet the following criteria, which we'll verify in just a moment:\n",
        "\n",
        "* The dataframe shape should be 10,299 rows by 562 columns\n",
        "* All feature columns should be doubles. Note that one of the columns is for our labels and it will not be double.\n",
        "* There should be no nulls. This point is crucial because Spark will fail to build our vector variables for our classifier if there are any null values.\n",
        "\n",
        "Let's confirm these points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iokDZIFRlx2A",
        "outputId": "1accca0f-112e-40cb-d09d-f02d8d14f4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Confirm the dataframe shape is 10,299 rows by 562 columns\n",
        "print(f\"Dataset shape is {df.count():d} rows by {len(df.columns):d} columns.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is 10299 rows by 562 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zh9sVIqtlx2E",
        "outputId": "bc9ba03f-8121-4e39-9821-6c094f331e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Confirm that all feature columns are doubles via a list comprehension\n",
        "# We're expecting 561 of 562 here, accounting for the labels column\n",
        "double_cols = [col[0] for col in df.dtypes if col[1] == 'double']\n",
        "print(f\"{len(double_cols):d} columns out of {len(df.columns):d} total are type double.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "561 columns out of 562 total are type double.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YEA2XsDtlx2I",
        "outputId": "e384bd9f-06cc-4854-e19b-5a8b1c142d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Confirm there are no null values. We use the dataframe select method to build a \n",
        "# list that is then converted to a Python dict. This way it's easy to sum up the nulls.\n",
        "null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
        "                         for c in df.columns]).toPandas().to_dict(orient='records')\n",
        "\n",
        "print(f\"There are {sum(null_counts[0].values()):d} null values in the dataset.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 0 null values in the dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vxdcUvn7lx2L"
      },
      "source": [
        "## Set up and run our classifier in Spark\n",
        "\n",
        "After confirming our data is clean, we're ready to reshape the data and run the random forest model.\n",
        "\n",
        "In Spark, we manipulate the data to work in a Spark pipeline, define each of the steps in the pipeline, chain them together, and finally run the pipeline.\n",
        "\n",
        "Apache Spark classifiers expect 2 columns of input:\n",
        "\n",
        "1. __labels__: an indexed set of numeric variables that represent the classification from the set of features we provide.\n",
        "2. __features__: an indexed, vector variable that contains all of the feature values in each row. \n",
        "\n",
        "In order to do this, we need to create these 2 columns from our dataset - the data is there, but not yet in a format we can use for the classifier.\n",
        "\n",
        "To create the indexed labels column, we'll create a column called `indexedLabel` using the `StringIndexer` method. We use the column `_c0` as the source for our label index since that contains our labels. The column contains only one value per index.\n",
        "    \n",
        "To create the indexed features column, we'll need to do two things. First, we'll create the vector of features using the `VectorAssembler` method. To create this vector, we'll need to use all 561 numeric columns from our data frame. The vector assembler will create a new column called `features`, and each row of this column will contain a 561-element vector that is built from the 561 features in the dataset.\n",
        "\n",
        "Finally, we'll complete the data preparation by creating an indexed vector from the `features` column. We'll call this vector `indexedFeatures`.\n",
        "    \n",
        "Since the classifier expects indexed labels and an indexed vector column of data, we'll use the `indexedLabel` and `indexedFeatures` as inputs to our random forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LlRqCnRslx2M",
        "colab": {}
      },
      "source": [
        "# Generate our feature vector.\n",
        "# Note that we're doing the work on the `df` object - we don't create new dataframes, \n",
        "# just add columns to the one we already are using.\n",
        "\n",
        "# the transform method creates the column.\n",
        "\n",
        "vector_df = VectorAssembler(inputCols=double_cols, outputCol=\"features\").transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GHNhdDitlx2O"
      },
      "source": [
        "Let's confirm that the features are there. It's easy to do this in Apache Spark using the `select` and `show` methods on the dataframe.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cFL8zXBDlx2P",
        "outputId": "516052ff-7bd8-4a16-ba23-0373e248360a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "vector_df.select(\"_c0\", \"features\").show(5)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+\n",
            "|_c0|            features|\n",
            "+---+--------------------+\n",
            "|  5|[0.289,-0.0203,-0...|\n",
            "|  5|[0.278,-0.0164,-0...|\n",
            "|  5|[0.28,-0.0195,-0....|\n",
            "|  5|[0.279,-0.0262,-0...|\n",
            "|  5|[0.277,-0.0166,-0...|\n",
            "+---+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGEdZAwMQ0tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list = vector_df.select(\"_c0\").distinct().collect()\n",
        "\n",
        "import numpy as np \n",
        "  \n",
        "# function to get unique values \n",
        "def unique(list1): \n",
        "    x = np.array(list1) \n",
        "    return np.unique(x).tolist()\n",
        "data_labels = unique(label_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JuLglvQlx2S"
      },
      "source": [
        "Now we're ready to build the indexers, split our data for training and testing, define our model, and finally chain everything together into a pipeline.\n",
        "\n",
        "__It's important to note that when we execute this cell, we're not actually running our model. At this point, we're only defining its parameters__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tMHGAVylx2U",
        "colab": {}
      },
      "source": [
        "# Split the data into training and validation sets (30% held out for testing)\n",
        "(trainingData, testData) = vector_df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "\n",
        "# Build the training indexers / split data / classifier\n",
        "# first we'll generate a labelIndexer\n",
        "labelIndexer = StringIndexer(inputCol=\"_c0\", outputCol=\"indexedLabel\").fit(vector_df)\n",
        "\n",
        "# now generate the indexed feature vector\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\",\n",
        "                               maxCategories=4).fit(vector_df)\n",
        "    \n",
        "\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\n",
        "                            numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUN-wJyyvpCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xBr2bivRlx2W"
      },
      "source": [
        "This next cell runs the pipeline, delivering a trained model at the end of the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVl2IQMolx2X",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yBOhNbXPlx2Y"
      },
      "source": [
        "It is now easy to test our model and make predictions simply by using the model's `transform` method on the `testData` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AOpXWFSPlx2Z",
        "colab": {}
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkvRJ5g9q2I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions.show(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ipzFtKllx2c"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "Now we can use the MulticlassClassificationEvaluator to test the model's accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mBGcd3x_lx2d",
        "outputId": "34c40b42-4bcd-4c31-8b54-55ea04d76a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.082205\n",
            "Accuracy = 0.917795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn5WsvLwL-iB",
        "colab_type": "text"
      },
      "source": [
        "## Add two columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEFpSmVSylZf",
        "colab_type": "code",
        "outputId": "53064981-2d50-4a7c-9dd5-1df41dd77ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "activity_labels.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------------+\n",
            "|_c0|               _c1|\n",
            "+---+------------------+\n",
            "|  1|           WALKING|\n",
            "|  2|  WALKING_UPSTAIRS|\n",
            "|  3|WALKING_DOWNSTAIRS|\n",
            "|  4|           SITTING|\n",
            "|  5|          STANDING|\n",
            "|  6|            LAYING|\n",
            "+---+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GROqNerOfQi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.printSchema().show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JRsPojDd_3",
        "colab_type": "code",
        "outputId": "dd42dd10-8d1b-4867-a63e-98c4a91a0354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "data2_df = df.withColumn('all_walking', col(\"_c1\") + col(\"_c2\"))\n",
        "data2_df.select(\"all_walking\", \"_c1\", \"_c2\").show(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-----+--------+\n",
            "|        all_walking|  _c1|     _c2|\n",
            "+-------------------+-----+--------+\n",
            "|             0.2687|0.289| -0.0203|\n",
            "|             0.2616|0.278| -0.0164|\n",
            "|             0.2605| 0.28| -0.0195|\n",
            "|             0.2528|0.279| -0.0262|\n",
            "|             0.2604|0.277| -0.0166|\n",
            "|             0.2669|0.277| -0.0101|\n",
            "|             0.2594|0.279| -0.0196|\n",
            "|0.24650000000000002|0.277| -0.0305|\n",
            "|0.25520000000000004|0.277| -0.0218|\n",
            "|            0.27104|0.281|-0.00996|\n",
            "+-------------------+-----+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xyyKT8KMCim",
        "colab_type": "text"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNwxU5rVlx01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add feature scaling\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "scaler = StandardScaler(withMean=True, withStd=True, inputCol='features', outputCol='features_scaled')\n",
        "features_scaled = scaler.fit(vector_df)\n",
        "features_scaled_df = features_scaled.transform(vector_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrRgpvLWE43o",
        "colab_type": "code",
        "outputId": "cc56f1dd-34fa-48ac-da19-cbbf208dd066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "from pyspark.ml.feature import PCA\n",
        "pca = PCA(k=10, inputCol=\"features_scaled\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(features_scaled_df)\n",
        "pca_features_df = pca_model.transform(features_scaled_df)\n",
        "pca_features_df.show(5)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+----+------+------+------+------+------+------+------+------+-------+-----+-------+------+-------+-----+-------+-----+-------+-------+------+-------+-------+-----+-----+------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+------+-----+------+------+------+------+------+----+----+------+-------+------+-------+------+------+------+-------+------+------+-----+------+-----+------+------+-----+------+-------+--------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+----+----+------+------+------+------+------+------+-----+------+-----+-----+------+--------+-----+-----+-----+-------+------+------+------+-------+------+-------+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+------+-----+------+------+------+-------+------+------+------+-------+-----+------+------+-------+------+------+------+------+-----+------+-------+------+------+-------+-------+-------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+-----+-----+------+------+------+------+------+------+-------+-------+-----+------+------+-------+------+--------+-----+------+-------+------+------+-------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+-------+------+------+------+------+------+------+------+------+------+------+-------+------+-------+------+------+------+------+------+------+-----+------+------+-----+------+------+--------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+-----+-----+-----+-------+-------+------+------+-------+-------+-------+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+-----+------+-----+-----+-----+------+-----+------+------+-----+-----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+-----+-----+-----+-----+-----+-----+------+-------+------+------+------+------+------+------+------+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+------+------+------+-----+------+------+-------+-------+-------+------+------+------+-------+------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+-----+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+------+------+-------+------+------+-------+--------+------+-------+------+-----+-------+--------------------+--------------------+--------------------+\n",
            "|_c0|  _c1|    _c2|   _c3|   _c4|   _c5|   _c6|   _c7|   _c8|   _c9|  _c10|  _c11|  _c12| _c13| _c14| _c15|  _c16|_c17|_c18|  _c19|  _c20|  _c21|  _c22|  _c23|  _c24|  _c25|  _c26|   _c27| _c28|   _c29|  _c30|   _c31| _c32|   _c33| _c34|   _c35|   _c36|  _c37|   _c38|   _c39| _c40| _c41|  _c42|  _c43|  _c44|  _c45|  _c46|  _c47|  _c48|  _c49| _c50|  _c51|  _c52| _c53|  _c54|  _c55|  _c56| _c57|  _c58|  _c59|  _c60|  _c61|  _c62|_c63|_c64|  _c65|   _c66|  _c67|   _c68|  _c69|  _c70|  _c71|   _c72|  _c73|  _c74| _c75|  _c76| _c77|  _c78|  _c79| _c80|  _c81|   _c82|    _c83|  _c84|  _c85|  _c86|  _c87|  _c88|  _c89|  _c90|  _c91|  _c92| _c93| _c94| _c95|  _c96|_c97|_c98|_c99| _c100| _c101| _c102| _c103| _c104| _c105|_c106| _c107|_c108|_c109| _c110|   _c111|_c112|_c113|_c114|  _c115| _c116| _c117| _c118|  _c119| _c120|  _c121|  _c122| _c123| _c124| _c125| _c126| _c127| _c128| _c129| _c130| _c131| _c132|_c133|_c134|_c135| _c136|_c137| _c138|_c139| _c140| _c141| _c142|  _c143| _c144| _c145| _c146|  _c147|_c148| _c149| _c150|  _c151| _c152| _c153| _c154| _c155|_c156| _c157|  _c158| _c159| _c160|  _c161|  _c162|  _c163| _c164| _c165| _c166| _c167| _c168| _c169| _c170| _c171| _c172|_c173|_c174|_c175| _c176|_c177|_c178|_c179| _c180| _c181| _c182| _c183| _c184| _c185|  _c186|  _c187|_c188| _c189| _c190|  _c191| _c192|   _c193|_c194| _c195|  _c196| _c197| _c198|  _c199| _c200| _c201| _c202| _c203| _c204| _c205| _c206| _c207| _c208| _c209|  _c210|  _c211|   _c212| _c213| _c214| _c215| _c216| _c217| _c218| _c219| _c220| _c221| _c222|  _c223|  _c224|   _c225| _c226| _c227| _c228| _c229| _c230| _c231| _c232|_c233| _c234| _c235|_c236| _c237| _c238|  _c239| _c240| _c241| _c242| _c243| _c244| _c245| _c246| _c247| _c248| _c249|  _c250| _c251|  _c252| _c253| _c254| _c255| _c256| _c257| _c258|_c259| _c260| _c261|_c262| _c263| _c264|   _c265| _c266| _c267| _c268| _c269| _c270| _c271| _c272| _c273| _c274| _c275| _c276| _c277| _c278| _c279| _c280| _c281|_c282| _c283| _c284| _c285| _c286| _c287| _c288| _c289| _c290| _c291|_c292|_c293|_c294|  _c295|  _c296| _c297| _c298|  _c299|  _c300|  _c301|   _c302|_c303|_c304|_c305|_c306|_c307|_c308|_c309|_c310|_c311|_c312|_c313|_c314|_c315|_c316| _c317|_c318|_c319|_c320|_c321|_c322| _c323|_c324| _c325|_c326|_c327|_c328| _c329|_c330| _c331| _c332|_c333|_c334| _c335| _c336| _c337| _c338| _c339|_c340| _c341| _c342| _c343| _c344| _c345| _c346| _c347| _c348| _c349| _c350| _c351| _c352| _c353| _c354| _c355| _c356| _c357| _c358| _c359| _c360|_c361|_c362|_c363| _c364| _c365| _c366|_c367|_c368|_c369|_c370|_c371|_c372| _c373|  _c374| _c375| _c376| _c377| _c378| _c379| _c380| _c381|_c382|_c383|_c384|_c385|_c386|_c387| _c388|_c389|_c390|_c391|_c392| _c393|_c394|_c395|_c396|_c397| _c398|_c399|_c400|_c401|_c402|_c403|_c404|_c405|_c406|_c407|_c408|_c409| _c410|_c411|_c412|_c413|_c414|_c415| _c416| _c417|_c418|_c419|_c420| _c421|_c422|_c423| _c424| _c425| _c426| _c427| _c428| _c429| _c430| _c431| _c432| _c433| _c434| _c435| _c436| _c437| _c438| _c439|_c440|_c441|_c442| _c443| _c444| _c445| _c446| _c447| _c448|_c449| _c450| _c451|  _c452|  _c453|  _c454| _c455| _c456| _c457|  _c458| _c459| _c460|_c461|_c462|_c463|_c464|_c465|_c466|_c467|_c468|_c469|_c470|_c471|_c472|_c473|_c474| _c475|_c476|_c477|_c478|_c479|_c480| _c481| _c482|_c483|_c484|_c485| _c486|_c487|_c488|_c489|_c490|_c491|_c492|_c493|_c494| _c495|_c496|_c497|_c498|_c499| _c500|_c501|_c502| _c503| _c504| _c505| _c506| _c507| _c508| _c509| _c510| _c511| _c512|  _c513| _c514| _c515| _c516| _c517| _c518| _c519| _c520| _c521|_c522| _c523|_c524| _c525|_c526| _c527| _c528| _c529| _c530| _c531| _c532| _c533| _c534| _c535| _c536| _c537| _c538|  _c539| _c540| _c541| _c542| _c543| _c544| _c545| _c546| _c547|_c548| _c549| _c550| _c551|  _c552| _c553| _c554|  _c555|   _c556| _c557|  _c558| _c559|_c560|  _c561|            features|     features_scaled|        pca_features|\n",
            "+---+-----+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+----+------+------+------+------+------+------+------+------+-------+-----+-------+------+-------+-----+-------+-----+-------+-------+------+-------+-------+-----+-----+------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+------+-----+------+------+------+------+------+----+----+------+-------+------+-------+------+------+------+-------+------+------+-----+------+-----+------+------+-----+------+-------+--------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+----+----+------+------+------+------+------+------+-----+------+-----+-----+------+--------+-----+-----+-----+-------+------+------+------+-------+------+-------+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+------+-----+------+------+------+-------+------+------+------+-------+-----+------+------+-------+------+------+------+------+-----+------+-------+------+------+-------+-------+-------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+-----+-----+------+------+------+------+------+------+-------+-------+-----+------+------+-------+------+--------+-----+------+-------+------+------+-------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+-------+------+------+------+------+------+------+------+------+------+------+-------+------+-------+------+------+------+------+------+------+-----+------+------+-----+------+------+--------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+-----+-----+-----+-------+-------+------+------+-------+-------+-------+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+-----+------+-----+-----+-----+------+-----+------+------+-----+-----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+-----+-----+-----+-----+-----+-----+------+-------+------+------+------+------+------+------+------+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+------+------+------+-----+------+------+-------+-------+-------+------+------+------+-------+------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+-----+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+------+------+-------+------+------+-------+--------+------+-------+------+-----+-------+--------------------+--------------------+--------------------+\n",
            "|  5|0.289|-0.0203|-0.133|-0.995|-0.983|-0.914|-0.995|-0.983|-0.924|-0.935|-0.567|-0.744|0.853|0.686|0.814|-0.966|-1.0|-1.0|-0.995|-0.994|-0.988|-0.943|-0.408|-0.679|-0.602| 0.929| -0.853| 0.36|-0.0585| 0.257| -0.225|0.264|-0.0952|0.279| -0.465|  0.492|-0.191|  0.376|  0.435|0.661|0.963|-0.141| 0.115|-0.985|-0.982|-0.878|-0.985|-0.984|-0.895|0.892|-0.161| 0.125|0.977|-0.123|0.0565|-0.375|0.899|-0.971|-0.976|-0.984|-0.989|-0.918|-1.0|-1.0| 0.114|  -0.59| 0.591| -0.592| 0.592|-0.745| 0.721| -0.712| 0.711|-0.995|0.996|-0.996|0.992|  0.57| 0.439|0.987| 0.078|  0.005| -0.0678|-0.994|-0.988|-0.994|-0.994|-0.986|-0.993|-0.985|-0.992|-0.993| 0.99|0.992|0.991|-0.994|-1.0|-1.0|-1.0|-0.994|-0.986|-0.989| -0.82|-0.793|-0.889|  1.0|-0.221|0.637|0.388| 0.241| -0.0523|0.264|0.373|0.342|  -0.57| 0.265|-0.478|-0.385| 0.0336|-0.127|-0.0061|-0.0314| 0.108|-0.985|-0.977|-0.992|-0.985|-0.976|-0.992|-0.867|-0.934|-0.748|0.847|0.915|0.831|-0.967| -1.0|-0.999| -1.0|-0.983|-0.979|-0.993| 0.0826| 0.202|-0.169|0.0963| -0.275|0.499| -0.22|   1.0| -0.973| 0.317| 0.376| 0.723|-0.771| 0.69|-0.332|   0.71| 0.135| 0.301|-0.0992|-0.0555| -0.062|-0.992|-0.993|-0.992|-0.992|-0.995|-0.993| -0.99|-0.987|-0.992|0.994|0.992|0.989|-0.994| -1.0| -1.0| -1.0|-0.992|-0.997|-0.992| -0.59|-0.688|-0.572|  0.292| -0.362|0.406|-0.039| 0.989| -0.415| 0.392|   0.282|0.927|-0.572|  0.692| 0.468|-0.131|-0.0872| 0.336|-0.959|-0.951|-0.958|-0.946|-0.993|-0.959|-0.998|-0.958|-0.233| -0.173|-0.0229|  0.0948| 0.192|-0.959|-0.951|-0.958|-0.946|-0.993|-0.959|-0.998|-0.958|-0.233| -0.173|-0.0229|  0.0948| 0.192|-0.993|-0.994|-0.995|-0.993|-0.991|-0.993| -1.0|-0.993|-0.863|0.283|-0.237|-0.105|-0.0382|-0.969|-0.964|-0.957|-0.975|-0.992|-0.969|-0.999| -0.95|0.0726| 0.573| -0.739| 0.213|  0.433|-0.994|-0.991|-0.993|-0.989|-0.993|-0.994| -1.0|-0.995| -0.62|0.293|-0.177|-0.146|  -0.124|-0.995|-0.983|-0.939|-0.995|-0.983|-0.906|-0.997|-0.985|-0.932|-0.994|-0.983|-0.885|-0.994|-0.993|-0.923|-0.975| -1.0|  -1.0|-0.995|-0.996| -0.99|-0.988|-0.946|-0.905|-0.591|  -1.0| -1.0| -1.0|0.252|  0.132|-0.0521| 0.142|-0.151| -0.221| -0.559|  0.247|-0.00742| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|-0.994|-0.999| -1.0| -1.0|-0.999|-0.998|-0.996|-0.995|-0.995| -1.0|-0.999|-0.996|-0.995|-0.999|-0.992|-0.987| -0.99|-0.996|-0.991|-0.997|-0.994|-0.991|-0.997|-0.997|-0.992|-0.993|-0.998|-0.991| -0.96|-0.991| -1.0| -1.0| -1.0|-0.993|-0.991|-0.996| -1.0| -1.0| -1.0|  1.0|-0.24| -1.0|  0.87|  0.211| 0.264|-0.704|-0.904|-0.583|-0.936|-0.507|-0.806| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|-0.999| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.987|-0.982| -0.99|-0.985|-0.974|-0.994|-0.987|-0.984|-0.992| -0.98|-0.972|-0.995|-0.998|-0.984|-0.994|-0.985| -1.0| -1.0| -1.0| -0.99|-0.995|-0.994|-0.712|-0.645|-0.839| -1.0|  -1.0|  -1.0| -0.258| 0.0979|  0.547| 0.377| 0.134| 0.273|-0.0913|-0.484|-0.783| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0|-0.998|-0.999| -1.0| -1.0| -1.0|-0.998| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.952|-0.956|-0.949|-0.974|-0.926|-0.952|-0.998|-0.973|-0.646|-0.793|-0.0884|-0.436|-0.797|-0.994|-0.994|-0.992|-0.993|-0.988|-0.994| -1.0|-0.991| -1.0|-0.937|0.347|-0.516|-0.803| -0.98|-0.961|-0.974|-0.952|-0.989| -0.98|-0.999|-0.993|-0.701|  -1.0| -0.129| 0.586| 0.375|-0.992|-0.991| -0.99|-0.992|-0.991|-0.992| -1.0| -0.99|-0.871|  -1.0|-0.0743|-0.299| -0.71| -0.113|  0.0304|-0.465|-0.0184|-0.841| 0.18|-0.0586|[0.289,-0.0203,-0...|[0.21665932344528...|[16.3801170855296...|\n",
            "|  5|0.278|-0.0164|-0.124|-0.998|-0.975| -0.96|-0.999|-0.975|-0.958|-0.943|-0.558|-0.818|0.849|0.686|0.823|-0.982|-1.0|-1.0|-0.998|-0.999|-0.978|-0.948|-0.715|-0.501|-0.571| 0.612|  -0.33|0.284|  0.285| 0.116| -0.091|0.294| -0.281|0.086|-0.0222|-0.0167|-0.221|-0.0134|-0.0727|0.579|0.967|-0.142| 0.109|-0.997|-0.989|-0.932|-0.998| -0.99|-0.933|0.892|-0.161| 0.123|0.985|-0.115| 0.103|-0.383|0.908|-0.971|-0.979|-0.999| -0.99|-0.942|-1.0|-1.0| -0.21|  -0.41| 0.414| -0.418| 0.421|-0.196| 0.125| -0.106| 0.109|-0.834|0.834|-0.834| 0.83|-0.831|-0.866|0.974| 0.074|0.00577|  0.0294|-0.996|-0.981|-0.992|-0.996|-0.979|-0.991|-0.995|-0.979|-0.992|0.993|0.992|0.989|-0.991|-1.0|-1.0|-1.0|-0.994|-0.979|-0.993|-0.875|-0.655|-0.767| 0.49| 0.071|0.363|0.527| 0.149|  0.0629| 0.37|0.414|0.122|  0.181|0.0474| 0.167|-0.209| 0.0841|-0.269|-0.0161|-0.0839| 0.101|-0.983|-0.989|-0.989|-0.987|-0.989|-0.989|-0.865|-0.954|-0.746|0.834|0.908|0.829|-0.981| -1.0|  -1.0| -1.0|-0.993|-0.989| -0.99|0.00747|-0.531|-0.177|-0.388|  0.179|0.211| -0.14|-0.047|-0.0649| 0.118|0.0817|0.0424| -0.15|0.293|-0.149| 0.0467|-0.257| 0.169| -0.111|-0.0448|-0.0592| -0.99|-0.997|-0.994| -0.99|-0.997|-0.994|-0.992|-0.998|-0.995| 0.99|0.997|0.995|-0.995| -1.0| -1.0| -1.0|-0.991|-0.997|-0.994|-0.601|-0.748|-0.609| -0.193|-0.0674|0.186|0.0415|0.0724|-0.0354| 0.178|  0.0275|0.183|-0.167|  0.253| 0.132| 0.294|-0.0181|-0.343|-0.979|-0.976|-0.978|-0.979|-0.995|-0.979|-0.999|-0.981|-0.442| 0.0816| -0.109|   0.312|-0.412|-0.979|-0.976|-0.978|-0.979|-0.995|-0.979|-0.999|-0.981|-0.442| 0.0816| -0.109|   0.312|-0.412|-0.991|-0.992|-0.993|-0.989|-0.991|-0.991| -1.0|-0.993| -0.82|0.459|-0.245|0.0561| -0.458|-0.981|-0.984|-0.982|-0.985|-0.992|-0.981|  -1.0|-0.983|-0.193|-0.225|-0.0171| 0.156| 0.0826|-0.995|-0.996|-0.996|-0.997|-0.992|-0.995| -1.0|-0.995|-0.731|0.209|-0.178|-0.103| -0.0438|-0.997|-0.977|-0.974|-0.999|-0.975|-0.955|-0.998|-0.977|-0.968|-0.999|-0.974|-0.949|-0.998|-0.993| -0.99|-0.986| -1.0|-0.999|-0.999|-0.995|-0.981|-0.986|  -1.0|-0.905|-0.758|0.0968| -1.0| -1.0|0.271| 0.0429|-0.0143|-0.693|-0.954|-0.0497| -0.332| 0.0567|  -0.289| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|-0.999| -1.0| -1.0| -1.0|-0.999| -1.0|-0.998|  -1.0| -1.0| -1.0|  -1.0|-0.999|-0.999|-0.999|-0.999| -1.0|  -1.0|-0.999|-0.999|  -1.0|-0.995|-0.981| -0.99|-0.997|-0.982|-0.993|-0.995|-0.983|-0.992|-0.997|-0.985|-0.993|-0.998|-0.983|-0.987| -0.99| -1.0| -1.0| -1.0|-0.993|-0.985|-0.991| -1.0| -1.0| -1.0|-0.32|-0.12|-0.32| 0.609|-0.0537|0.0631| -0.63| -0.91|-0.414|-0.851|-0.656|-0.916| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.977|-0.993| -0.99|-0.985|-0.987| -0.99|-0.979|-0.992|-0.988|-0.987|-0.985| -0.99|-0.987|-0.999|-0.994|-0.987| -1.0| -1.0| -1.0|-0.987|-0.996|-0.987|-0.611|-0.765|-0.751| -1.0|  -1.0|  -1.0|-0.0482| -0.402|-0.0682|-0.459|-0.797| 0.388|  0.149|-0.157|-0.452| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.981|-0.976|-0.976|-0.978|-0.987|-0.981|-0.999|-0.984|-0.817|  -1.0|-0.0441|-0.122| -0.45| -0.99|-0.992| -0.99|-0.994| -0.99| -0.99| -1.0|-0.991| -1.0|-0.841|0.532|-0.625|  -0.9|-0.988|-0.983|-0.983|-0.986|-0.992|-0.988|  -1.0|-0.994|-0.721|-0.949| -0.272|-0.336| -0.72|-0.996|-0.996|-0.995|-0.997|-0.994|-0.996| -1.0|-0.995|  -1.0|  -1.0|  0.158|-0.595|-0.861| 0.0535|-0.00743|-0.733|  0.704|-0.845| 0.18|-0.0543|[0.278,-0.0164,-0...|[0.05400645504448...|[15.5840886077768...|\n",
            "|  5| 0.28|-0.0195|-0.113|-0.995|-0.967|-0.979|-0.997|-0.964|-0.977|-0.939|-0.558|-0.818|0.844|0.682|0.839|-0.983|-1.0|-1.0|-0.999|-0.997|-0.965|-0.975|-0.592|-0.486|-0.571| 0.273|-0.0863|0.337| -0.165|0.0172|-0.0745|0.342| -0.333|0.239| -0.136|  0.174|-0.299| -0.125| -0.181|0.609|0.967|-0.142| 0.102|  -1.0|-0.993|-0.993|  -1.0|-0.993|-0.993|0.892|-0.164|0.0946|0.987|-0.115| 0.103|-0.402|0.909| -0.97|-0.982|  -1.0|-0.992|-0.993|-1.0|-1.0|-0.927|0.00223|0.0275|-0.0567|0.0855|-0.329| 0.271| -0.254| 0.258|-0.705|0.714|-0.723|0.729|-0.181| 0.338|0.643|0.0736| 0.0031|-0.00905|-0.991|-0.981| -0.99|-0.991|-0.979|-0.987|-0.987|-0.979|-0.992|0.988|0.992|0.989|-0.988|-1.0|-1.0|-1.0|-0.988| -0.98|-0.982|-0.754|-0.673|-0.747|0.265| 0.188|0.465|0.372|0.0827|-0.00462|0.327|0.438|0.258|   0.07| 0.187| 0.247| -0.12|  -0.11| -0.04|-0.0317| -0.102|0.0961|-0.976|-0.994|-0.986|-0.975|-0.994|-0.986|-0.865|-0.959|-0.743|0.834|0.906|0.829|-0.976| -1.0|  -1.0| -1.0|-0.972|-0.995|-0.987| -0.261|  -1.0|-0.248|-0.437|  0.239|0.145|-0.114|0.0323| -0.128| 0.115| 0.125| 0.112|-0.166|0.135| 0.184|-0.0101|0.0433|-0.351| -0.108|-0.0424|-0.0558|-0.988|-0.996|-0.992|-0.988|-0.996|-0.992|-0.993|-0.994|-0.989|0.989|0.997|0.994|-0.993| -1.0| -1.0| -1.0|-0.987|-0.995|-0.993|-0.544|-0.673|-0.588| -0.241|-0.0114|0.116|0.0896| 0.096| 0.0096|0.0951|   0.253|0.182|-0.169|  0.132|0.0082| 0.193| 0.0737|-0.315|-0.984|-0.988|-0.988|-0.986|-0.995|-0.984|  -1.0|-0.986|  -0.6|  0.038|-0.0742|   0.254|-0.296|-0.984|-0.988|-0.988|-0.986|-0.995|-0.984|  -1.0|-0.986|  -0.6|  0.038|-0.0742|   0.254|-0.296|-0.989| -0.99|-0.991|-0.989|-0.993|-0.989| -1.0| -0.99|-0.795| 0.65| -0.26|-0.128| -0.521|-0.976|-0.986|-0.984|-0.985|-0.966|-0.976|  -1.0|-0.983|-0.223|-0.227| 0.0597|0.0615| 0.0417|-0.993|-0.995|-0.995|-0.995|-0.998|-0.993| -1.0|-0.994|-0.663|0.328|-0.155|-0.221|  -0.108|-0.994|-0.973|-0.983|-0.996|-0.966|-0.977|-0.994|-0.972|-0.982|-0.998|-0.963|-0.969|-0.997| -0.99|-0.991|-0.986| -1.0|-0.999|-0.999|-0.989|-0.977|-0.981|  -1.0|-0.816|-0.814|-0.935| -1.0| -1.0|0.125|-0.0646| 0.0827|-0.727|-0.965|  0.163|-0.0922|-0.0449|  -0.288| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|-0.999| -1.0| -1.0| -1.0|-0.999| -1.0|-0.999|  -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.999| -1.0|  -1.0|  -1.0|-0.999|  -1.0|-0.991|-0.982|-0.988|-0.991|-0.981| -0.99|-0.988|-0.981|-0.988|-0.995|-0.985|-0.994|-0.997|-0.999|-0.998|-0.987| -1.0| -1.0| -1.0|-0.982|-0.985|-0.982| -1.0| -1.0| -1.0|-0.16|-0.48|-0.28| 0.115| -0.193|0.0383|-0.595|-0.924|-0.529|-0.913|-0.803| -0.98| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.975|-0.994|-0.987|-0.977|-0.993|-0.987|-0.976|-0.994|-0.985|-0.973|-0.995|-0.991|-0.988|-0.997|-0.994|-0.986| -1.0| -1.0| -1.0|-0.986|-0.995|-0.993|-0.591|-0.808|-0.751| -1.0|-0.871|  -1.0| -0.217|-0.0173| -0.111|0.0905|-0.245|-0.429| -0.813|-0.392|-0.767| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.988|-0.989|-0.986|-0.993| -0.99|-0.988|  -1.0|-0.989|-0.907|-0.862|  0.258|-0.619| -0.88|-0.989|-0.991|-0.987|-0.993|  -1.0|-0.989| -1.0|-0.987| -1.0|-0.905|0.661|-0.725|-0.929|-0.989|-0.986|-0.984|-0.991|-0.996|-0.989|  -1.0|-0.993|-0.737|-0.795| -0.213|-0.535|-0.872|-0.995|-0.995|-0.995|-0.996|-0.996|-0.995| -1.0|-0.994|  -1.0|-0.556|  0.415|-0.391| -0.76| -0.119|   0.178| 0.101|  0.809|-0.849|0.181|-0.0491|[0.28,-0.0195,-0....|[0.08357970384463...|[15.4273201112631...|\n",
            "|  5|0.279|-0.0262|-0.123|-0.996|-0.983|-0.991|-0.997|-0.983|-0.989|-0.939|-0.576| -0.83|0.844|0.682|0.838|-0.986|-1.0|-1.0|  -1.0|-0.997|-0.984|-0.986|-0.627|-0.851|-0.912|0.0614| 0.0748|0.198| -0.264|0.0725| -0.155|0.323| -0.171|0.295| -0.306|  0.482| -0.47| -0.306| -0.363|0.507|0.968|-0.144|0.0999|-0.997|-0.981|-0.978|-0.996|-0.981|-0.978|0.894|-0.164|0.0934|0.987|-0.121|0.0958|  -0.4|0.911|-0.969|-0.982|-0.996|-0.981| -0.98|-1.0|-1.0|-0.596|-0.0649|0.0754|-0.0858|0.0962|-0.295| 0.228| -0.206| 0.205|-0.385|0.386|-0.387|0.385|-0.991|-0.969|0.984|0.0773| 0.0201|-0.00986|-0.993|-0.988|-0.993|-0.994|-0.986|-0.991|-0.987|-0.992| -0.99|0.988|0.993|0.993|-0.993|-1.0|-1.0|-1.0|-0.995|-0.987|-0.989|-0.821|-0.755|-0.825|0.123| 0.276|0.457|0.193| 0.102| -0.0991|0.195|0.484|0.358| -0.187| 0.298| 0.452|-0.127|-0.0833| 0.457|-0.0434|-0.0914|0.0855|-0.991|-0.992|-0.988|-0.992|-0.993| -0.99|-0.885|-0.957|-0.743|0.834|0.906|0.827|-0.982| -1.0|  -1.0| -1.0|-0.991|-0.994|-0.995| -0.931|-0.827|-0.543|-0.166|-0.0129| 0.32|-0.165|0.0446| -0.125|0.0783| 0.177| 0.193|-0.207|0.112| 0.202|   0.21| 0.141|-0.725|-0.0912|-0.0363|-0.0605|-0.991|-0.997|-0.993|-0.991|-0.997|-0.994|-0.994|-0.994|-0.989|0.989|0.998|0.994|-0.995| -1.0| -1.0| -1.0|-0.991|-0.997|-0.995|-0.562|-0.731|-0.661|0.00989| -0.138|0.126| 0.316|0.0943| 0.0262|0.0697|   0.247|0.257|-0.137| 0.0873| 0.149| 0.197|   0.14|-0.306|-0.987|-0.986|-0.986|-0.986|-0.997|-0.987|  -1.0|-0.984|-0.589|-0.0929| 0.0464|-4.66E-4|0.0371|-0.987|-0.986|-0.986|-0.986|-0.997|-0.987|  -1.0|-0.984|-0.589|-0.0929| 0.0464|-4.66E-4|0.0371|-0.993|-0.993|-0.993|-0.993|-0.993|-0.993| -1.0|-0.992|-0.792|0.662|-0.247| -0.23| -0.436|-0.982|-0.987|-0.986| -0.99|-0.982|-0.982|  -1.0|-0.984|-0.241|-0.202| 0.0547|  0.11|-0.0794|-0.996|-0.995|-0.995|-0.995|-0.998|-0.996| -1.0|-0.995|-0.683|0.595|-0.265|-0.316|  -0.164|-0.995|-0.984|-0.991|-0.996|-0.983| -0.99|-0.995|-0.983|-0.989|-0.997|-0.987|-0.988|-0.994| -0.99|-0.997|-0.993| -1.0|  -1.0|  -1.0| -0.99|-0.992|-0.988|  -1.0| -0.87|-0.944|  -1.0| -1.0| -1.0|0.029| 0.0803|  0.186|-0.599|-0.908| -0.461| -0.813| -0.567|  -0.771| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.994|-0.989|-0.991|-0.991|-0.987|-0.994|-0.989|-0.987|-0.994|-0.993|-0.988|-0.994|-0.998|  -1.0|-0.965|-0.993| -1.0| -1.0| -1.0|-0.992|-0.991|-0.993| -1.0| -1.0| -1.0|-0.12|-0.56|-0.28|0.0358| -0.093| 0.168|-0.264|-0.757|-0.396| -0.83|-0.577|-0.893| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.987|-0.994|-0.987|-0.993|-0.992|-0.989| -0.99|-0.993|-0.987|-0.995|-0.992|-0.992| -0.99|-0.994|-0.993| -0.99| -1.0| -1.0| -1.0|-0.993|-0.996| -0.99|-0.724|-0.804|-0.817| -1.0|  -1.0|-0.793|  0.217| -0.135|-0.0497|-0.572|-0.874|-0.135| -0.542|-0.379|-0.757| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.988|-0.987|-0.984| -0.99|-0.998|-0.988|  -1.0|-0.983|-0.907|  -1.0| 0.0736|-0.468|-0.756|-0.993|-0.992|-0.989|-0.994|-0.996|-0.993| -1.0|-0.988| -1.0|   1.0|0.679|-0.701| -0.91|-0.989|-0.988|-0.987|-0.987|-0.996|-0.989|  -1.0|-0.989|-0.721|  -1.0|-0.0357| -0.23|-0.511|-0.995|-0.995|-0.996|-0.995|-0.996|-0.995| -1.0|-0.995|-0.956|-0.937|  0.405|-0.117|-0.483|-0.0368| -0.0129|  0.64| -0.485|-0.849|0.182|-0.0477|[0.279,-0.0262,-0...|[0.06879307944455...|[15.6484821869073...|\n",
            "|  5|0.277|-0.0166|-0.115|-0.998|-0.981| -0.99|-0.998| -0.98| -0.99|-0.942|-0.569|-0.825|0.849|0.683|0.838|-0.993|-1.0|-1.0|  -1.0|-0.998|-0.981|-0.991|-0.787|-0.559|-0.761| 0.313| -0.131|0.191| 0.0869| 0.258| -0.273|0.435| -0.315| 0.44| -0.269|  0.179|-0.089| -0.156|  -0.19|0.599|0.968|-0.149|0.0945|-0.998|-0.988|-0.979|-0.998|-0.989|-0.979|0.894|-0.167|0.0917|0.987|-0.122|0.0941|  -0.4|0.912|-0.967|-0.984|-0.998|-0.991| -0.98|-1.0|-1.0|-0.617| -0.257| 0.269| -0.281| 0.293|-0.167|0.0899|-0.0663|0.0671|-0.237|0.239|-0.241|0.241|-0.408|-0.185|0.965|0.0734| 0.0191|  0.0168|-0.996|-0.988|-0.992|-0.997|-0.987|-0.991|-0.997|-0.992| -0.99|0.994|0.993|0.986|-0.994|-1.0|-1.0|-1.0|-0.996|-0.987|-0.991|-0.851|-0.746|-0.797|0.241| 0.135|0.297|0.287| 0.319|  -0.143|0.477|0.418| 0.39|-0.0303| 0.163|  0.18|-0.273|  0.103|0.0647| -0.034|-0.0747|0.0774|-0.985|-0.992|-0.987|-0.987|-0.993|-0.988| -0.87|-0.953| -0.75|0.839|0.911|0.821|-0.985| -1.0|  -1.0| -1.0| -0.99|-0.993|-0.991| -0.629|-0.468|-0.651|-0.213|0.00211|0.388|-0.233|-0.163|  0.186|-0.435|  0.65|  0.24| -0.34|0.133| 0.473| -0.142| 0.484|-0.725|-0.0908|-0.0376|-0.0583|-0.991|-0.996|-0.995|-0.993|-0.997|-0.994| -0.98|-0.998|-0.993|0.994|0.997|0.997|-0.996| -1.0| -1.0| -1.0|-0.995|-0.997|-0.994|-0.618|-0.683|-0.633|-0.0257| -0.188|0.231|   0.2|-0.149|  0.272|-0.272|-0.00994|0.235|-0.341|-0.0857| 0.164| 0.121|  0.107|-0.283|-0.993|-0.991|-0.991|-0.991|-0.997|-0.993|  -1.0| -0.99|-0.705|   0.18| -0.278|   0.516|-0.356|-0.993|-0.991|-0.991|-0.991|-0.997|-0.993|  -1.0| -0.99|-0.705|   0.18| -0.278|   0.516|-0.356|-0.993|-0.996|-0.996|-0.993|-0.981|-0.993| -1.0|-0.997| -0.85|0.312| -0.17| 0.134| -0.458|-0.985|-0.989| -0.99|-0.987|-0.982|-0.985|  -1.0|-0.992|-0.339|-0.237| 0.0938|0.0233|  0.039|-0.996|-0.995|-0.996|-0.992|-0.992|-0.996| -1.0|-0.996| -0.72|0.332|-0.261|-0.146|-0.00737|-0.997|-0.982|-0.988|-0.999| -0.98|-0.992|-0.998|-0.982|-0.991|-0.999|-0.981|-0.989|-0.995|-0.992|-0.974|-0.992| -1.0|  -1.0|  -1.0|-0.994|-0.988|-0.986|  -1.0| -0.87|-0.944|0.0968| -1.0| -1.0|0.181|  0.058|   0.56|-0.677|-0.951|  -0.18| -0.534| -0.586|   -0.79| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0|  -1.0|  -1.0|-0.999|-0.999|  -1.0| -1.0|  -1.0|-0.999|  -1.0|  -1.0|-0.996|-0.989|-0.991|-0.997|-0.989|-0.993|-0.996|-0.989|-0.992|-0.997| -0.99|-0.995|-0.996|-0.996|-0.996|-0.993| -1.0| -1.0| -1.0|-0.996|-0.992|-0.986| -1.0| -1.0| -1.0|-0.32|-0.08| 0.04| 0.273| 0.0791| 0.292|-0.522|-0.813|-0.497|-0.904|-0.764|-0.966| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.982|-0.993|-0.989|-0.986|-0.992|-0.988|-0.983|-0.993|-0.986|-0.988|-0.993|-0.991|-0.994|-0.994|-0.995|-0.989| -1.0| -1.0| -1.0| -0.99|-0.996|-0.997|-0.653|-0.827|-0.737| -1.0|-0.806|  -1.0| -0.153|-0.0884| -0.162| -0.34|-0.723|-0.265|  -0.69|-0.268|-0.659| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.994| -0.99|-0.992|-0.991|-0.988|-0.994|  -1.0|-0.997|-0.907|  -1.0|  0.394|-0.113|-0.482|-0.996|-0.994|-0.993|-0.995|-0.982|-0.996| -1.0|-0.994| -1.0|  -1.0|0.559|-0.529|-0.859|-0.991|-0.989|-0.988|-0.991|-0.998|-0.991|  -1.0|-0.989|-0.763|-0.897| -0.274| -0.51|-0.831|-0.995|-0.995|-0.995|-0.996|-0.997|-0.995| -1.0|-0.995|  -1.0|-0.937| 0.0878|-0.351|-0.699|  0.123|   0.123| 0.694| -0.616|-0.848|0.185|-0.0439|[0.277,-0.0166,-0...|[0.03921983064441...|[15.8422450236592...|\n",
            "+---+-----+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+----+------+------+------+------+------+------+------+------+-------+-----+-------+------+-------+-----+-------+-----+-------+-------+------+-------+-------+-----+-----+------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+------+-----+------+------+------+------+------+----+----+------+-------+------+-------+------+------+------+-------+------+------+-----+------+-----+------+------+-----+------+-------+--------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+----+----+------+------+------+------+------+------+-----+------+-----+-----+------+--------+-----+-----+-----+-------+------+------+------+-------+------+-------+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+------+-----+------+------+------+-------+------+------+------+-------+-----+------+------+-------+------+------+------+------+-----+------+-------+------+------+-------+-------+-------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+-----+-----+------+------+------+------+------+------+-------+-------+-----+------+------+-------+------+--------+-----+------+-------+------+------+-------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+-------+------+------+------+------+------+------+------+------+------+------+-------+------+-------+------+------+------+------+------+------+-----+------+------+-----+------+------+--------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+-----+-----+-----+-------+-------+------+------+-------+-------+-------+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+-----+------+-----+-----+-----+------+-----+------+------+-----+-----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+-----+-----+-----+-----+-----+-----+------+-------+------+------+------+------+------+------+------+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+------+------+------+-----+------+------+-------+-------+-------+------+------+------+-------+------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+-----+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+------+------+-------+------+------+-------+--------+------+-------+------+-----+-------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj9vYWJrt6C8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_indexed = StringIndexer(inputCol=\"_c0\", \n",
        "                               outputCol=\"indexed_label\")#.fit(pca_features_df)\n",
        "features_indexed = VectorIndexer(inputCol=\"pca_features\", \n",
        "                                 outputCol=\"indexed_pca_features\")#.fit(pca_features_df)\n",
        "randomf = RandomForestClassifier(featuresCol=\"indexed_pca_features\", \n",
        "                                 labelCol=\"indexed_label\", \n",
        "                                 numTrees=RF_NUM_TREES)\n",
        "rf_wpca_pipe = Pipeline(stages=[features_scaled, pca_model, labels_indexed, features_indexed, randomf])\n",
        "\n",
        "(training_data, test_data) = (pca_features_df\n",
        "                              .select('_c0',  'features')\n",
        "                              .randomSplit([TRAINING_DATA_RATIO, 1-TRAINING_DATA_RATIO], \n",
        "                                           seed=42))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRSqLfYIOX0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf_wpca_model = rf_wpca_pipe.fit(training_data)\n",
        "pca_preds = rf_wpca_model.transform(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDPIe3MtPdZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "0f053e02-02ae-4e49-9662-022542ee444e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from pyspark.ml.classification import  OneVsRest\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "ovr = OneVsRest(classifier=rf_wpca_pipe)\n",
        "\n",
        "ovrModel = ovr.fit(train)\n",
        "# Learn to predict each class against the other\n",
        "y_score = ovrModel.fit(training_data).decision_function(test_data)\n",
        "false_positive_rate, true_positive_rate, _ = roc_curve(\n",
        "    y_true=test_data.select(\"_c0\").collect(), \n",
        "    y_score=pca_preds.select(\"probability\").collect())\n",
        "\n",
        "sns.lineplot(x=false_positive_rate, y=true_positive_rate)\n",
        "plt.plot()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-748a18cb8a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Learn to predict each class against the other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_wpca_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m false_positive_rate, true_positive_rate, _ = roc_curve(\n\u001b[1;32m      9\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_c0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# overall.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'multioutput'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_type_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             raise ValueError(\"Multioutput target data is not supported with \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[0;32m--> 241\u001b[0;31m                          'got %r' % y)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0msparseseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SparseSeries'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got DataFrame[_c0: int, features: vector]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQyTcfP97W2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "from sklearn.metrics import roc_curve\n",
        "for i in range(data_labels):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "plt.figure()\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "  for i in range(n_classes):\n",
        "      plt.plot(fpr[i], tpr[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLmp2wYq2h2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "55211904-732f-44d3-a2bb-caaa37b169a4"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "#native\n",
        "sns.lineplot(\n",
        "    x=rf_wpca_model.stages[-1].summary.roc.select('FPR').collect(),\n",
        "    y=rf_wpca_model.stages[-1].summary.roc.select('TPR').collect())\n",
        "\n",
        "# might be probabilityCol ??"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-bdc55c1fc157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#native\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m sns.lineplot(\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_wpca_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FPR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     y=rf_wpca_model.stages[-1].summary.roc.select('TPR').collect())\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassificationModel' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptgqO6EiCqTz",
        "colab_type": "text"
      },
      "source": [
        "Seems like need to implement [this](https://stackoverflow.com/questions/52847408/pyspark-extract-roc-curve) to plot multiclass roc curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDrdglv-lx2h"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "We've seen how to prepare data and build a classifier in Spark. You might want to play around with this notebook and learn more about how Spark works. Here are some ideas:\n",
        "\n",
        "- Look at the set of labels, and see if there are any features that would make sense to combine. Spark allows you to map values into a new column.\n",
        "- Identify the most important features among the 561 source features (using PCA or something similar), then reduce the feature set and see if the model performs better.\n",
        "- Modify the settings of the random forest to see if the performance improves.\n",
        "- Use Spark's tools to find other techniques to evaluate the performance of your model. See if you can figure out how to generate an ROC plot, find the AUC value, or plot a confusion matrix."
      ]
    }
  ]
}