{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rfc_spark_batch_02_26_19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisoyer/thinkful_notes/blob/master/Unit_4_Spark/rfc_spark_batch_02_26_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rCwqd_Gdlx10"
      },
      "source": [
        "In this notebook, you'll learn the basics of working with Spark in batch mode to build a random forest classifier. Note that this notebook is intended to be run on Google Colaboratory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GOUD58haara",
        "colab_type": "text"
      },
      "source": [
        "## Spark and Colaboratory setup\n",
        "\n",
        "First, there's some configration specific to running Spark on Colaboratory that we'll need to attend to. Run these cells to set everything up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahlaHUHYnGcg",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65tInhQ5aarv",
        "colab_type": "code",
        "outputId": "9c07ba8a-0050-41a1-c7b9-e81a268fd087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 103kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=1fc315a28b6a29323ceb0d3f6e51a3759ea42d399f00912234416a8dd9960377\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pxKUb5pnHix",
        "colab": {}
      },
      "source": [
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mil61lIqaar_",
        "colab_type": "code",
        "outputId": "f7cf566a-5538-4b47-e784-db6a21527dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Point Colaboratory to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cTDxREFdlx11"
      },
      "source": [
        "##  Import dependencies\n",
        "\n",
        "Next, we need to import the tools we'll need from PySpark. The imports below allow us to connect to the Spark server, load our data, clean it, and prepare, execute, and evaluate a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBIeh7Eblx12",
        "outputId": "c89293b4-646f-4b65-a061-ad1a595a271a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "import pyspark.sql.functions as F"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-359be67112ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5PLkpx0slx15"
      },
      "source": [
        "## Set our constants\n",
        "\n",
        "Next, we create a set of constants that we can refer to throughout the notebook. These are values that the rest of our code needs to run, but that we might need to change at some point (for instance, if the location of our data changes). \n",
        "\n",
        "If you saved the relevant datasets in the folders suggested in the previous checkpoint (link), you can use the below code chunk as is. If you saved the datasets elsewhere on your Google Drive, modify the file path after the `My Drive` folder. \n",
        "\n",
        "Regardless of the exact file path, these datasets **must** be stored on Google Drive!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mqs6LIRelx16",
        "colab": {}
      },
      "source": [
        "CSV_PATH = \"/content/gdrive/My Drive/thinkful/colab_datasets/allData.csv\" \n",
        "CSV_ACTIVITY_LABEL_PATH = \"/content/gdrive/My Drive/thinkful/colab_datasets/activity_labels.csv\"\n",
        "APP_NAME = \"UCI HAR Random Forest Example\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "RANDOM_SEED = 141107\n",
        "TRAINING_DATA_RATIO = 0.8\n",
        "RF_NUM_TREES = 10\n",
        "RF_MAX_DEPTH = 4\n",
        "RF_NUM_BINS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hh1r-3Ialx19"
      },
      "source": [
        "## Connect to the server and load data\n",
        "\n",
        "Now we're ready to connect to the Spark server. We do that (relying on the constants set above) and then load our labels (loaded into `activity_labels`) and activity data (loaded into `df`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e3daglotlx19",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "activity_labels = spark.read.options(inferschema = \"true\").csv(CSV_ACTIVITY_LABEL_PATH)\n",
        "df = spark.read.options(inferschema = \"true\").csv(CSV_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-r3VQzLlx2A"
      },
      "source": [
        "## Validate the data\n",
        "\n",
        "If our data has been properly cleaned and prepared, it will meet the following criteria, which we'll verify in just a moment:\n",
        "\n",
        "* The dataframe shape should be 10,299 rows by 562 columns\n",
        "* All feature columns should be doubles. Note that one of the columns is for our labels and it will not be double.\n",
        "* There should be no nulls. This point is crucial because Spark will fail to build our vector variables for our classifier if there are any null values.\n",
        "\n",
        "Let's confirm these points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iokDZIFRlx2A",
        "outputId": "bfd0f9f3-56e2-4846-e64b-60ec730066ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Confirm the dataframe shape is 10,299 rows by 562 columns\n",
        "print(f\"Dataset shape is {df.count():d} rows by {len(df.columns):d} columns.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is 10299 rows by 562 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zh9sVIqtlx2E",
        "outputId": "fe202f30-f172-49e3-d4d4-1776f009fa71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Confirm that all feature columns are doubles via a list comprehension\n",
        "# We're expecting 561 of 562 here, accounting for the labels column\n",
        "double_cols = [col[0] for col in df.dtypes if col[1] == 'double']\n",
        "print(f\"{len(double_cols):d} columns out of {len(df.columns):d} total are type double.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "561 columns out of 562 total are type double.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YEA2XsDtlx2I",
        "outputId": "b324b7a5-feed-4c5d-8bdf-1579d7855228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "# Confirm there are no null values. We use the dataframe select method to build a \n",
        "# list that is then converted to a Python dict. This way it's easy to sum up the nulls.\n",
        "null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
        "                         for c in df.columns]).toPandas().to_dict(orient='records')\n",
        "\n",
        "print(f\"There are {sum(null_counts[0].values()):d} null values in the dataset.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-94cbfa470ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                          for c in df.columns]).toPandas().to_dict(orient='records')\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There are {sum(null_counts[0].values()):d} null values in the dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n",
            "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling z:org.apache.spark.sql.functions.sum. Trace:\npy4j.Py4JException: Method sum([class java.util.ArrayList]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339)\n\tat py4j.Gateway.invoke(Gateway.java:276)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vxdcUvn7lx2L"
      },
      "source": [
        "## Set up and run our classifier in Spark\n",
        "\n",
        "After confirming our data is clean, we're ready to reshape the data and run the random forest model.\n",
        "\n",
        "In Spark, we manipulate the data to work in a Spark pipeline, define each of the steps in the pipeline, chain them together, and finally run the pipeline.\n",
        "\n",
        "Apache Spark classifiers expect 2 columns of input:\n",
        "\n",
        "1. __labels__: an indexed set of numeric variables that represent the classification from the set of features we provide.\n",
        "2. __features__: an indexed, vector variable that contains all of the feature values in each row. \n",
        "\n",
        "In order to do this, we need to create these 2 columns from our dataset - the data is there, but not yet in a format we can use for the classifier.\n",
        "\n",
        "To create the indexed labels column, we'll create a column called `indexedLabel` using the `StringIndexer` method. We use the column `_c0` as the source for our label index since that contains our labels. The column contains only one value per index.\n",
        "    \n",
        "To create the indexed features column, we'll need to do two things. First, we'll create the vector of features using the `VectorAssembler` method. To create this vector, we'll need to use all 561 numeric columns from our data frame. The vector assembler will create a new column called `features`, and each row of this column will contain a 561-element vector that is built from the 561 features in the dataset.\n",
        "\n",
        "Finally, we'll complete the data preparation by creating an indexed vector from the `features` column. We'll call this vector `indexedFeatures`.\n",
        "    \n",
        "Since the classifier expects indexed labels and an indexed vector column of data, we'll use the `indexedLabel` and `indexedFeatures` as inputs to our random forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LlRqCnRslx2M",
        "colab": {}
      },
      "source": [
        "# Generate our feature vector.\n",
        "# Note that we're doing the work on the `df` object - we don't create new dataframes, \n",
        "# just add columns to the one we already are using.\n",
        "\n",
        "# the transform method creates the column.\n",
        "\n",
        "vector_df = VectorAssembler(inputCols=double_cols, outputCol=\"features\").transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GHNhdDitlx2O"
      },
      "source": [
        "Let's confirm that the features are there. It's easy to do this in Apache Spark using the `select` and `show` methods on the dataframe.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cFL8zXBDlx2P",
        "outputId": "f61a55a4-a8d6-4c8e-e9a7-5de3c9a9452d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "vector_df.select(\"_c0\", \"features\").show(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fac916f97ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvector_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_c0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vector_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGEdZAwMQ0tp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "14b7a365-fca2-451c-9b85-683744bcc913"
      },
      "source": [
        "vector_df.select(\"_c0\").distinct().collect()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_c0=1), Row(_c0=6), Row(_c0=3), Row(_c0=5), Row(_c0=4), Row(_c0=2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7JuLglvQlx2S"
      },
      "source": [
        "Now we're ready to build the indexers, split our data for training and testing, define our model, and finally chain everything together into a pipeline.\n",
        "\n",
        "__It's important to note that when we execute this cell, we're not actually running our model. At this point, we're only defining its parameters__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tMHGAVylx2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "95429ab7-7bdd-4cef-e834-56270488c1e6"
      },
      "source": [
        "# Build the training indexers / split data / classifier\n",
        "# first we'll generate a labelIndexer\n",
        "labelIndexer = StringIndexer(inputCol=\"_c0\", outputCol=\"indexedLabel\").fit(vector_df)\n",
        "\n",
        "# now generate the indexed feature vector\n",
        "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\",\n",
        "                               maxCategories=4).fit(vector_df)\n",
        "    \n",
        "# Split the data into training and validation sets (30% held out for testing)\n",
        "(trainingData, testData) = vector_df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
        "\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\n",
        "                            numTrees=RF_NUM_TREES)\n",
        "\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-21e3b1df5b8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabelIndexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_c0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexedLabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# now generate the indexed feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\",\n\u001b[1;32m      5\u001b[0m                                maxCategories=4).fit(vector_df)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StringIndexer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xBr2bivRlx2W"
      },
      "source": [
        "This next cell runs the pipeline, delivering a trained model at the end of the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVl2IQMolx2X",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "9a7b34d3-b1df-48ae-c5e3-e540a7bd485c"
      },
      "source": [
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5d58c0b896ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yBOhNbXPlx2Y"
      },
      "source": [
        "It is now easy to test our model and make predictions simply by using the model's `transform` method on the `testData` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AOpXWFSPlx2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "dc80d1a7-81e9-4117-cb8f-d21c979234af"
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d63edce853e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkvRJ5g9q2I8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "9a49c3e8-fab9-4fbd-8247-c523be799159"
      },
      "source": [
        "predictions.show(6)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-55bb46e2c83e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ipzFtKllx2c"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "Now we can use the MulticlassClassificationEvaluator to test the model's accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mBGcd3x_lx2d",
        "outputId": "960ca5af-dda3-43c1-bc49-02371400393e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
        "print(f\"Accuracy = {accuracy:g}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.0962567\n",
            "Accuracy = 0.903743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn5WsvLwL-iB",
        "colab_type": "text"
      },
      "source": [
        "## Add two columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEFpSmVSylZf",
        "colab_type": "code",
        "outputId": "770f6b26-f10d-41d5-970a-946d25e030c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "activity_labels.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------------+\n",
            "|_c0|               _c1|\n",
            "+---+------------------+\n",
            "|  1|           WALKING|\n",
            "|  2|  WALKING_UPSTAIRS|\n",
            "|  3|WALKING_DOWNSTAIRS|\n",
            "|  4|           SITTING|\n",
            "|  5|          STANDING|\n",
            "|  6|            LAYING|\n",
            "+---+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GROqNerOfQi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.printSchema().show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5JRsPojDd_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "543c077b-d482-4c0b-a53d-08f43bde6d05"
      },
      "source": [
        "data2_df = df.withColumn('all_walking', col(\"_c1\") + col(\"_c2\"))\n",
        "data2_df.select(\"all_walking\", \"_c1\", \"_c2\").show(10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+--------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+------+------+------+------+------+------+------+------+------+-------+------+-------+------+-------+------+-------+-----+-------+-------+------+-------+-------+-----+-----+------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+------+-----+------+------+------+------+------+----+----+------+-------+------+-------+------+------+------+-------+------+------+-----+------+-----+------+-------+------+------+-------+--------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+------+----+------+------+------+------+------+------+-----+-------+-----+-------+-------+--------+------+-----+-------+-------+------+------+------+-------+------+-------+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+------+-----+------+------+------+-------+------+------+-------+-------+------+------+-------+-------+-------+-------+-------+------+------+-------+-------+------+------+-------+-------+-------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+-----+-----+------+------+------+------+------+------+-------+-------+-------+------+-------+-------+-------+--------+-------+------+--------+-------+-------+-------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+-------+------+------+------+------+------+------+------+------+------+-------+-------+--------+-------+------+------+------+------+------+------+-----+------+------+------+------+-------+-------+------+------+------+------+------+------+------+------+------+-------+-------+-------+-------+------+------+------+------+------+------+-----+------+------+-----+------+--------+--------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+-------+-------+-------+------+------+-------+-------+-------+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+-----+------+------+------+-----+------+-----+-----+-----+-----+------+-------+------+------+------+------+------+------+------+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+------+------+------+------+-----+-----+-----+------+------+-----+------+------+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+------+------+------+------+------+------+-------+-------+-------+--------+------+------+-------+-------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+-----+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+------+------+-------+-------+------+-------+--------+------+-------+------+-----+-------+-------------------+\n",
            "|_c0|  _c1|     _c2|   _c3|   _c4|   _c5|   _c6|   _c7|   _c8|   _c9|  _c10|  _c11|  _c12| _c13| _c14| _c15|  _c16|_c17|  _c18|  _c19|  _c20|  _c21|  _c22|  _c23|  _c24|  _c25|  _c26|   _c27|  _c28|   _c29|  _c30|   _c31|  _c32|   _c33| _c34|   _c35|   _c36|  _c37|   _c38|   _c39| _c40| _c41|  _c42|  _c43|  _c44|  _c45|  _c46|  _c47|  _c48|  _c49| _c50|  _c51|  _c52| _c53|  _c54|  _c55|  _c56| _c57|  _c58|  _c59|  _c60|  _c61|  _c62|_c63|_c64|  _c65|   _c66|  _c67|   _c68|  _c69|  _c70|  _c71|   _c72|  _c73|  _c74| _c75|  _c76| _c77|  _c78|   _c79|  _c80|  _c81|   _c82|    _c83|  _c84|  _c85|  _c86|  _c87|  _c88|  _c89|  _c90|  _c91|  _c92| _c93| _c94| _c95|  _c96|_c97|  _c98|_c99| _c100| _c101| _c102| _c103| _c104| _c105|_c106|  _c107|_c108|  _c109|  _c110|   _c111| _c112|_c113|  _c114|  _c115| _c116| _c117| _c118|  _c119| _c120|  _c121|  _c122| _c123| _c124| _c125| _c126| _c127| _c128| _c129| _c130| _c131| _c132|_c133|_c134|_c135| _c136|_c137| _c138|_c139| _c140| _c141| _c142|  _c143| _c144| _c145|  _c146|  _c147| _c148| _c149|  _c150|  _c151|  _c152|  _c153|  _c154| _c155| _c156|  _c157|  _c158| _c159| _c160|  _c161|  _c162|  _c163| _c164| _c165| _c166| _c167| _c168| _c169| _c170| _c171| _c172|_c173|_c174|_c175| _c176|_c177|_c178|_c179| _c180| _c181| _c182| _c183| _c184| _c185|  _c186|  _c187|  _c188| _c189|  _c190|  _c191|  _c192|   _c193|  _c194| _c195|   _c196|  _c197|  _c198|  _c199| _c200| _c201| _c202| _c203| _c204| _c205| _c206| _c207| _c208| _c209|  _c210|  _c211|   _c212|  _c213| _c214| _c215| _c216| _c217| _c218| _c219| _c220| _c221| _c222|  _c223|  _c224|   _c225|  _c226| _c227| _c228| _c229| _c230| _c231| _c232|_c233| _c234| _c235| _c236| _c237|  _c238|  _c239| _c240| _c241| _c242| _c243| _c244| _c245| _c246| _c247| _c248|  _c249|  _c250|  _c251|  _c252| _c253| _c254| _c255| _c256| _c257| _c258|_c259| _c260| _c261|_c262| _c263|   _c264|   _c265| _c266| _c267| _c268| _c269| _c270| _c271| _c272| _c273| _c274| _c275| _c276| _c277| _c278| _c279| _c280| _c281|_c282| _c283| _c284| _c285| _c286| _c287| _c288| _c289| _c290| _c291| _c292| _c293|  _c294|  _c295|  _c296| _c297| _c298|  _c299|  _c300|  _c301|   _c302|_c303|_c304|_c305|_c306|_c307|_c308|_c309|_c310|_c311|_c312|_c313|_c314|_c315|_c316| _c317| _c318| _c319| _c320| _c321| _c322| _c323| _c324| _c325| _c326| _c327| _c328| _c329| _c330| _c331| _c332| _c333|_c334| _c335| _c336| _c337| _c338| _c339|_c340| _c341| _c342| _c343| _c344| _c345| _c346| _c347| _c348| _c349| _c350| _c351| _c352| _c353| _c354| _c355| _c356| _c357| _c358| _c359| _c360|_c361| _c362|_c363| _c364| _c365| _c366|_c367| _c368|_c369|_c370|_c371|_c372| _c373|  _c374| _c375| _c376| _c377| _c378| _c379| _c380| _c381|_c382|_c383|_c384|_c385|_c386|_c387| _c388|_c389|_c390|_c391|_c392| _c393|_c394|_c395|_c396|_c397| _c398| _c399| _c400| _c401|_c402|_c403|_c404| _c405| _c406|_c407| _c408| _c409| _c410|_c411|_c412|_c413|_c414|_c415| _c416| _c417|_c418|_c419|_c420| _c421|_c422|_c423| _c424| _c425| _c426| _c427| _c428| _c429| _c430| _c431| _c432| _c433| _c434| _c435| _c436| _c437| _c438| _c439|_c440|_c441|_c442| _c443| _c444| _c445| _c446| _c447| _c448| _c449| _c450| _c451|  _c452|  _c453|  _c454|   _c455| _c456| _c457|  _c458|  _c459| _c460|_c461|_c462|_c463|_c464|_c465|_c466|_c467|_c468|_c469|_c470|_c471|_c472|_c473|_c474| _c475|_c476|_c477|_c478|_c479|_c480| _c481| _c482|_c483|_c484|_c485| _c486|_c487|_c488|_c489|_c490|_c491|_c492|_c493|_c494| _c495|_c496|_c497|_c498|_c499| _c500|_c501|_c502| _c503| _c504| _c505| _c506| _c507| _c508| _c509| _c510| _c511| _c512|  _c513| _c514| _c515| _c516| _c517| _c518| _c519| _c520| _c521|_c522| _c523|_c524| _c525|_c526| _c527| _c528| _c529| _c530| _c531| _c532| _c533| _c534| _c535| _c536| _c537| _c538|  _c539| _c540| _c541| _c542| _c543| _c544| _c545| _c546| _c547|_c548| _c549| _c550| _c551|  _c552|  _c553| _c554|  _c555|   _c556| _c557|  _c558| _c559|_c560|  _c561|        all_walking|\n",
            "+---+-----+--------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+------+------+------+------+------+------+------+------+------+-------+------+-------+------+-------+------+-------+-----+-------+-------+------+-------+-------+-----+-----+------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+------+-----+------+------+------+------+------+----+----+------+-------+------+-------+------+------+------+-------+------+------+-----+------+-----+------+-------+------+------+-------+--------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+------+----+------+------+------+------+------+------+-----+-------+-----+-------+-------+--------+------+-----+-------+-------+------+------+------+-------+------+-------+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+------+-----+------+------+------+-------+------+------+-------+-------+------+------+-------+-------+-------+-------+-------+------+------+-------+-------+------+------+-------+-------+-------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+-----+-----+------+------+------+------+------+------+-------+-------+-------+------+-------+-------+-------+--------+-------+------+--------+-------+-------+-------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+-------+------+------+------+------+------+------+------+------+------+-------+-------+--------+-------+------+------+------+------+------+------+-----+------+------+------+------+-------+-------+------+------+------+------+------+------+------+------+------+-------+-------+-------+-------+------+------+------+------+------+------+-----+------+------+-----+------+--------+--------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+-------+-------+-------+------+------+-------+-------+-------+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+-----+------+------+------+-----+------+-----+-----+-----+-----+------+-------+------+------+------+------+------+------+------+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+------+------+------+------+-----+-----+-----+------+------+-----+------+------+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+------+------+------+------+------+------+-------+-------+-------+--------+------+------+-------+-------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+-----+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+------+------+-------+-------+------+-------+--------+------+-------+------+-----+-------+-------------------+\n",
            "|  5|0.289| -0.0203|-0.133|-0.995|-0.983|-0.914|-0.995|-0.983|-0.924|-0.935|-0.567|-0.744|0.853|0.686|0.814|-0.966|-1.0|  -1.0|-0.995|-0.994|-0.988|-0.943|-0.408|-0.679|-0.602| 0.929| -0.853|  0.36|-0.0585| 0.257| -0.225| 0.264|-0.0952|0.279| -0.465|  0.492|-0.191|  0.376|  0.435|0.661|0.963|-0.141| 0.115|-0.985|-0.982|-0.878|-0.985|-0.984|-0.895|0.892|-0.161| 0.125|0.977|-0.123|0.0565|-0.375|0.899|-0.971|-0.976|-0.984|-0.989|-0.918|-1.0|-1.0| 0.114|  -0.59| 0.591| -0.592| 0.592|-0.745| 0.721| -0.712| 0.711|-0.995|0.996|-0.996|0.992|  0.57|  0.439| 0.987| 0.078|  0.005| -0.0678|-0.994|-0.988|-0.994|-0.994|-0.986|-0.993|-0.985|-0.992|-0.993| 0.99|0.992|0.991|-0.994|-1.0|  -1.0|-1.0|-0.994|-0.986|-0.989| -0.82|-0.793|-0.889|  1.0| -0.221|0.637|  0.388|  0.241| -0.0523| 0.264|0.373|  0.342|  -0.57| 0.265|-0.478|-0.385| 0.0336|-0.127|-0.0061|-0.0314| 0.108|-0.985|-0.977|-0.992|-0.985|-0.976|-0.992|-0.867|-0.934|-0.748|0.847|0.915|0.831|-0.967| -1.0|-0.999| -1.0|-0.983|-0.979|-0.993| 0.0826| 0.202|-0.169| 0.0963| -0.275| 0.499| -0.22|    1.0| -0.973|  0.317|  0.376|  0.723|-0.771|  0.69| -0.332|   0.71| 0.135| 0.301|-0.0992|-0.0555| -0.062|-0.992|-0.993|-0.992|-0.992|-0.995|-0.993| -0.99|-0.987|-0.992|0.994|0.992|0.989|-0.994| -1.0| -1.0| -1.0|-0.992|-0.997|-0.992| -0.59|-0.688|-0.572|  0.292| -0.362|  0.406|-0.039|  0.989| -0.415|  0.392|   0.282|  0.927|-0.572|   0.692|  0.468| -0.131|-0.0872| 0.336|-0.959|-0.951|-0.958|-0.946|-0.993|-0.959|-0.998|-0.958|-0.233| -0.173|-0.0229|  0.0948|  0.192|-0.959|-0.951|-0.958|-0.946|-0.993|-0.959|-0.998|-0.958|-0.233| -0.173|-0.0229|  0.0948|  0.192|-0.993|-0.994|-0.995|-0.993|-0.991|-0.993| -1.0|-0.993|-0.863| 0.283|-0.237| -0.105|-0.0382|-0.969|-0.964|-0.957|-0.975|-0.992|-0.969|-0.999| -0.95|0.0726|  0.573| -0.739|  0.213|  0.433|-0.994|-0.991|-0.993|-0.989|-0.993|-0.994| -1.0|-0.995| -0.62|0.293|-0.177|  -0.146|  -0.124|-0.995|-0.983|-0.939|-0.995|-0.983|-0.906|-0.997|-0.985|-0.932|-0.994|-0.983|-0.885|-0.994|-0.993|-0.923|-0.975| -1.0|  -1.0|-0.995|-0.996| -0.99|-0.988|-0.946|-0.905|-0.591|  -1.0|  -1.0|  -1.0|  0.252|  0.132|-0.0521| 0.142|-0.151| -0.221| -0.559|  0.247|-0.00742| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.999|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.994|-0.999|  -1.0| -1.0|-0.999|-0.998|-0.996|-0.995|-0.995| -1.0|-0.999|-0.996|-0.995|-0.999|-0.992|-0.987| -0.99|-0.996|-0.991|-0.997|-0.994|-0.991|-0.997|-0.997|-0.992|-0.993|-0.998|-0.991| -0.96|-0.991| -1.0|  -1.0| -1.0|-0.993|-0.991|-0.996| -1.0|  -1.0| -1.0|  1.0|-0.24| -1.0|  0.87|  0.211| 0.264|-0.704|-0.904|-0.583|-0.936|-0.507|-0.806| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|-0.999| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.987|-0.982| -0.99|-0.985|-0.974|-0.994|-0.987|-0.984|-0.992| -0.98|-0.972|-0.995|-0.998|-0.984|-0.994|-0.985| -1.0| -1.0| -1.0| -0.99|-0.995|-0.994|-0.712|-0.645|-0.839|  -1.0|  -1.0|  -1.0| -0.258| 0.0979|  0.547|   0.377| 0.134| 0.273|-0.0913| -0.484|-0.783| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0| -1.0|-0.998|-0.999| -1.0| -1.0| -1.0|-0.998| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.952|-0.956|-0.949|-0.974|-0.926|-0.952|-0.998|-0.973|-0.646|-0.793|-0.0884|-0.436|-0.797|-0.994|-0.994|-0.992|-0.993|-0.988|-0.994| -1.0|-0.991| -1.0|-0.937|0.347|-0.516|-0.803| -0.98|-0.961|-0.974|-0.952|-0.989| -0.98|-0.999|-0.993|-0.701|  -1.0| -0.129| 0.586| 0.375|-0.992|-0.991| -0.99|-0.992|-0.991|-0.992| -1.0| -0.99|-0.871|  -1.0|-0.0743| -0.299| -0.71| -0.113|  0.0304|-0.465|-0.0184|-0.841| 0.18|-0.0586|             0.2687|\n",
            "|  5|0.278| -0.0164|-0.124|-0.998|-0.975| -0.96|-0.999|-0.975|-0.958|-0.943|-0.558|-0.818|0.849|0.686|0.823|-0.982|-1.0|  -1.0|-0.998|-0.999|-0.978|-0.948|-0.715|-0.501|-0.571| 0.612|  -0.33| 0.284|  0.285| 0.116| -0.091| 0.294| -0.281|0.086|-0.0222|-0.0167|-0.221|-0.0134|-0.0727|0.579|0.967|-0.142| 0.109|-0.997|-0.989|-0.932|-0.998| -0.99|-0.933|0.892|-0.161| 0.123|0.985|-0.115| 0.103|-0.383|0.908|-0.971|-0.979|-0.999| -0.99|-0.942|-1.0|-1.0| -0.21|  -0.41| 0.414| -0.418| 0.421|-0.196| 0.125| -0.106| 0.109|-0.834|0.834|-0.834| 0.83|-0.831| -0.866| 0.974| 0.074|0.00577|  0.0294|-0.996|-0.981|-0.992|-0.996|-0.979|-0.991|-0.995|-0.979|-0.992|0.993|0.992|0.989|-0.991|-1.0|  -1.0|-1.0|-0.994|-0.979|-0.993|-0.875|-0.655|-0.767| 0.49|  0.071|0.363|  0.527|  0.149|  0.0629|  0.37|0.414|  0.122|  0.181|0.0474| 0.167|-0.209| 0.0841|-0.269|-0.0161|-0.0839| 0.101|-0.983|-0.989|-0.989|-0.987|-0.989|-0.989|-0.865|-0.954|-0.746|0.834|0.908|0.829|-0.981| -1.0|  -1.0| -1.0|-0.993|-0.989| -0.99|0.00747|-0.531|-0.177| -0.388|  0.179| 0.211| -0.14| -0.047|-0.0649|  0.118| 0.0817| 0.0424| -0.15| 0.293| -0.149| 0.0467|-0.257| 0.169| -0.111|-0.0448|-0.0592| -0.99|-0.997|-0.994| -0.99|-0.997|-0.994|-0.992|-0.998|-0.995| 0.99|0.997|0.995|-0.995| -1.0| -1.0| -1.0|-0.991|-0.997|-0.994|-0.601|-0.748|-0.609| -0.193|-0.0674|  0.186|0.0415| 0.0724|-0.0354|  0.178|  0.0275|  0.183|-0.167|   0.253|  0.132|  0.294|-0.0181|-0.343|-0.979|-0.976|-0.978|-0.979|-0.995|-0.979|-0.999|-0.981|-0.442| 0.0816| -0.109|   0.312| -0.412|-0.979|-0.976|-0.978|-0.979|-0.995|-0.979|-0.999|-0.981|-0.442| 0.0816| -0.109|   0.312| -0.412|-0.991|-0.992|-0.993|-0.989|-0.991|-0.991| -1.0|-0.993| -0.82| 0.459|-0.245| 0.0561| -0.458|-0.981|-0.984|-0.982|-0.985|-0.992|-0.981|  -1.0|-0.983|-0.193| -0.225|-0.0171|  0.156| 0.0826|-0.995|-0.996|-0.996|-0.997|-0.992|-0.995| -1.0|-0.995|-0.731|0.209|-0.178|  -0.103| -0.0438|-0.997|-0.977|-0.974|-0.999|-0.975|-0.955|-0.998|-0.977|-0.968|-0.999|-0.974|-0.949|-0.998|-0.993| -0.99|-0.986| -1.0|-0.999|-0.999|-0.995|-0.981|-0.986|  -1.0|-0.905|-0.758|0.0968|  -1.0|  -1.0|  0.271| 0.0429|-0.0143|-0.693|-0.954|-0.0497| -0.332| 0.0567|  -0.289| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.999|  -1.0|  -1.0|  -1.0|-0.999|  -1.0|-0.998|  -1.0|  -1.0| -1.0|  -1.0|-0.999|-0.999|-0.999|-0.999| -1.0|  -1.0|-0.999|-0.999|  -1.0|-0.995|-0.981| -0.99|-0.997|-0.982|-0.993|-0.995|-0.983|-0.992|-0.997|-0.985|-0.993|-0.998|-0.983|-0.987| -0.99| -1.0|  -1.0| -1.0|-0.993|-0.985|-0.991| -1.0|  -1.0| -1.0|-0.32|-0.12|-0.32| 0.609|-0.0537|0.0631| -0.63| -0.91|-0.414|-0.851|-0.656|-0.916| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.977|-0.993| -0.99|-0.985|-0.987| -0.99|-0.979|-0.992|-0.988|-0.987|-0.985| -0.99|-0.987|-0.999|-0.994|-0.987| -1.0| -1.0| -1.0|-0.987|-0.996|-0.987|-0.611|-0.765|-0.751|  -1.0|  -1.0|  -1.0|-0.0482| -0.402|-0.0682|  -0.459|-0.797| 0.388|  0.149| -0.157|-0.452| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.981|-0.976|-0.976|-0.978|-0.987|-0.981|-0.999|-0.984|-0.817|  -1.0|-0.0441|-0.122| -0.45| -0.99|-0.992| -0.99|-0.994| -0.99| -0.99| -1.0|-0.991| -1.0|-0.841|0.532|-0.625|  -0.9|-0.988|-0.983|-0.983|-0.986|-0.992|-0.988|  -1.0|-0.994|-0.721|-0.949| -0.272|-0.336| -0.72|-0.996|-0.996|-0.995|-0.997|-0.994|-0.996| -1.0|-0.995|  -1.0|  -1.0|  0.158| -0.595|-0.861| 0.0535|-0.00743|-0.733|  0.704|-0.845| 0.18|-0.0543|             0.2616|\n",
            "|  5| 0.28| -0.0195|-0.113|-0.995|-0.967|-0.979|-0.997|-0.964|-0.977|-0.939|-0.558|-0.818|0.844|0.682|0.839|-0.983|-1.0|  -1.0|-0.999|-0.997|-0.965|-0.975|-0.592|-0.486|-0.571| 0.273|-0.0863| 0.337| -0.165|0.0172|-0.0745| 0.342| -0.333|0.239| -0.136|  0.174|-0.299| -0.125| -0.181|0.609|0.967|-0.142| 0.102|  -1.0|-0.993|-0.993|  -1.0|-0.993|-0.993|0.892|-0.164|0.0946|0.987|-0.115| 0.103|-0.402|0.909| -0.97|-0.982|  -1.0|-0.992|-0.993|-1.0|-1.0|-0.927|0.00223|0.0275|-0.0567|0.0855|-0.329| 0.271| -0.254| 0.258|-0.705|0.714|-0.723|0.729|-0.181|  0.338| 0.643|0.0736| 0.0031|-0.00905|-0.991|-0.981| -0.99|-0.991|-0.979|-0.987|-0.987|-0.979|-0.992|0.988|0.992|0.989|-0.988|-1.0|  -1.0|-1.0|-0.988| -0.98|-0.982|-0.754|-0.673|-0.747|0.265|  0.188|0.465|  0.372| 0.0827|-0.00462| 0.327|0.438|  0.258|   0.07| 0.187| 0.247| -0.12|  -0.11| -0.04|-0.0317| -0.102|0.0961|-0.976|-0.994|-0.986|-0.975|-0.994|-0.986|-0.865|-0.959|-0.743|0.834|0.906|0.829|-0.976| -1.0|  -1.0| -1.0|-0.972|-0.995|-0.987| -0.261|  -1.0|-0.248| -0.437|  0.239| 0.145|-0.114| 0.0323| -0.128|  0.115|  0.125|  0.112|-0.166| 0.135|  0.184|-0.0101|0.0433|-0.351| -0.108|-0.0424|-0.0558|-0.988|-0.996|-0.992|-0.988|-0.996|-0.992|-0.993|-0.994|-0.989|0.989|0.997|0.994|-0.993| -1.0| -1.0| -1.0|-0.987|-0.995|-0.993|-0.544|-0.673|-0.588| -0.241|-0.0114|  0.116|0.0896|  0.096| 0.0096| 0.0951|   0.253|  0.182|-0.169|   0.132| 0.0082|  0.193| 0.0737|-0.315|-0.984|-0.988|-0.988|-0.986|-0.995|-0.984|  -1.0|-0.986|  -0.6|  0.038|-0.0742|   0.254| -0.296|-0.984|-0.988|-0.988|-0.986|-0.995|-0.984|  -1.0|-0.986|  -0.6|  0.038|-0.0742|   0.254| -0.296|-0.989| -0.99|-0.991|-0.989|-0.993|-0.989| -1.0| -0.99|-0.795|  0.65| -0.26| -0.128| -0.521|-0.976|-0.986|-0.984|-0.985|-0.966|-0.976|  -1.0|-0.983|-0.223| -0.227| 0.0597| 0.0615| 0.0417|-0.993|-0.995|-0.995|-0.995|-0.998|-0.993| -1.0|-0.994|-0.663|0.328|-0.155|  -0.221|  -0.108|-0.994|-0.973|-0.983|-0.996|-0.966|-0.977|-0.994|-0.972|-0.982|-0.998|-0.963|-0.969|-0.997| -0.99|-0.991|-0.986| -1.0|-0.999|-0.999|-0.989|-0.977|-0.981|  -1.0|-0.816|-0.814|-0.935|  -1.0|  -1.0|  0.125|-0.0646| 0.0827|-0.727|-0.965|  0.163|-0.0922|-0.0449|  -0.288| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.999|  -1.0|  -1.0|  -1.0|-0.999|  -1.0|-0.999|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.999| -1.0|  -1.0|  -1.0|-0.999|  -1.0|-0.991|-0.982|-0.988|-0.991|-0.981| -0.99|-0.988|-0.981|-0.988|-0.995|-0.985|-0.994|-0.997|-0.999|-0.998|-0.987| -1.0|  -1.0| -1.0|-0.982|-0.985|-0.982| -1.0|  -1.0| -1.0|-0.16|-0.48|-0.28| 0.115| -0.193|0.0383|-0.595|-0.924|-0.529|-0.913|-0.803| -0.98| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.975|-0.994|-0.987|-0.977|-0.993|-0.987|-0.976|-0.994|-0.985|-0.973|-0.995|-0.991|-0.988|-0.997|-0.994|-0.986| -1.0| -1.0| -1.0|-0.986|-0.995|-0.993|-0.591|-0.808|-0.751|  -1.0|-0.871|  -1.0| -0.217|-0.0173| -0.111|  0.0905|-0.245|-0.429| -0.813| -0.392|-0.767| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.988|-0.989|-0.986|-0.993| -0.99|-0.988|  -1.0|-0.989|-0.907|-0.862|  0.258|-0.619| -0.88|-0.989|-0.991|-0.987|-0.993|  -1.0|-0.989| -1.0|-0.987| -1.0|-0.905|0.661|-0.725|-0.929|-0.989|-0.986|-0.984|-0.991|-0.996|-0.989|  -1.0|-0.993|-0.737|-0.795| -0.213|-0.535|-0.872|-0.995|-0.995|-0.995|-0.996|-0.996|-0.995| -1.0|-0.994|  -1.0|-0.556|  0.415| -0.391| -0.76| -0.119|   0.178| 0.101|  0.809|-0.849|0.181|-0.0491|             0.2605|\n",
            "|  5|0.279| -0.0262|-0.123|-0.996|-0.983|-0.991|-0.997|-0.983|-0.989|-0.939|-0.576| -0.83|0.844|0.682|0.838|-0.986|-1.0|  -1.0|  -1.0|-0.997|-0.984|-0.986|-0.627|-0.851|-0.912|0.0614| 0.0748| 0.198| -0.264|0.0725| -0.155| 0.323| -0.171|0.295| -0.306|  0.482| -0.47| -0.306| -0.363|0.507|0.968|-0.144|0.0999|-0.997|-0.981|-0.978|-0.996|-0.981|-0.978|0.894|-0.164|0.0934|0.987|-0.121|0.0958|  -0.4|0.911|-0.969|-0.982|-0.996|-0.981| -0.98|-1.0|-1.0|-0.596|-0.0649|0.0754|-0.0858|0.0962|-0.295| 0.228| -0.206| 0.205|-0.385|0.386|-0.387|0.385|-0.991| -0.969| 0.984|0.0773| 0.0201|-0.00986|-0.993|-0.988|-0.993|-0.994|-0.986|-0.991|-0.987|-0.992| -0.99|0.988|0.993|0.993|-0.993|-1.0|  -1.0|-1.0|-0.995|-0.987|-0.989|-0.821|-0.755|-0.825|0.123|  0.276|0.457|  0.193|  0.102| -0.0991| 0.195|0.484|  0.358| -0.187| 0.298| 0.452|-0.127|-0.0833| 0.457|-0.0434|-0.0914|0.0855|-0.991|-0.992|-0.988|-0.992|-0.993| -0.99|-0.885|-0.957|-0.743|0.834|0.906|0.827|-0.982| -1.0|  -1.0| -1.0|-0.991|-0.994|-0.995| -0.931|-0.827|-0.543| -0.166|-0.0129|  0.32|-0.165| 0.0446| -0.125| 0.0783|  0.177|  0.193|-0.207| 0.112|  0.202|   0.21| 0.141|-0.725|-0.0912|-0.0363|-0.0605|-0.991|-0.997|-0.993|-0.991|-0.997|-0.994|-0.994|-0.994|-0.989|0.989|0.998|0.994|-0.995| -1.0| -1.0| -1.0|-0.991|-0.997|-0.995|-0.562|-0.731|-0.661|0.00989| -0.138|  0.126| 0.316| 0.0943| 0.0262| 0.0697|   0.247|  0.257|-0.137|  0.0873|  0.149|  0.197|   0.14|-0.306|-0.987|-0.986|-0.986|-0.986|-0.997|-0.987|  -1.0|-0.984|-0.589|-0.0929| 0.0464|-4.66E-4| 0.0371|-0.987|-0.986|-0.986|-0.986|-0.997|-0.987|  -1.0|-0.984|-0.589|-0.0929| 0.0464|-4.66E-4| 0.0371|-0.993|-0.993|-0.993|-0.993|-0.993|-0.993| -1.0|-0.992|-0.792| 0.662|-0.247|  -0.23| -0.436|-0.982|-0.987|-0.986| -0.99|-0.982|-0.982|  -1.0|-0.984|-0.241| -0.202| 0.0547|   0.11|-0.0794|-0.996|-0.995|-0.995|-0.995|-0.998|-0.996| -1.0|-0.995|-0.683|0.595|-0.265|  -0.316|  -0.164|-0.995|-0.984|-0.991|-0.996|-0.983| -0.99|-0.995|-0.983|-0.989|-0.997|-0.987|-0.988|-0.994| -0.99|-0.997|-0.993| -1.0|  -1.0|  -1.0| -0.99|-0.992|-0.988|  -1.0| -0.87|-0.944|  -1.0|  -1.0|  -1.0|  0.029| 0.0803|  0.186|-0.599|-0.908| -0.461| -0.813| -0.567|  -0.771| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.994|-0.989|-0.991|-0.991|-0.987|-0.994|-0.989|-0.987|-0.994|-0.993|-0.988|-0.994|-0.998|  -1.0|-0.965|-0.993| -1.0|  -1.0| -1.0|-0.992|-0.991|-0.993| -1.0|  -1.0| -1.0|-0.12|-0.56|-0.28|0.0358| -0.093| 0.168|-0.264|-0.757|-0.396| -0.83|-0.577|-0.893| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.987|-0.994|-0.987|-0.993|-0.992|-0.989| -0.99|-0.993|-0.987|-0.995|-0.992|-0.992| -0.99|-0.994|-0.993| -0.99| -1.0| -1.0| -1.0|-0.993|-0.996| -0.99|-0.724|-0.804|-0.817|  -1.0|  -1.0|-0.793|  0.217| -0.135|-0.0497|  -0.572|-0.874|-0.135| -0.542| -0.379|-0.757| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.988|-0.987|-0.984| -0.99|-0.998|-0.988|  -1.0|-0.983|-0.907|  -1.0| 0.0736|-0.468|-0.756|-0.993|-0.992|-0.989|-0.994|-0.996|-0.993| -1.0|-0.988| -1.0|   1.0|0.679|-0.701| -0.91|-0.989|-0.988|-0.987|-0.987|-0.996|-0.989|  -1.0|-0.989|-0.721|  -1.0|-0.0357| -0.23|-0.511|-0.995|-0.995|-0.996|-0.995|-0.996|-0.995| -1.0|-0.995|-0.956|-0.937|  0.405| -0.117|-0.483|-0.0368| -0.0129|  0.64| -0.485|-0.849|0.182|-0.0477|             0.2528|\n",
            "|  5|0.277| -0.0166|-0.115|-0.998|-0.981| -0.99|-0.998| -0.98| -0.99|-0.942|-0.569|-0.825|0.849|0.683|0.838|-0.993|-1.0|  -1.0|  -1.0|-0.998|-0.981|-0.991|-0.787|-0.559|-0.761| 0.313| -0.131| 0.191| 0.0869| 0.258| -0.273| 0.435| -0.315| 0.44| -0.269|  0.179|-0.089| -0.156|  -0.19|0.599|0.968|-0.149|0.0945|-0.998|-0.988|-0.979|-0.998|-0.989|-0.979|0.894|-0.167|0.0917|0.987|-0.122|0.0941|  -0.4|0.912|-0.967|-0.984|-0.998|-0.991| -0.98|-1.0|-1.0|-0.617| -0.257| 0.269| -0.281| 0.293|-0.167|0.0899|-0.0663|0.0671|-0.237|0.239|-0.241|0.241|-0.408| -0.185| 0.965|0.0734| 0.0191|  0.0168|-0.996|-0.988|-0.992|-0.997|-0.987|-0.991|-0.997|-0.992| -0.99|0.994|0.993|0.986|-0.994|-1.0|  -1.0|-1.0|-0.996|-0.987|-0.991|-0.851|-0.746|-0.797|0.241|  0.135|0.297|  0.287|  0.319|  -0.143| 0.477|0.418|   0.39|-0.0303| 0.163|  0.18|-0.273|  0.103|0.0647| -0.034|-0.0747|0.0774|-0.985|-0.992|-0.987|-0.987|-0.993|-0.988| -0.87|-0.953| -0.75|0.839|0.911|0.821|-0.985| -1.0|  -1.0| -1.0| -0.99|-0.993|-0.991| -0.629|-0.468|-0.651| -0.213|0.00211| 0.388|-0.233| -0.163|  0.186| -0.435|   0.65|   0.24| -0.34| 0.133|  0.473| -0.142| 0.484|-0.725|-0.0908|-0.0376|-0.0583|-0.991|-0.996|-0.995|-0.993|-0.997|-0.994| -0.98|-0.998|-0.993|0.994|0.997|0.997|-0.996| -1.0| -1.0| -1.0|-0.995|-0.997|-0.994|-0.618|-0.683|-0.633|-0.0257| -0.188|  0.231|   0.2| -0.149|  0.272| -0.272|-0.00994|  0.235|-0.341| -0.0857|  0.164|  0.121|  0.107|-0.283|-0.993|-0.991|-0.991|-0.991|-0.997|-0.993|  -1.0| -0.99|-0.705|   0.18| -0.278|   0.516| -0.356|-0.993|-0.991|-0.991|-0.991|-0.997|-0.993|  -1.0| -0.99|-0.705|   0.18| -0.278|   0.516| -0.356|-0.993|-0.996|-0.996|-0.993|-0.981|-0.993| -1.0|-0.997| -0.85| 0.312| -0.17|  0.134| -0.458|-0.985|-0.989| -0.99|-0.987|-0.982|-0.985|  -1.0|-0.992|-0.339| -0.237| 0.0938| 0.0233|  0.039|-0.996|-0.995|-0.996|-0.992|-0.992|-0.996| -1.0|-0.996| -0.72|0.332|-0.261|  -0.146|-0.00737|-0.997|-0.982|-0.988|-0.999| -0.98|-0.992|-0.998|-0.982|-0.991|-0.999|-0.981|-0.989|-0.995|-0.992|-0.974|-0.992| -1.0|  -1.0|  -1.0|-0.994|-0.988|-0.986|  -1.0| -0.87|-0.944|0.0968|  -1.0|  -1.0|  0.181|  0.058|   0.56|-0.677|-0.951|  -0.18| -0.534| -0.586|   -0.79| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|-0.999|-0.999|  -1.0| -1.0|  -1.0|-0.999|  -1.0|  -1.0|-0.996|-0.989|-0.991|-0.997|-0.989|-0.993|-0.996|-0.989|-0.992|-0.997| -0.99|-0.995|-0.996|-0.996|-0.996|-0.993| -1.0|  -1.0| -1.0|-0.996|-0.992|-0.986| -1.0|  -1.0| -1.0|-0.32|-0.08| 0.04| 0.273| 0.0791| 0.292|-0.522|-0.813|-0.497|-0.904|-0.764|-0.966| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.982|-0.993|-0.989|-0.986|-0.992|-0.988|-0.983|-0.993|-0.986|-0.988|-0.993|-0.991|-0.994|-0.994|-0.995|-0.989| -1.0| -1.0| -1.0| -0.99|-0.996|-0.997|-0.653|-0.827|-0.737|  -1.0|-0.806|  -1.0| -0.153|-0.0884| -0.162|   -0.34|-0.723|-0.265|  -0.69| -0.268|-0.659| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.994| -0.99|-0.992|-0.991|-0.988|-0.994|  -1.0|-0.997|-0.907|  -1.0|  0.394|-0.113|-0.482|-0.996|-0.994|-0.993|-0.995|-0.982|-0.996| -1.0|-0.994| -1.0|  -1.0|0.559|-0.529|-0.859|-0.991|-0.989|-0.988|-0.991|-0.998|-0.991|  -1.0|-0.989|-0.763|-0.897| -0.274| -0.51|-0.831|-0.995|-0.995|-0.995|-0.996|-0.997|-0.995| -1.0|-0.995|  -1.0|-0.937| 0.0878| -0.351|-0.699|  0.123|   0.123| 0.694| -0.616|-0.848|0.185|-0.0439|             0.2604|\n",
            "|  5|0.277| -0.0101|-0.105|-0.997| -0.99|-0.995|-0.998| -0.99|-0.996|-0.942|-0.566|-0.823|0.849|0.696|0.846|-0.994|-1.0|  -1.0|  -1.0|-0.998|-0.992|-0.995|-0.752|-0.455|-0.551|  0.39| -0.182| 0.159|  0.187|  0.26| -0.243| 0.422| -0.418|0.558| -0.218|  0.165|0.0809|  -0.21| -0.151| 0.18|0.968|-0.148|0.0919|-0.999|-0.987|-0.997|-0.999|-0.987|-0.997|0.894|-0.167|0.0833|0.988|-0.122|0.0941|-0.409|0.912|-0.967|-0.985|-0.999|-0.987|-0.998|-1.0|-1.0|  -1.0| -0.302| 0.379| -0.457| 0.537|-0.198| 0.127| -0.108| 0.111|-0.158|0.175|-0.193|0.208|-0.564|  0.466| 0.443|0.0779| 0.0187| 0.00934|-0.995|-0.989|-0.992|-0.995|-0.987|-0.991|-0.994|-0.992|-0.993|0.994|0.993|0.986|-0.993|-1.0|  -1.0|-1.0|-0.995|-0.987| -0.99|-0.779|-0.755|-0.791|0.281|    0.1| 0.26|  0.202|  0.351| -0.0773| 0.563|0.352|  0.369| 0.0434| 0.147| 0.299|-0.375| 0.0418|-0.112|-0.0288|-0.0704| 0.079|-0.985|-0.992|-0.983|-0.986|-0.992|-0.983| -0.87|-0.953|-0.746| 0.84|0.911|0.819|-0.985| -1.0|  -1.0| -1.0|-0.985|-0.993|-0.984| -0.364|-0.371|-0.462| -0.403|  0.242|0.0591|0.0303|  -0.12|  0.151| -0.381|  0.573|  0.104|-0.228| 0.138|  0.346| -0.448| 0.645|-0.746|-0.0942|-0.0434|-0.0419|-0.992|-0.996|-0.993|-0.993|-0.996|-0.993| -0.98|-0.998|-0.993|0.994|0.997|0.997|-0.995| -1.0| -1.0| -1.0|-0.994|-0.996|-0.992|-0.628|-0.681|-0.542| -0.265| 0.0558|-0.0456| 0.236| -0.122|  0.268| -0.194|-0.00532|  0.203|-0.297|  0.0699|-0.0123| 0.0179|  0.187|-0.321|-0.994|-0.995|-0.995|-0.996|-0.994|-0.994|  -1.0|-0.993|-0.785|   0.37| -0.393|   0.563| -0.482|-0.994|-0.995|-0.995|-0.996|-0.994|-0.994|  -1.0|-0.993|-0.785|   0.37| -0.393|   0.563| -0.482|-0.993|-0.995|-0.996|-0.993|-0.993|-0.993| -1.0|-0.995|-0.871|0.0727|0.0178|-0.0686| -0.166|-0.986|-0.986|-0.986|-0.987| -0.99|-0.986|  -1.0|-0.989|-0.245| -0.173|-0.0078| 0.0959| 0.0698|-0.995|-0.995|-0.996|-0.992|-0.993|-0.995| -1.0|-0.996|-0.751|0.179|-0.181|  0.0496|  -0.169|-0.997|-0.987|-0.993|-0.998|-0.992|-0.997|-0.997| -0.99|-0.995|-0.999|-0.993|-0.998|-0.996|-0.995|-0.986|-0.995| -1.0|  -1.0|  -1.0|-0.995|-0.987|-0.988|  -1.0|-0.945|  -1.0|-0.613|  -1.0|  -1.0|  0.157|  0.319|  0.606|-0.631|-0.935| -0.661| -0.899| -0.881|  -0.964| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|-0.999|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.995|-0.988| -0.99|-0.995| -0.99|-0.993|-0.993| -0.99|-0.992|-0.997|-0.993|-0.994|-0.996|-0.999|-0.985|-0.992| -1.0|  -1.0| -1.0|-0.991|-0.991|-0.988| -1.0|  -1.0| -1.0|-0.32|-0.36| 0.52| 0.329| 0.0548| 0.321|-0.595|-0.905|-0.665|-0.956|-0.723|-0.943| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.985|-0.993|-0.981|-0.985|-0.992|-0.985|-0.983|-0.993|-0.984|-0.983|-0.993|-0.988|-0.999|-0.998|-0.982|-0.988| -1.0| -1.0| -1.0|-0.988|-0.994| -0.99|-0.678|-0.808|-0.751|-0.933|-0.935|-0.931| -0.363| -0.133|  0.195|-0.00403|-0.323| -0.29| -0.705| -0.235|-0.608| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.995|-0.995|-0.994|-0.995|-0.989|-0.995|  -1.0|-0.992|  -1.0|  -1.0|  0.438|-0.595|-0.809|-0.995|-0.995|-0.994|-0.994|-0.983|-0.995| -1.0|-0.997| -1.0|  -1.0|0.247|-0.521|-0.803|-0.991|-0.986|-0.986|-0.988|-0.995|-0.991|  -1.0|-0.992|-0.769|  -1.0| -0.297|-0.346|-0.727|-0.995|-0.995|-0.994|-0.996|-0.999|-0.995| -1.0|-0.995|  -1.0|  -1.0|   0.02| -0.545|-0.845| 0.0826|  -0.143| 0.275| -0.368| -0.85|0.185|-0.0421|             0.2669|\n",
            "|  5|0.279| -0.0196| -0.11|-0.997|-0.967|-0.983|-0.997|-0.966|-0.983|-0.941|-0.566|-0.817|0.851|0.674|0.834|-0.987|-1.0|  -1.0|  -1.0|-0.997|-0.972|-0.983|-0.637|-0.515|-0.537|  0.36| -0.233| 0.226| 0.0695|0.0643|-0.0764| 0.138|-0.0368|0.231| -0.115|  0.319|-0.488|-0.0959| -0.136|0.611|0.968|-0.144|0.0931|-0.999|-0.989|-0.992|-0.999|-0.989|-0.992|0.893|-0.166|0.0852|0.988| -0.12|0.0941|-0.417|0.911|-0.969|-0.985|-0.999| -0.99|-0.991|-1.0|-1.0|  -1.0| -0.301| 0.401| -0.503| 0.606|-0.423| 0.374| -0.362| 0.367|-0.128|0.138|-0.147|0.153| 0.726|  0.939| 0.879|0.0822| -0.017| -0.0158|-0.995|-0.985|-0.988|-0.996|-0.983|-0.989|-0.994|-0.988|-0.982|0.994|0.991|0.989|-0.992|-1.0|  -1.0|-1.0|-0.996| -0.98| -0.99|-0.788|-0.726|-0.749|0.318| 0.0311|0.308|   0.24| 0.0785|-0.00397| 0.171| 0.18|  0.293|  0.155| 0.244| 0.612| 0.108|  0.255| 0.265|-0.0286| -0.083|0.0955|-0.988|-0.989|-0.979|-0.988| -0.99| -0.98|-0.881|-0.954|-0.743|0.839|0.907|0.819|-0.984| -1.0|  -1.0| -1.0|-0.987|-0.992|-0.982| -0.374| -0.57|-0.166|-0.0949|-0.0377| 0.335|-0.101|-0.0469|-0.0549| 0.0634|   0.24| 0.0176|-0.117|0.0488|  0.336|-0.0161| 0.466|-0.688|-0.0971|-0.0416|-0.0447| -0.99|-0.995| -0.99| -0.99|-0.996| -0.99|-0.991|-0.996|-0.992|0.992|0.997|0.995|-0.994| -1.0| -1.0| -1.0| -0.99|-0.996|-0.989| -0.52|-0.666|  -0.5|0.00959| -0.131|  0.108| 0.417|-0.0525| 0.0512|-0.0398|   0.369| 0.0208|-0.112|  -0.111|  0.213|  0.218|  0.204|-0.416|-0.987|-0.983|-0.987|-0.978|-0.993|-0.987|  -1.0|-0.991|-0.586|  0.156|  -0.24|   0.293|-0.0627|-0.987|-0.983|-0.987|-0.978|-0.993|-0.987|  -1.0|-0.991|-0.586|  0.156|  -0.24|   0.293|-0.0627|-0.991|-0.989|-0.991|-0.986|-0.993|-0.991| -1.0|-0.993|-0.795| 0.178|0.0616| -0.187| -0.207|-0.986|-0.985|-0.982|-0.988|-0.993|-0.986|  -1.0| -0.98|-0.219|-0.0993|-0.0913|  0.196|-0.0113|-0.994|-0.995|-0.995|-0.996|-0.993|-0.994| -1.0|-0.994|-0.681|0.265|-0.255|   0.203|  -0.365|-0.996|-0.968|-0.984|-0.997|-0.968|-0.983|-0.998|-0.972|-0.983|-0.997|-0.969|-0.977|-0.995|-0.996|-0.996|-0.986| -1.0|-0.999|  -1.0|-0.997|-0.981|-0.978|  -1.0|-0.758|-0.869|-0.484|  -1.0|  -1.0|  0.432|   0.11|   0.38|-0.321|-0.708|-0.0994| -0.428| -0.263|  -0.506| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0|  -1.0|-0.999|  -1.0|-0.999|-0.999|-0.999|-0.999|  -1.0|-0.999|-0.999|-0.999|-0.999|  -1.0|  -1.0|-0.999| -1.0|  -1.0|  -1.0|-0.999|-0.999|  -1.0| -1.0|  -1.0|-0.999|  -1.0|  -1.0|-0.995|-0.983|-0.987|-0.996|-0.988|-0.988|-0.995|-0.988|-0.988|-0.995|-0.991|-0.989|-0.985|-0.993|-0.967|-0.989| -1.0|  -1.0| -1.0|-0.995| -0.99|-0.987| -1.0|  -1.0| -1.0|-0.12| -0.6|  0.0| 0.356| 0.0508| 0.209|-0.298|-0.652|-0.643| -0.95| -0.42|-0.833| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0|-0.999| -1.0| -1.0|-0.986| -0.99|-0.978|-0.989|-0.988|-0.981|-0.985| -0.99|-0.978| -0.99|-0.992|-0.987|  -1.0|-0.994|-0.993|-0.986| -1.0| -1.0| -1.0|-0.986|-0.993|-0.987|-0.661|-0.716|-0.709|  -1.0|-0.935|  -1.0| -0.307| -0.346|-0.0792|  -0.406|-0.755|  -0.3| -0.729| -0.369| -0.75| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.982|-0.985|-0.982|-0.989|-0.975|-0.982|  -1.0| -0.99|-0.844|  -1.0|   0.22|-0.473|-0.784|-0.988|-0.991|-0.988|-0.994|-0.976|-0.988| -1.0|-0.991| -1.0|-0.905| 0.29|-0.669|-0.933|-0.988|-0.985|-0.984|-0.985|-0.995|-0.988|  -1.0|-0.989|-0.736|  -1.0| -0.257|-0.322|-0.658|-0.996|-0.995|-0.994|-0.994|-0.997|-0.996| -1.0|-0.994|-0.956|  -1.0|  0.146| -0.217|-0.564| -0.213|  -0.231|0.0146|  -0.19|-0.852|0.182| -0.043|             0.2594|\n",
            "|  5|0.277| -0.0305|-0.125|-0.997|-0.967|-0.982|-0.996|-0.966|-0.983|-0.941|-0.573|-0.817| 0.85| 0.67|0.832|-0.977|-1.0|-0.999|-0.999|-0.996|-0.976|-0.987|-0.633|-0.744|-0.822| 0.363| -0.301| 0.347|-0.0637| 0.144| -0.132|0.0832| 0.0416|0.137|-0.0923|  0.372|-0.721| -0.162|-0.0171|0.561|0.968|-0.147|0.0917|-0.998|-0.973|-0.977|-0.998|-0.973|-0.977|0.894|-0.166|0.0852|0.988|-0.129|0.0859|-0.413|0.913|-0.968|-0.985|-0.998|-0.976|-0.982|-1.0|-1.0| -0.59| -0.368|  0.39| -0.412| 0.433|-0.471| 0.421| -0.405| 0.405|-0.143|0.139|-0.135| 0.13|-0.933| -0.859| 0.982|0.0724|0.00875|-0.00447|-0.995|-0.981| -0.99|-0.995|-0.978|-0.992|-0.996|-0.988|-0.982|0.994|0.991|0.989|-0.991|-1.0|  -1.0|-1.0|-0.993|-0.977|-0.995|-0.807|-0.672|-0.778|0.388|-0.0173|0.387|  0.394|  0.163|  0.0258| 0.123|0.274|  0.291|  0.169| 0.332|  0.53|  0.21|  0.304| 0.192|-0.0242|-0.0779|0.0941|-0.989|-0.987|-0.979|-0.989|-0.988|-0.976|-0.879|-0.953|-0.743|0.839|0.907|0.826|-0.983| -1.0|  -1.0| -1.0|-0.989| -0.99|-0.975| -0.255|-0.403|-0.243|-0.0523|  -0.11| 0.446|-0.183|-0.0859|-0.0132|-0.0539|  0.366|  0.166|-0.283| 0.177|  0.308|  0.204| 0.193|-0.733| -0.103|-0.0355|-0.0632|-0.991|-0.996|-0.991|-0.991|-0.996| -0.99|-0.991|-0.996|-0.992|0.992|0.997|0.995|-0.994| -1.0| -1.0| -1.0|-0.991|-0.996|-0.989|-0.582|-0.668|-0.565|  0.076| -0.224|  0.238| 0.335| -0.087| 0.0739| -0.138|   0.321|  0.206|-0.304| 0.00519|  0.101|  0.264|  0.208|-0.385|-0.977|-0.976|-0.977|-0.978|-0.988|-0.977|-0.999|-0.975|-0.448| 0.0497|  -0.14|    0.15| 0.0351|-0.977|-0.976|-0.977|-0.978|-0.988|-0.977|-0.999|-0.975|-0.448| 0.0497|  -0.14|    0.15| 0.0351|-0.991| -0.99|-0.992|-0.986|-0.976|-0.991| -1.0|-0.992|-0.831| 0.261|0.0351|  -0.17| -0.343|-0.985|-0.987|-0.986|-0.988|-0.993|-0.985|  -1.0|-0.987|-0.257|-0.0536| -0.127|  0.227|-0.0644|-0.994|-0.995|-0.995|-0.996|-0.992|-0.994| -1.0|-0.994|-0.646|0.327|-0.329|   0.234|  -0.352|-0.995|-0.974|-0.989|-0.997|-0.964|-0.978|-0.996|-0.973|-0.985|-0.998|-0.962|-0.967|-0.992|-0.999|-0.994|-0.989| -1.0|-0.999|  -1.0|-0.991|-0.985|-0.986|  -1.0|-0.816|-0.889|  -1.0|  -1.0|  -1.0|7.72E-4| -0.123|  0.157|-0.664|-0.942|  0.167| -0.118|   0.23|  0.0557| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0|  -1.0|  -1.0|-0.999|-0.999|  -1.0|  -1.0|-0.999|  -1.0|-0.999|  -1.0|-0.999|  -1.0|-0.999|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.995|-0.981|-0.991|-0.996|-0.983|-0.988|-0.995|-0.982|-0.989|-0.997|-0.988|-0.988|-0.994|-0.991|-0.994| -0.99| -1.0|  -1.0| -1.0|-0.992|-0.984| -0.99| -1.0|  -1.0| -1.0| -0.2|-0.48|-0.04| 0.295| 0.0229|0.0269|-0.606|-0.871|-0.636|-0.953| -0.38|-0.772| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0|-0.999|-0.999| -1.0| -1.0| -1.0|  -1.0|-0.999| -1.0|  -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.987| -0.99| -0.98| -0.99|-0.986| -0.98|-0.988| -0.99|-0.979| -0.99|-0.986|-0.982|-0.996|-0.995|-0.993|-0.987| -1.0| -1.0| -1.0|-0.991|-0.995|-0.993|-0.707| -0.74|-0.733|-0.867|  -1.0|  -1.0|-0.0881| -0.208| -0.076|  -0.181| -0.55|0.0452| -0.353|-0.0607|-0.411| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.982|-0.975|-0.977|-0.975|-0.998|-0.982|-0.999|-0.987|-0.854|  -1.0|  -0.11|0.0805|-0.184| -0.99| -0.99|-0.987|-0.994| -0.98| -0.99| -1.0| -0.99| -1.0|-0.968| 0.25|-0.656|-0.933|-0.989|-0.987|-0.986|-0.988|-0.998|-0.989|  -1.0| -0.99|-0.736|  -1.0| -0.197|-0.407|-0.733|-0.996|-0.995|-0.995|-0.994|-0.997|-0.996| -1.0|-0.995|-0.956|  -1.0|  0.136|-0.0823|-0.422|-0.0209|   0.594|-0.562|  0.467|-0.851|0.184| -0.042|0.24650000000000002|\n",
            "|  5|0.277| -0.0218|-0.121|-0.997|-0.961|-0.984|-0.998|-0.957|-0.984|-0.941|-0.564|-0.824| 0.85| 0.67|0.832|-0.983|-1.0|  -1.0|-0.999|-0.997|-0.957|-0.986|-0.683|-0.525|-0.759| 0.358| -0.253| 0.267| -0.124| 0.215| -0.183| 0.172| -0.069|0.242| -0.194|  0.217|-0.338| -0.165|-0.0338|0.724|0.968|-0.154|0.0851|-0.998|-0.976|-0.969|-0.998|-0.976|-0.969|0.894|-0.168|0.0845|0.988| -0.13|0.0832| -0.41|0.913|-0.964|-0.987|-0.997|-0.979|-0.969|-1.0|-1.0|-0.456| -0.288| 0.292| -0.295| 0.299|-0.329| 0.263|  -0.24| 0.236|-0.505|0.504|-0.502|0.497| 0.344|  0.553| 0.968|0.0753| 0.0308|  0.0112|-0.996| -0.98|-0.997|-0.996|-0.978|-0.997|-0.996|-0.988|-0.991|0.997|0.979|0.989|-0.993|-1.0|  -1.0|-1.0|-0.994|-0.977|-0.998|-0.875|-0.661|-0.868|0.376| 0.0772|0.378|  0.326|  0.222|   0.059| 0.177|0.483|  0.279|-0.0188| 0.201| 0.171|-0.301|-0.0606|0.0644|-0.0248|-0.0664|0.0779|-0.991|-0.993|-0.987|-0.991|-0.994|-0.988|-0.879|-0.953|-0.749|0.842|0.908|0.822|-0.988| -1.0|  -1.0| -1.0| -0.99|-0.995|-0.989| -0.323|-0.314|-0.591|-0.0909|-0.0383|  0.41|-0.284| -0.171| 0.0402|  0.229|-0.0273|  0.181|-0.283| 0.342|-0.0592| -0.187| 0.234|-0.442| -0.101|-0.0477|-0.0677|-0.992|-0.996|-0.994|-0.993|-0.997|-0.994| -0.99|-0.997|-0.996|0.992|0.994|0.996|-0.996| -1.0| -1.0| -1.0|-0.993|-0.997|-0.993|-0.635|-0.765|-0.688| 0.0866|  -0.11|  0.243| 0.461| -0.134|-0.0135|  0.199| -0.0371|  0.295|-0.266|    0.24|  0.187|  0.285| -0.141|-0.258|-0.984|-0.978|-0.979|-0.978|-0.994|-0.984|  -1.0| -0.98|-0.495|  0.383| -0.337|   0.219| -0.162|-0.984|-0.978|-0.979|-0.978|-0.994|-0.984|  -1.0| -0.98|-0.495|  0.383| -0.337|   0.219| -0.162|-0.993|-0.993|-0.994| -0.99|-0.985|-0.993| -1.0|-0.997|-0.851| 0.161|-0.315| 0.0355|  0.161|-0.989|-0.991| -0.99|-0.991|-0.992|-0.989|  -1.0| -0.99|-0.377|-0.0937| 0.0628| -0.111|  0.116|-0.996|-0.996|-0.996|-0.996|-0.992|-0.996| -1.0|-0.996|-0.687| 0.48|-0.259|-0.00745|  -0.367|-0.997|-0.968|-0.991|-0.997|-0.959| -0.98|-0.997| -0.97|-0.988|-0.997|-0.954|-0.968|-0.998|-0.974|-0.986|-0.989| -1.0|-0.999|  -1.0|-0.995|-0.979| -0.99|  -1.0| -0.85|-0.889|  -1.0|  -1.0|  -1.0| -0.028|  0.154|  0.165| -0.36|-0.726|  0.414|  0.228|  0.334|   0.162| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|  -1.0|  -1.0|-0.999|-0.999|-0.999|-0.999|  -1.0|-0.999|  -1.0|-0.999|-0.999|-0.999|-0.999|-0.999|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.997| -0.98|-0.996|-0.997|-0.981|-0.995|-0.995|-0.981|-0.996|-0.997|-0.985|-0.991|  -1.0|-0.983|-0.982|-0.993| -1.0|  -1.0| -1.0|-0.996|-0.984|-0.993| -1.0|  -1.0| -1.0| -0.2|  0.2|-0.04| 0.286|  0.152|  0.25|-0.477|-0.799| -0.49|-0.913|-0.279|-0.632| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|-0.999|  -1.0|-0.999| -1.0| -1.0| -1.0|  -1.0|-0.999| -1.0|  -1.0|-0.999|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.989|-0.992|-0.984|-0.991|-0.994| -0.99|-0.989|-0.994|-0.986|-0.992|-0.994|-0.993|-0.999|-0.982|-0.987| -0.99| -1.0| -1.0| -1.0| -0.99|-0.994|-0.991|-0.707|-0.827|-0.731|  -1.0|  -1.0|-0.793| -0.184|  0.177|  0.213|  -0.346|-0.694| -0.29| -0.667| -0.514|-0.842| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.983|-0.977|-0.979|-0.978|-0.984|-0.983|  -1.0|-0.989|-0.907|  -1.0| 0.0838|0.0375|-0.295|-0.992|-0.993|-0.991|-0.995|-0.996|-0.992| -1.0|-0.992| -1.0|  -1.0|0.272| -0.75|-0.929|-0.992|-0.992|-0.991|-0.992|-0.995|-0.992|  -1.0|-0.991| -0.85|  -1.0| 0.0734|-0.371|-0.675|-0.995|-0.996|-0.996|-0.995|-0.994|-0.995| -1.0|-0.995|-0.956|  -1.0|  0.314| -0.269|-0.573|  0.013|  0.0809|-0.234|  0.118|-0.848|0.189|-0.0374|0.25520000000000004|\n",
            "|  5|0.281|-0.00996|-0.106|-0.995|-0.973|-0.986|-0.995|-0.974|-0.986| -0.94|-0.555|-0.816|0.845|0.685|0.838|-0.987|-1.0|  -1.0|  -1.0|-0.996| -0.98|-0.983|-0.551|-0.295| -0.48| 0.193|-0.0212|0.0379|  0.191|0.0397| 0.0543|0.0373| 0.0816|0.172|  0.036| -0.185| 0.351| -0.176| -0.448|0.392|0.968|-0.156|0.0809|-0.997|-0.991|-0.997|-0.997|-0.991|-0.998|0.895|-0.176|0.0735|0.988| -0.13| 0.083|-0.416|0.913|-0.963|-0.989|-0.998|-0.991|-0.999|-1.0|-1.0|  -1.0| -0.331| 0.361| -0.392| 0.423|-0.362| 0.316| -0.311| 0.323|-0.467|0.484|-0.501|0.515| 0.645|-0.0291|-0.536|0.0764| 0.0125| 0.00308|-0.991|-0.969|-0.989|-0.992|-0.966| -0.99|-0.986|-0.976|-0.985|0.992|0.979|0.987|-0.986|-1.0|-0.999|-1.0| -0.99|-0.965|-0.995|-0.754|-0.529|-0.767|0.137|  0.122|0.287|-0.0411|-0.0296|   0.225|0.0635| 0.39|-0.0278|  0.185|-0.225| 0.213| 0.107|  0.136|  0.44|-0.0234|-0.0709| 0.079|-0.985|-0.987|-0.981|-0.985|-0.989|-0.983|-0.872|-0.949|-0.748|0.837|0.907|0.807|-0.984| -1.0|  -1.0| -1.0|-0.986|-0.991|-0.988| -0.263|-0.273|-0.495| -0.176| 0.0735|  0.21|0.0533| -0.204| 0.0755|  0.137|  0.211|-0.0823|0.0587|0.0352|  0.187| -0.366|  0.16|-0.447|-0.0984|-0.0435|-0.0486|-0.984|-0.993|-0.984|-0.984|-0.994|-0.986|-0.985|-0.992| -0.98|0.989|0.994|0.987| -0.99| -1.0| -1.0| -1.0|-0.985|-0.993|-0.987|-0.391|-0.559|-0.462| -0.133|-0.0247|1.51E-4| 0.443| -0.245| 0.0103| 0.0812|    0.11|-0.0877|0.0581|-0.00812|  0.203|0.00945| 0.0892|-0.456|-0.987|-0.987|-0.988|-0.988|-0.994|-0.987|  -1.0|-0.991|-0.613|  0.431| -0.397|   0.267|-0.0903|-0.987|-0.987|-0.988|-0.988|-0.994|-0.987|  -1.0|-0.991|-0.613|  0.431| -0.397|   0.267|-0.0903|-0.985|-0.984|-0.985|-0.979|-0.985|-0.985| -1.0|-0.989|-0.705| 0.232|-0.258| -0.162|  0.177|-0.985| -0.98|-0.977|-0.986|-0.992|-0.985|  -1.0|-0.977|-0.149| -0.156|  0.117|-0.0995|  0.071| -0.99|-0.991|-0.991|-0.993| -0.99| -0.99| -1.0| -0.99|-0.466|0.548|-0.329|   -0.25| -0.0818|-0.994| -0.97|-0.986|-0.995|-0.975|-0.987|-0.993|-0.971|-0.986|-0.997|-0.984|-0.986|-0.999|-0.999|-0.996|-0.986| -1.0|-0.999|  -1.0|-0.988|-0.969|-0.988|  -1.0|-0.787| -0.81| -0.29|-0.267|-0.385| 0.0376|  0.161|   0.26|-0.607|-0.913| -0.579| -0.876| -0.583|  -0.807| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|-0.999|-0.999|-0.999|-0.999|-0.999|  -1.0|  -1.0|-0.999|-0.999|-0.999|  -1.0|-0.999|-0.999|  -1.0|-0.999|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|  -1.0| -1.0|  -1.0|  -1.0|  -1.0|  -1.0|-0.992|-0.971|-0.987|-0.991|-0.969|-0.989|-0.989|-0.969|-0.989|-0.995|-0.975| -0.99|-0.995|-0.992|-0.993|-0.984| -1.0|-0.999| -1.0|-0.989|-0.972|-0.988| -1.0|-0.939| -1.0| 0.12|-0.56|-0.08| 0.212|-0.0419|  0.03|-0.489|-0.868|-0.449|-0.874|-0.575|-0.857| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|-0.999|-0.999|-0.999|-0.999| -1.0| -1.0| -1.0|-0.999|-0.999| -1.0|-0.999|-0.999|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.982|-0.988|-0.977|-0.986|-0.987|-0.984|-0.981|-0.987|-0.977|-0.988|-0.991|-0.991|-0.999|-0.991|-0.988|-0.983| -1.0| -1.0| -1.0|-0.985| -0.99|-0.978|-0.635|-0.685|-0.647|-0.533|-0.548|-0.793| -0.173| -0.249| -0.061|  -0.412|-0.761|-0.485| -0.864| -0.624|-0.908| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0|  -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0| -1.0| -1.0|  -1.0| -1.0| -1.0|-0.985|-0.989|-0.988|-0.991|-0.996|-0.985|  -1.0|-0.993|-0.907|  -1.0|  0.426|-0.478|-0.769|-0.982|-0.984| -0.98|-0.986|-0.983|-0.982| -1.0|-0.979| -1.0|  -1.0|0.251| -0.51|-0.802|-0.985| -0.98|-0.982|-0.977|-0.993|-0.985|  -1.0|-0.982|-0.671|  -1.0|  -0.14| 0.107|-0.131|-0.991|-0.991|-0.992|-0.988|-0.985|-0.991| -1.0| -0.99|-0.956|  -1.0|  0.267|   0.34|  0.14|-0.0206|  -0.128|-0.483|-0.0707|-0.848| 0.19|-0.0344|            0.27104|\n",
            "+---+-----+--------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+------+------+------+------+------+------+------+------+------+-------+------+-------+------+-------+------+-------+-----+-------+-------+------+-------+-------+-----+-----+------+------+------+------+------+------+------+------+-----+------+------+-----+------+------+------+-----+------+------+------+------+------+----+----+------+-------+------+-------+------+------+------+-------+------+------+-----+------+-----+------+-------+------+------+-------+--------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+----+------+----+------+------+------+------+------+------+-----+-------+-----+-------+-------+--------+------+-----+-------+-------+------+------+------+-------+------+-------+-------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+------+-----+------+------+------+-------+------+------+-------+-------+------+------+-------+-------+-------+-------+-------+------+------+-------+-------+------+------+-------+-------+-------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+-----+-----+-----+------+------+------+------+------+------+-------+-------+-------+------+-------+-------+-------+--------+-------+------+--------+-------+-------+-------+------+------+------+------+------+------+------+------+------+------+-------+-------+--------+-------+------+------+------+------+------+------+------+------+------+-------+-------+--------+-------+------+------+------+------+------+------+-----+------+------+------+------+-------+-------+------+------+------+------+------+------+------+------+------+-------+-------+-------+-------+------+------+------+------+------+------+-----+------+------+-----+------+--------+--------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+-------+-------+-------+------+------+-------+-------+-------+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+------+------+------+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+------+-----+------+------+------+-----+------+-----+-----+-----+-----+------+-------+------+------+------+------+------+------+------+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+-----+-----+------+------+------+------+-----+-----+-----+------+------+-----+------+------+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-----+-----+-----+------+------+------+------+------+------+------+------+------+-------+-------+-------+--------+------+------+-------+-------+------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+-----+------+------+-----+-----+-----+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+-----+------+-----+-----+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+-----+------+-----+------+------+------+------+------+------+------+------+------+------+------+------+-------+------+------+------+------+------+------+------+------+-----+------+------+------+-------+-------+------+-------+--------+------+-------+------+-----+-------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xyyKT8KMCim",
        "colab_type": "text"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrRgpvLWE43o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2482e0a0-446c-4e9b-a7a7-c621e66d57e1"
      },
      "source": [
        "from pyspark.ml.feature import PCA\n",
        "pca = PCA(k=10, inputCol=\"features\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(vector_df)\n",
        "pca_features = pca_model.transform(vector_df).select(\"pca_features\")\n",
        "type(pca_features[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.column.Column"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAb4bUlvziiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8663374e-411c-4c46-8835-a9c9d4c0e4c7"
      },
      "source": [
        "# join to labels column\n",
        "pca_complete_df = vector_df.withColumn('pca_features1', pca_features[0]) \\\n",
        "                  #  .withColumn('labels', vector_df._c0)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o9074.withColumn.\n: org.apache.spark.sql.AnalysisException: Resolved attribute(s) pca_features#19190 missing from _c46#70,_c156#180,_c96#120,_c271#295,_c84#108,_c235#259,_c50#74,_c78#102,_c102#126,_c79#103,_c475#499,_c74#98,_c216#240,_c70#94,_c273#297,_c222#246,_c260#284,_c525#549,_c36#60,_c99#123,_c450#474,_c414#438,_c373#397,_c21#45,_c131#155,_c328#352,_c202#226,_c64#88,_c112#136,_c494#518,_c539#563,_c45#69,_c425#449,_c82#106,_c364#388,_c9#33,_c511#535,_c330#354,_c372#396,_c332#356,_c380#404,_c276#300,_c377#401,_c212#236,_c261#285,_c214#238,_c518#542,_c169#193,_c185#209,_c472#496,_c313#337,_c349#373,_c141#165,_c327#351,_c259#283,_c387#411,_c397#421,_c113#137,_c59#83,_c168#192,_c321#345,_c134#158,_c552#576,_c419#443,_c108#132,_c236#260,_c266#290,_c190#214,_c265#289,_c258#282,_c333#357,_c418#442,_c318#342,_c519#543,_c127#151,_c94#118,_c458#482,_c357#381,_c545#569,_c413#437,_c309#333,_c43#67,_c359#383,_c60#84,_c42#66,_c175#199,_c298#322,_c433#457,_c47#71,_c161#185,_c65#89,_c471#495,_c72#96,_c198#222,_c484#508,_c363#387,_c150#174,_c217#241,_c370#394,_c424#448,_c305#329,_c151#175,_c215#239,_c376#400,_c281#305,_c197#221,_c499#523,_c502#526,_c293#317,_c345#369,_c95#119,_c66#90,_c469#493,_c394#418,_c379#403,_c122#146,_c352#376,_c191#215,_c155#179,_c35#59,_c11#35,_c40#64,_c103#127,_c207#231,_c455#479,_c434#458,_c334#358,_c120#144,_c529#553,_c467#491,_c470#494,_c544#568,_c538#562,_c528#552,_c299#323,_c126#150,_c252#276,_c173#197,_c34#58,_c430#454,_c211#235,_c195#219,_c393#417,_c540#564,_c241#265,_c...\n!Project [_c0#24, _c1#25, _c2#26, _c3#27, _c4#28, _c5#29, _c6#30, _c7#31, _c8#32, _c9#33, _c10#34, _c11#35, _c12#36, _c13#37, _c14#38, _c15#39, _c16#40, _c17#41, _c18#42, _c19#43, _c20#44, _c21#45, _c22#46, _c23#47, ... 540 more fields]\n+- Project [_c0#24, _c1#25, _c2#26, _c3#27, _c4#28, _c5#29, _c6#30, _c7#31, _c8#32, _c9#33, _c10#34, _c11#35, _c12#36, _c13#37, _c14#38, _c15#39, _c16#40, _c17#41, _c18#42, _c19#43, _c20#44, _c21#45, _c22#46, _c23#47, ... 539 more fields]\n   +- Relation[_c0#24,_c1#25,_c2#26,_c3#27,_c4#28,_c5#29,_c6#30,_c7#31,_c8#32,_c9#33,_c10#34,_c11#35,_c12#36,_c13#37,_c14#38,_c15#39,_c16#40,_c17#41,_c18#42,_c19#43,_c20#44,_c21#45,_c22#46,_c23#47,... 538 more fields] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.failAnalysis(CheckAnalysis.scala:43)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:369)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3412)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1340)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2258)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2225)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-13a2735376e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca_complete_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pca_features1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m#  .withColumn('_c0', vector_df._c0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \"\"\"\n\u001b[1;32m   1989\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1990\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: 'Resolved attribute(s) pca_features#19190 missing from _c46#70,_c156#180,_c96#120,_c271#295,_c84#108,_c235#259,_c50#74,_c78#102,_c102#126,_c79#103,_c475#499,_c74#98,_c216#240,_c70#94,_c273#297,_c222#246,_c260#284,_c525#549,_c36#60,_c99#123,_c450#474,_c414#438,_c373#397,_c21#45,_c131#155,_c328#352,_c202#226,_c64#88,_c112#136,_c494#518,_c539#563,_c45#69,_c425#449,_c82#106,_c364#388,_c9#33,_c511#535,_c330#354,_c372#396,_c332#356,_c380#404,_c276#300,_c377#401,_c212#236,_c261#285,_c214#238,_c518#542,_c169#193,_c185#209,_c472#496,_c313#337,_c349#373,_c141#165,_c327#351,_c259#283,_c387#411,_c397#421,_c113#137,_c59#83,_c168#192,_c321#345,_c134#158,_c552#576,_c419#443,_c108#132,_c236#260,_c266#290,_c190#214,_c265#289,_c258#282,_c333#357,_c418#442,_c318#342,_c519#543,_c127#151,_c94#118,_c458#482,_c357#381,_c545#569,_c413#437,_c309#333,_c43#67,_c359#383,_c60#84,_c42#66,_c175#199,_c298#322,_c433#457,_c47#71,_c161#185,_c65#89,_c471#495,_c72#96,_c198#222,_c484#508,_c363#387,_c150#174,_c217#241,_c370#394,_c424#448,_c305#329,_c151#175,_c215#239,_c376#400,_c281#305,_c197#221,_c499#523,_c502#526,_c293#317,_c345#369,_c95#119,_c66#90,_c469#493,_c394#418,_c379#403,_c122#146,_c352#376,_c191#215,_c155#179,_c35#59,_c11#35,_c40#64,_c103#127,_c207#231,_c455#479,_c434#458,_c334#358,_c120#144,_c529#553,_c467#491,_c470#494,_c544#568,_c538#562,_c528#552,_c299#323,_c126#150,_c252#276,_c173#197,_c34#58,_c430#454,_c211#235,_c195#219,_c393#417,_c540#564,_c241#265,_c143#167,_c1..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj9vYWJrt6C8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "88dc7208-992b-4b36-94bc-9ced25405329"
      },
      "source": [
        "labels_indexed = StringIndexer(inputCol=\"_c0\", outputCol=\"indexed_label\").fit(pca_complete_df)\n",
        "features_indexed = VectorIndexer(inputCol=\"pca_features\", outputCol=\"indexed_pca_features\").fit(pca_complete_df)\n",
        "randomf = RandomForestClassifier(featuresCol=\"indexed_pca_features\", \n",
        "                                 labelCol=\"indexed_label\", \n",
        "                                 numTrees=RF_NUM_TREES)\n",
        "rf_pipe = Pipeline([labels_indexed, features_indexed, randomf])\n",
        "\n",
        "(training_data, test_data) = pca_complete_df.randomSplit([TRAINING_DATA_RATIO, 1-TRAINING_DATA_RATIO], \n",
        "                                                         seed=42)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-5d1201e59a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_indexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"_c0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexed_label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_complete_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_indexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pca_features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexed_pca_features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_complete_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m randomf = RandomForestClassifier(featuresCol=\"indexed_pca_features\", \n\u001b[1;32m      4\u001b[0m                                  \u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"indexed_label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  numTrees=RF_NUM_TREES)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pca_complete_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRSqLfYIOX0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_rf_model = rf_pipe.fit(training_data)\n",
        "pca_preds = pca_rf_model.transform(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDPIe3MtPdZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "false_positive_rate, true_positive_rate, _ = roc_curve(\n",
        "    y_true=test_data.select(\"labels\"), \n",
        "    y_score=pca_preds.select(\"probability\"))\n",
        "\n",
        "sns.lineplot(x=false_positive_rate, y=true_positive_rate)\n",
        "plt.plot()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLmp2wYq2h2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#native\n",
        "sns.lineplot(\n",
        "    x=pca_rf_model.summary.roc.select('FPR').collect()\n",
        "    y=pca_rf_model.summary.roc.select('TPR').collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDrdglv-lx2h"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "We've seen how to prepare data and build a classifier in Spark. You might want to play around with this notebook and learn more about how Spark works. Here are some ideas:\n",
        "\n",
        "- Look at the set of labels, and see if there are any features that would make sense to combine. Spark allows you to map values into a new column.\n",
        "- Identify the most important features among the 561 source features (using PCA or something similar), then reduce the feature set and see if the model performs better.\n",
        "- Modify the settings of the random forest to see if the performance improves.\n",
        "- Use Spark's tools to find other techniques to evaluate the performance of your model. See if you can figure out how to generate an ROC plot, find the AUC value, or plot a confusion matrix."
      ]
    }
  ]
}